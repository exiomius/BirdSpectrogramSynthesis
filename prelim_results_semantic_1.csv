authors,paperId,title,venue,year,no_citations,abstract
"Lvmin Zhang, Maneesh Agrawala",e55695dfe6cde42ee195aa6672fe720ec92ee8c3,Adding Conditional Control to Text-to-Image Diffusion Models,ArXiv,2023,50,"We present a neural network structure, ControlNet, to control pretrained large diffusion models to support additional input conditions. The ControlNet learns task-specific conditions in an end-to-end way, and the learning is robust even when the training dataset is small (<50k). Moreover, training a ControlNet is as fast as fine-tuning a diffusion model, and the model can be trained on a personal devices. Alternatively, if powerful computation clusters are available, the model can scale to large amounts (millions to billions) of data. We report that large diffusion models like Stable Diffusion can be augmented with ControlNets to enable conditional inputs like edge maps, segmentation maps, keypoints, etc. This may enrich the methods to control large diffusion models and further facilitate related applications."
"Chong Mou, Xintao Wang, Liangbin Xie, Jing Zhang, Zhongang Qi, Ying Shan, Xiaohu Qie",58842cdca3ea68f7b9e638b288fc247a6f26dafc,T2I-Adapter: Learning Adapters to Dig out More Controllable Ability for Text-to-Image Diffusion Models,ArXiv,2023,14,"The incredible generative ability of large-scale text-to-image (T2I) models has demonstrated strong power of learning complex structures and meaningful semantics. However, relying solely on text prompts cannot fully take advantage of the knowledge learned by the model, especially when flexible and accurate controlling (e.g., color and structure) is needed. In this paper, we aim to ``dig out""the capabilities that T2I models have implicitly learned, and then explicitly use them to control the generation more granularly. Specifically, we propose to learn simple and lightweight T2I-Adapters to align internal knowledge in T2I models with external control signals, while freezing the original large T2I models. In this way, we can train various adapters according to different conditions, achieving rich control and editing effects in the color and structure of the generation results. Further, the proposed T2I-Adapters have attractive properties of practical value, such as composability and generalization ability. Extensive experiments demonstrate that our T2I-Adapter has promising generation quality and a wide range of applications."
"Hila Chefer, Yuval Alaluf, Yael Vinker, Lior Wolf, D. Cohen-Or",d84f6d72cd152734e676f598ffeba20c7762e15b,Attend-and-Excite: Attention-Based Semantic Guidance for Text-to-Image Diffusion Models,ArXiv,2023,7,"Recent text-to-image generative models have demonstrated an unparalleled ability to generate diverse and creative imagery guided by a target text prompt. While revolutionary, current state-of-the-art diffusion models may still fail in generating images that fully convey the semantics in the given text prompt. We analyze the publicly available Stable Diffusion model and assess the existence of catastrophic neglect, where the model fails to generate one or more of the subjects from the input prompt. Moreover, we find that in some cases the model also fails to correctly bind attributes (e.g., colors) to their corresponding subjects. To help mitigate these failure cases, we introduce the concept of Generative Semantic Nursing (GSN), where we seek to intervene in the generative process on the fly during inference time to improve the faithfulness of the generated images. Using an attention-based formulation of GSN, dubbed Attend-and-Excite, we guide the model to refine the cross-attention units to attend to all subject tokens in the text prompt and strengthen - or excite - their activations, encouraging the model to generate all subjects described in the text prompt. We compare our approach to alternative approaches and demonstrate that it conveys the desired concepts more faithfully across a range of text prompts."
"E. Hoogeboom, J. Heek, Tim Salimans",6e3a3b7a8a0376d867cad72eedf2f9b746f29a33,simple diffusion: End-to-end diffusion for high resolution images,ArXiv,2023,7,"Currently, applying diffusion models in pixel space of high resolution images is difficult. Instead, existing approaches focus on diffusion in lower dimensional spaces (latent diffusion), or have multiple super-resolution levels of generation referred to as cascades. The downside is that these approaches add additional complexity to the diffusion framework. This paper aims to improve denoising diffusion for high resolution images while keeping the model as simple as possible. The paper is centered around the research question: How can one train a standard denoising diffusion models on high resolution images, and still obtain performance comparable to these alternate approaches? The four main findings are: 1) the noise schedule should be adjusted for high resolution images, 2) It is sufficient to scale only a particular part of the architecture, 3) dropout should be added at specific locations in the architecture, and 4) downsampling is an effective strategy to avoid high resolution feature maps. Combining these simple yet effective techniques, we achieve state-of-the-art on image generation among diffusion models without sampling modifiers on ImageNet."
"Yu Takagi, Shinji Nishimoto",2824f18b3aeaae51b3fbe0d629c9b8a728da86d7,High-resolution image reconstruction with latent diffusion models from human brain activity,bioRxiv,2023,6,"Reconstructing visual experiences from human brain activity offers a unique way to understand how the brain represents the world, and to interpret the connection between computer vision models and our visual system. While deep generative models have recently been employed for this task, reconstructing realistic images with high semantic fidelity is still a challenging problem. Here, we propose a new method based on a diffusion model (DM) to reconstruct images from human brain activity obtained via functional magnetic resonance imaging (fMRI). More specifically, we rely on a latent diffusion model (LDM) termed Stable Diffusion. This model reduces the computational cost of DMs, while preserving their high generative performance. We also characterize the inner mechanisms of the LDM by studying how its different components (such as the latent vector of image Z, conditioning inputs C, and different elements of the denoising U-Net) relate to distinct brain functions. We show that our proposed method can reconstruct high-resolution images with high fidelity in straight-forward fashion, without the need for any additional training and fine-tuning of complex deep-learning models. We also provide a quantitative interpretation of different LDM components from a neuroscientific perspective. Overall, our study proposes a promising method for reconstructing images from human brain activity, and provides a new framework for understanding DMs. Please check out our webpage at https://sites.google.com/view/stablediffusion-with-brain/."
"Litu Rout, Advait Parulekar, C. Caramanis, S. Shakkottai",19cd7d16764ee6a35a49f999f1885279f149ccee,A Theoretical Justification for Image Inpainting using Denoising Diffusion Probabilistic Models,ArXiv,2023,6,"We provide a theoretical justification for sample recovery using diffusion based image inpainting in a linear model setting. While most inpainting algorithms require retraining with each new mask, we prove that diffusion based inpainting generalizes well to unseen masks without retraining. We analyze a recently proposed popular diffusion based inpainting algorithm called RePaint (Lugmayr et al., 2022), and show that it has a bias due to misalignment that hampers sample recovery even in a two-state diffusion process. Motivated by our analysis, we propose a modified RePaint algorithm we call RePaint$^+$ that provably recovers the underlying true sample and enjoys a linear rate of convergence. It achieves this by rectifying the misalignment error present in drift and dispersion of the reverse process. To the best of our knowledge, this is the first linear convergence result for a diffusion based image inpainting algorithm."
"Omer Bar-Tal, Lior Yariv, Y. Lipman, Tali Dekel",9ced6e814457eae83f5415364e266143defc81d1,MultiDiffusion: Fusing Diffusion Paths for Controlled Image Generation,ArXiv,2023,4,"Recent advances in text-to-image generation with diffusion models present transformative capabilities in image quality. However, user controllability of the generated image, and fast adaptation to new tasks still remains an open challenge, currently mostly addressed by costly and long re-training and fine-tuning or ad-hoc adaptations to specific image generation tasks. In this work, we present MultiDiffusion, a unified framework that enables versatile and controllable image generation, using a pre-trained text-to-image diffusion model, without any further training or finetuning. At the center of our approach is a new generation process, based on an optimization task that binds together multiple diffusion generation processes with a shared set of parameters or constraints. We show that MultiDiffusion can be readily applied to generate high quality and diverse images that adhere to user-provided controls, such as desired aspect ratio (e.g., panorama), and spatial guiding signals, ranging from tight segmentation masks to bounding boxes. Project webpage: https://multidiffusion.github.io"
"Chenshuang Zhang, Chaoning Zhang, Mengchun Zhang, In-So Kweon",35ccd924de9e8483bdcf144cbf2edf09be157b7e,Text-to-image Diffusion Model in Generative AI: A Survey,ArXiv,2023,4,"This survey reviews text-to-image diffusion models in the context that diffusion models have emerged to be popular for a wide range of generative tasks. As a self-contained work, this survey starts with a brief introduction of how a basic diffusion model works for image synthesis, followed by how condition or guidance improves learning. Based on that, we present a review of state-of-the-art methods on text-conditioned image synthesis, i.e., text-to-image. We further summarize applications beyond text-to-image generation: text-guided creative generation and text-guided image editing. Beyond the progress made so far, we discuss existing challenges and promising future directions."
"Jiatao Gu, Alex Trevithick, Kai-En Lin, J. Susskind, C. Theobalt, Lingjie Liu, R. Ramamoorthi",a8efa7087fd6d84d5d84fd6c7c7cfb9d7ddb6dce,NerfDiff: Single-image View Synthesis with NeRF-guided Distillation from 3D-aware Diffusion,ArXiv,2023,3,"Novel view synthesis from a single image requires inferring occluded regions of objects and scenes whilst simultaneously maintaining semantic and physical consistency with the input. Existing approaches condition neural radiance fields (NeRF) on local image features, projecting points to the input image plane, and aggregating 2D features to perform volume rendering. However, under severe occlusion, this projection fails to resolve uncertainty, resulting in blurry renderings that lack details. In this work, we propose NerfDiff, which addresses this issue by distilling the knowledge of a 3D-aware conditional diffusion model (CDM) into NeRF through synthesizing and refining a set of virtual views at test time. We further propose a novel NeRF-guided distillation algorithm that simultaneously generates 3D consistent virtual views from the CDM samples, and finetunes the NeRF based on the improved virtual views. Our approach significantly outperforms existing NeRF-based and geometry-free approaches on challenging datasets, including ShapeNet, ABO, and Clevr3D."
"Mohamed Akrout, B'alint Gyepesi, P. Holló, A. Poór, Blága Kincso, Stephen Solis, Katrina D Cirone, J. Kawahara, Dekker Slade, Latif Abid, M'at'e Kov'acs, I. Fazekas",a69a61b81b31e16339df59cd125027522b11a775,Diffusion-based Data Augmentation for Skin Disease Classification: Impact Across Original Medical Datasets to Fully Synthetic Images,ArXiv,2023,3,"Despite continued advancement in recent years, deep neural networks still rely on large amounts of training data to avoid overfitting. However, labeled training data for real-world applications such as healthcare is limited and difficult to access given longstanding privacy, and strict data sharing policies. By manipulating image datasets in the pixel or feature space, existing data augmentation techniques represent one of the effective ways to improve the quantity and diversity of training data. Here, we look to advance augmentation techniques by building upon the emerging success of text-to-image diffusion probabilistic models in augmenting the training samples of our macroscopic skin disease dataset. We do so by enabling fine-grained control of the image generation process via input text prompts. We demonstrate that this generative data augmentation approach successfully maintains a similar classification accuracy of the visual classifier even when trained on a fully synthetic skin disease dataset. Similar to recent applications of generative models, our study suggests that diffusion models are indeed effective in generating high-quality skin images that do not sacrifice the classifier performance, and can improve the augmentation of training datasets after curation."
"M. Delbracio, P. Milanfar",1b0a5c650c4fbe9b038bf960fd1b2ee7854f99d7,Inversion by Direct Iteration: An Alternative to Denoising Diffusion for Image Restoration,ArXiv,2023,2,"Inversion by Direct Iteration (InDI) is a new formulation for supervised image restoration that avoids the so-called ``regression to the mean'' effect and produces more realistic and detailed images than existing regression-based methods. It does this by gradually improving image quality in small steps, similar to generative denoising diffusion models. Image restoration is an ill-posed problem where multiple high-quality images are plausible reconstructions of a given low-quality input. Therefore, the outcome of a single step regression model is typically an aggregate of all possible explanations, therefore lacking details and realism. The main advantage of InDI is that it does not try to predict the clean target image in a single step but instead gradually improves the image in small steps, resulting in better perceptual quality. While generative denoising diffusion models also work in small steps, our formulation is distinct in that it does not require knowledge of any analytic form of the degradation process. Instead, we directly learn an iterative restoration process from low-quality and high-quality paired examples. InDI can be applied to virtually any image degradation, given paired training data. In conditional denoising diffusion image restoration the denoising network generates the restored image by repeatedly denoising an initial image of pure noise, conditioned on the degraded input. Contrary to conditional denoising formulations, InDI directly proceeds by iteratively restoring the input low-quality image, producing high-quality results on a variety of image restoration tasks, including motion and out-of-focus deblurring, super-resolution, compression artifact removal, and denoising."
"Y. Ma, Huan Yang, Wenjing Wang, Jianlong Fu, Jiaying Liu",d4b0fa75565e873eea165e7059435bb55ddeb9ef,Unified Multi-Modal Latent Diffusion for Joint Subject and Text Conditional Image Generation,ArXiv,2023,2,"Language-guided image generation has achieved great success nowadays by using diffusion models. However, texts can be less detailed to describe highly-specific subjects such as a particular dog or a certain car, which makes pure text-to-image generation not accurate enough to satisfy user requirements. In this work, we present a novel Unified Multi-Modal Latent Diffusion (UMM-Diffusion) which takes joint texts and images containing specified subjects as input sequences and generates customized images with the subjects. To be more specific, both input texts and images are encoded into one unified multi-modal latent space, in which the input images are learned to be projected to pseudo word embedding and can be further combined with text to guide image generation. Besides, to eliminate the irrelevant parts of the input images such as background or illumination, we propose a novel sampling technique of diffusion models used by the image generator which fuses the results guided by multi-modal input and pure text input. By leveraging the large-scale pre-trained text-to-image generator and the designed image encoder, our method is able to generate high-quality images with complex semantics from both aspects of input texts and images."
"Jiarui Xu, Sifei Liu, Arash Vahdat, Wonmin Byeon, Xiaolong Wang, Shalini De Mello",323400245885e08ad498cd108e30e18020662278,Open-Vocabulary Panoptic Segmentation with Text-to-Image Diffusion Models,ArXiv,2023,2,"We present ODISE: Open-vocabulary DIffusion-based panoptic SEgmentation, which unifies pre-trained text-image diffusion and discriminative models to perform open-vocabulary panoptic segmentation. Text-to-image diffusion models have the remarkable ability to generate high-quality images with diverse open-vocabulary language descriptions. This demonstrates that their internal representation space is highly correlated with open concepts in the real world. Text-image discriminative models like CLIP, on the other hand, are good at classifying images into open-vocabulary labels. We leverage the frozen internal representations of both these models to perform panoptic segmentation of any category in the wild. Our approach outperforms the previous state of the art by significant margins on both open-vocabulary panoptic and semantic segmentation tasks. In particular, with COCO training only, our method achieves 23.4 PQ and 30.0 mIoU on the ADE20K dataset, with 8.3 PQ and 7.9 mIoU absolute improvement over the previous state of the art. We open-source our code and models at https://github.com/NVlabs/ODISE ."
"Duygu Ceylan, C. Huang, N. Mitra",32a3c2fbd3e733bd0eea938517fec2ff8dc7c701,Pix2Video: Video Editing using Image Diffusion,,2023,1,"Image diffusion models, trained on massive image collections, have emerged as the most versatile image generator model in terms of quality and diversity. They support inverting real images and conditional (e.g., text) generation, making them attractive for high-quality image editing applications. We investigate how to use such pre-trained image models for text-guided video editing. The critical challenge is to achieve the target edits while still preserving the content of the source video. Our method works in two simple steps: first, we use a pre-trained structure-guided (e.g., depth) image diffusion model to perform text-guided edits on an anchor frame; then, in the key step, we progressively propagate the changes to the future frames via self-attention feature injection to adapt the core denoising step of the diffusion model. We then consolidate the changes by adjusting the latent code for the frame before continuing the process. Our approach is training-free and generalizes to a wide range of edits. We demonstrate the effectiveness of the approach by extensive experimentation and compare it against four different prior and parallel efforts (on ArXiv). We demonstrate that realistic text-guided video edits are possible, without any compute-intensive preprocessing or video-specific finetuning."
"Levon Khachatryan, A. Movsisyan, Vahram Tadevosyan, Roberto Henschel, Zhangyang Wang, Shant Navasardyan, Humphrey Shi",923a03032014a12c4e8b26511c0394e1b915fe74,Text2Video-Zero: Text-to-Image Diffusion Models are Zero-Shot Video Generators,,2023,1,"Recent text-to-video generation approaches rely on computationally heavy training and require large-scale video datasets. In this paper, we introduce a new task of zero-shot text-to-video generation and propose a low-cost approach (without any training or optimization) by leveraging the power of existing text-to-image synthesis methods (e.g., Stable Diffusion), making them suitable for the video domain. Our key modifications include (i) enriching the latent codes of the generated frames with motion dynamics to keep the global scene and the background time consistent; and (ii) reprogramming frame-level self-attention using a new cross-frame attention of each frame on the first frame, to preserve the context, appearance, and identity of the foreground object. Experiments show that this leads to low overhead, yet high-quality and remarkably consistent video generation. Moreover, our approach is not limited to text-to-video synthesis but is also applicable to other tasks such as conditional and content-specialized video generation, and Video Instruct-Pix2Pix, i.e., instruction-guided video editing. As experiments show, our method performs comparably or sometimes better than recent approaches, despite not being trained on additional video data. Our code will be open sourced at: https://github.com/Picsart-AI-Research/Text2Video-Zero ."
"Felix Friedrich, P. Schramowski, Manuel Brack, Lukas Struppek, Dominik Hintersdorf, Sasha Luccioni, K. Kersting",3ea713d77e7d6e579a060a3751669958a253e42d,Fair Diffusion: Instructing Text-to-Image Generation Models on Fairness,ArXiv,2023,1,"Generative AI models have recently achieved astonishing results in quality and are consequently employed in a fast-growing number of applications. However, since they are highly data-driven, relying on billion-sized datasets randomly scraped from the internet, they also suffer from degenerated and biased human behavior, as we demonstrate. In fact, they may even reinforce such biases. To not only uncover but also combat these undesired effects, we present a novel strategy, called Fair Diffusion, to attenuate biases after the deployment of generative text-to-image models. Specifically, we demonstrate shifting a bias, based on human instructions, in any direction yielding arbitrarily new proportions for, e.g., identity groups. As our empirical evaluation demonstrates, this introduced control enables instructing generative image models on fairness, with no data filtering and additional training required."
"Kevin Clark, Priyank Jaini",206fbce3adb594516eedecca83c6e70118829805,Text-to-Image Diffusion Models are Zero-Shot Classifiers,,2023,1,"The excellent generative capabilities of text-to-image diffusion models suggest they learn informative representations of image-text data. However, what knowledge their representations capture is not fully understood, and they have not been thoroughly explored on downstream tasks. We investigate diffusion models by proposing a method for evaluating them as zero-shot classifiers. The key idea is using a diffusion model's ability to denoise a noised image given a text description of a label as a proxy for that label's likelihood. We apply our method to Imagen, using it to probe fine-grained aspects of Imagen's knowledge and comparing it with CLIP's zero-shot abilities. Imagen performs competitively with CLIP on a wide range of zero-shot image classification datasets. Additionally, it achieves state-of-the-art results on shape/texture bias tests and can successfully perform attribute binding while CLIP cannot. Although generative pre-training is prevalent in NLP, visual foundation models often use other methods such as contrastive learning. Based on our findings, we argue that generative pre-training should be explored as a compelling alternative for vision and vision-language problems."
"Shanghua Gao, Pan Zhou, Mingg-Ming Cheng, Shuicheng Yan",ca21f28e2a0a8205038301d8385151ab7ca2a050,Masked Diffusion Transformer is a Strong Image Synthesizer,,2023,1,"Despite its success in image synthesis, we observe that diffusion probabilistic models (DPMs) often lack contextual reasoning ability to learn the relations among object parts in an image, leading to a slow learning process. To solve this issue, we propose a Masked Diffusion Transformer (MDT) that introduces a mask latent modeling scheme to explicitly enhance the DPMs' ability of contextual relation learning among object semantic parts in an image. During training, MDT operates on the latent space to mask certain tokens. Then, an asymmetric masking diffusion transformer is designed to predict masked tokens from unmasked ones while maintaining the diffusion generation process. Our MDT can reconstruct the full information of an image from its incomplete contextual input, thus enabling it to learn the associated relations among image tokens. Experimental results show that MDT achieves superior image synthesis performance, e.g. a new SoTA FID score on the ImageNet dataset, and has about 3x faster learning speed than the previous SoTA DiT. The source code is released at https://github.com/sail-sg/MDT."
"Binxu Wang, John J. Vastola",3392075cfa2ff1a73c0637b685f6270b1d219304,"Diffusion Models Generate Images Like Painters: an Analytical Theory of Outline First, Details Later",ArXiv,2023,1,"How do diffusion generative models convert pure noise into meaningful images? We argue that generation involves first committing to an outline, and then to finer and finer details. The corresponding reverse diffusion process can be modeled by dynamics on a (time-dependent) high-dimensional landscape full of Gaussian-like modes, which makes the following predictions: (i) individual trajectories tend to be very low-dimensional; (ii) scene elements that vary more within training data tend to emerge earlier; and (iii) early perturbations substantially change image content more often than late perturbations. We show that the behavior of a variety of trained unconditional and conditional diffusion models like Stable Diffusion is consistent with these predictions. Finally, we use our theory to search for the latent image manifold of diffusion models, and propose a new way to generate interpretable image variations. Our viewpoint suggests generation by GANs and diffusion models have unexpected similarities."
"Ziyi Li, Qinye Zhou, Xiaoyun Zhang, Ya Zhang, Yanfeng Wang, Weidi Xie",6dfcd4c74eed69efe582fabc239ad0d92a74d5fe,Guiding Text-to-Image Diffusion Model Towards Grounded Generation,ArXiv,2023,1,"The goal of this paper is to augment a pre-trained text-to-image diffusion model with the ability of open-vocabulary objects grounding, i.e., simultaneously generating images and segmentation masks for the corresponding visual entities described in the text prompt. We make the following contributions: (i) we insert a grounding module into the existing diffusion model, that can be trained to align the visual and textual embedding space of the diffusion model with only a small number of object categories; (ii) we propose an automatic pipeline for constructing a dataset, that consists of {image, segmentation mask, text prompt} triplets, to train the proposed grounding module; (iii) we evaluate the performance of open-vocabulary grounding on images generated from the text-to-image diffusion model and show that the module can well segment the objects of categories beyond seen ones at training time; (iv) we adopt the guided diffusion model to build a synthetic semantic segmentation dataset, and show that training a standard segmentation model on such dataset demonstrates competitive performance on zero-shot segmentation(ZS3) benchmark, which opens up new opportunities for adopting the powerful diffusion model for discriminative tasks."
"Hadas Orgad, Bahjat Kawar, Yonatan Belinkov",3e119b9bb4693e8cd8bd6072123f1783c9253eb4,Editing Implicit Assumptions in Text-to-Image Diffusion Models,ArXiv,2023,1,"Text-to-image diffusion models often make implicit assumptions about the world when generating images. While some assumptions are useful (e.g., the sky is blue), they can also be outdated, incorrect, or reflective of social biases present in the training data. Thus, there is a need to control these assumptions without requiring explicit user input or costly re-training. In this work, we aim to edit a given implicit assumption in a pre-trained diffusion model. Our Text-to-Image Model Editing method, TIME for short, receives a pair of inputs: a""source""under-specified prompt for which the model makes an implicit assumption (e.g.,""a pack of roses""), and a""destination""prompt that describes the same setting, but with a specified desired attribute (e.g.,""a pack of blue roses""). TIME then updates the model's cross-attention layers, as these layers assign visual meaning to textual tokens. We edit the projection matrices in these layers such that the source prompt is projected close to the destination prompt. Our method is highly efficient, as it modifies a mere 2.2% of the model's parameters in under one second. To evaluate model editing approaches, we introduce TIMED (TIME Dataset), containing 147 source and destination prompt pairs from various domains. Our experiments (using Stable Diffusion) show that TIME is successful in model editing, generalizes well for related prompts unseen during editing, and imposes minimal effect on unrelated generations."
"Cusuh Ham, James Hays, Jingwan Lu, Krishna Kumar Singh, Zhifei Zhang, T. Hinz",76d841195aaca949483fcd482ec82d4efd192fb0,Modulating Pretrained Diffusion Models for Multimodal Image Synthesis,ArXiv,2023,1,"We present multimodal conditioning modules (MCM) for enabling conditional image synthesis using pretrained diffusion models. Previous multimodal synthesis works rely on training networks from scratch or fine-tuning pretrained networks, both of which are computationally expensive for large, state-of-the-art diffusion models. Our method uses pretrained networks but does not require any updates to the diffusion network's parameters. MCM is a small module trained to modulate the diffusion network's predictions during sampling using 2D modalities (e.g., semantic segmentation maps, sketches) that were unseen during the original training of the diffusion model. We show that MCM enables user control over the spatial layout of the image and leads to increased control over the image generation process. Training MCM is cheap as it does not require gradients from the original diffusion net, consists of only $\sim$1$\%$ of the number of parameters of the base diffusion model, and is trained using only a limited number of training examples. We evaluate our method on unconditional and text-conditional models to demonstrate the improved control over the generated images and their alignment with respect to the conditioning inputs."
"Paul Hagemann, Lars Ruthotto, G. Steidl, Ni Yang",8ceb063f10c8cd8f516e07ce50cc734bdfd64bd9,Multilevel Diffusion: Infinite Dimensional Score-Based Diffusion Models for Image Generation,ArXiv,2023,1,"Score-based diffusion models (SBDM) have recently emerged as state-of-the-art approaches for image generation. Existing SBDMs are typically formulated in a finite-dimensional setting, where images are considered as tensors of a finite size. This papers develops SBDMs in the infinite-dimensional setting, that is, we model the training data as functions supported on a rectangular domain. Besides the quest for generating images at ever higher resolution our primary motivation is to create a well-posed infinite-dimensional learning problem so that we can discretize it consistently on multiple resolution levels. We thereby hope to obtain diffusion models that generalize across different resolution levels and improve the efficiency of the training process. We demonstrate how to overcome two shortcomings of current SBDM approaches in the infinite-dimensional setting. First, we modify the forward process to ensure that the latent distribution is well-defined in the infinite-dimensional setting using the notion of trace class operators. Second, we illustrate that approximating the score function with an operator network, in our case Fourier neural operators (FNOs), is beneficial for multilevel training. After deriving the forward and reverse process in the infinite-dimensional setting, we show their well-posedness, derive adequate discretizations, and investigate the role of the latent distributions. We provide first promising numerical results on two datasets, MNIST and material structures. In particular, we show that multilevel training is feasible within this framework."
"Shaheer U. Saeed, T. Syer, Wen Yan, Qianye Yang, M. Emberton, S. Punwani, M. Clarkson, D. Barratt, Yipeng Hu",2e1bc6ff3786e2415fad10b008d643dd795dc548,Bi-parametric prostate MR image synthesis using pathology and sequence-conditioned stable diffusion,ArXiv,2023,1,"We propose an image synthesis mechanism for multi-sequence prostate MR images conditioned on text, to control lesion presence and sequence, as well as to generate paired bi-parametric images conditioned on images e.g. for generating diffusion-weighted MR from T2-weighted MR for paired data, which are two challenging tasks in pathological image synthesis. Our proposed mechanism utilises and builds upon the recent stable diffusion model by proposing image-based conditioning for paired data generation. We validate our method using 2D image slices from real suspected prostate cancer patients. The realism of the synthesised images is validated by means of a blind expert evaluation for identifying real versus fake images, where a radiologist with 4 years experience reading urological MR only achieves 59.4% accuracy across all tested sequences (where chance is 50%). For the first time, we evaluate the realism of the generated pathology by blind expert identification of the presence of suspected lesions, where we find that the clinician performs similarly for both real and synthesised images, with a 2.9 percentage point difference in lesion identification accuracy between real and synthesised images, demonstrating the potentials in radiological training purposes. Furthermore, we also show that a machine learning model, trained for lesion identification, shows better performance (76.2% vs 70.4%, statistically significant improvement) when trained with real data augmented by synthesised data as opposed to training with only real images, demonstrating usefulness for model training."
"Pranav Aggarwal, Hareesh Ravi, Naveen Marri, Sachin Kelkar, F. Chen, V. Khuc, Midhun Harikumar, Ritiz Tambi, Sudharshan Reddy Kakumanu, Purvak Lapsiya, Alvin Ghouas, Sarah Saber, Malavika Ramprasad, Baldo Faieta, Ajinkya Kale",6d0100a6d8e3be6f51f80e1668870acb00f6fa32,Controlled and Conditional Text to Image Generation with Diffusion Prior,ArXiv,2023,1,"Denoising Diffusion models have shown remarkable performance in generating diverse, high quality images from text. Numerous techniques have been proposed on top of or in alignment with models like Stable Diffusion and Imagen that generate images directly from text. A lesser explored approach is DALLE-2's two step process comprising a Diffusion Prior that generates a CLIP image embedding from text and a Diffusion Decoder that generates an image from a CLIP image embedding. We explore the capabilities of the Diffusion Prior and the advantages of an intermediate CLIP representation. We observe that Diffusion Prior can be used in a memory and compute efficient way to constrain the generation to a specific domain without altering the larger Diffusion Decoder. Moreover, we show that the Diffusion Prior can be trained with additional conditional information such as color histogram to further control the generation. We show quantitatively and qualitatively that the proposed approaches perform better than prompt engineering for domain specific generation and existing baselines for color conditioned generation. We believe that our observations and results will instigate further research into the diffusion prior and uncover more of its capabilities."
"Zhangxing Bian, Muhan Shao, J. Zhuo, R. Gullapalli, A. Carass, Jerry L Prince",5e51dd50304aaa7ad22eac88a97140186a2a055f,FastCod: Fast Brain Connectivity in Diffusion Imaging,,2023,1,"Connectivity information derived from diffusion-weighted magnetic resonance images~(DW-MRIs) plays an important role in studying human subcortical gray matter structures. However, due to the $O(N^2)$ complexity of computing the connectivity of each voxel to every other voxel (or multiple ROIs), the current practice of extracting connectivity information is highly inefficient. This makes the processing of high-resolution images and population-level analyses very computationally demanding. To address this issue, we propose a more efficient way to extract connectivity information; briefly, we consider two regions/voxels to be connected if a white matter fiber streamline passes through them -- no matter where the streamline originates. We consider the thalamus parcellation task for demonstration purposes; our experiments show that our approach brings a 30 to 120 times speedup over traditional approaches with comparable qualitative parcellation results. We also demonstrate high-resolution connectivity features can be super-resolved from low-resolution DW-MRI in our framework. Together, these two innovations enable higher resolution connectivity analysis from DW-MRI. Our source code is availible at jasonbian97.github.io/fastcod."
"Hshmat Sahak, Daniel Watson, Chitwan Saharia, David J. Fleet",7d5c60dcd838c62b3c3697745bef07ed824d41d3,Denoising Diffusion Probabilistic Models for Robust Image Super-Resolution in the Wild,ArXiv,2023,1,"Diffusion models have shown promising results on single-image super-resolution and other image- to-image translation tasks. Despite this success, they have not outperformed state-of-the-art GAN models on the more challenging blind super-resolution task, where the input images are out of distribution, with unknown degradations. This paper introduces SR3+, a diffusion-based model for blind super-resolution, establishing a new state-of-the-art. To this end, we advocate self-supervised training with a combination of composite, parameterized degradations for self-supervised training, and noise-conditioing augmentation during training and testing. With these innovations, a large-scale convolutional architecture, and large-scale datasets, SR3+ greatly outperforms SR3. It outperforms Real-ESRGAN when trained on the same data, with a DRealSR FID score of 36.82 vs. 37.22, which further improves to FID of 32.37 with larger models, and further still with larger training sets."
"Axi Niu, Kang Zhang, T. Pham, Jinqiu Sun, Yu Zhu, In-So Kweon, Yanning Zhang",a3cecb2f7e9c6677a2b4ad8db78f10f3bf601b38,CDPMSR: Conditional Diffusion Probabilistic Models for Single Image Super-Resolution,ArXiv,2023,1,"Diffusion probabilistic models (DPM) have been widely adopted in image-to-image translation to generate high-quality images. Prior attempts at applying the DPM to image super-resolution (SR) have shown that iteratively refining a pure Gaussian noise with a conditional image using a U-Net trained on denoising at various-level noises can help obtain a satisfied high-resolution image for the low-resolution one. To further improve the performance and simplify current DPM-based super-resolution methods, we propose a simple but non-trivial DPM-based super-resolution post-process framework,i.e., cDPMSR. After applying a pre-trained SR model on the to-be-test LR image to provide the conditional input, we adapt the standard DPM to conduct conditional image generation and perform super-resolution through a deterministic iterative denoising process. Our method surpasses prior attempts on both qualitative and quantitative results and can generate more photo-realistic counterparts for the low-resolution images with various benchmark datasets including Set5, Set14, Urban100, BSD100, and Manga109. Code will be published after accepted."
"Yichen Peng, Chunqi Zhao, Haoran Xie, Tsukasa Fukusato, K. Miyata",d3d9d2f6fd6c9f0689d3c64373b70dbf94e6b488,DiffFaceSketch: High-Fidelity Face Image Synthesis with Sketch-Guided Latent Diffusion Model,ArXiv,2023,1,"Synthesizing face images from monochrome sketches is one of the most fundamental tasks in the field of image-to-image translation. However, it is still challenging to (1)~make models learn the high-dimensional face features such as geometry and color, and (2)~take into account the characteristics of input sketches. Existing methods often use sketches as indirect inputs (or as auxiliary inputs) to guide the models, resulting in the loss of sketch features or the alteration of geometry information. In this paper, we introduce a Sketch-Guided Latent Diffusion Model (SGLDM), an LDM-based network architect trained on the paired sketch-face dataset. We apply a Multi-Auto-Encoder (AE) to encode the different input sketches from different regions of a face from pixel space to a feature map in latent space, which enables us to reduce the dimension of the sketch input while preserving the geometry-related information of local face details. We build a sketch-face paired dataset based on the existing method that extracts the edge map from an image. We then introduce a Stochastic Region Abstraction (SRA), an approach to augment our dataset to improve the robustness of SGLDM to handle sketch input with arbitrary abstraction. The evaluation study shows that SGLDM can synthesize high-quality face images with different expressions, facial accessories, and hairstyles from various sketches with different abstraction levels."
Á. Jiménez,e6376edb31bf224c0223b48442b3fef4bb1a30f4,Mixture of Diffusers for scene composition and high resolution image generation,ArXiv,2023,1,"Diffusion methods have been proven to be very effective to generate images while conditioning on a text prompt. However, and although the quality of the generated images is unprecedented, these methods seem to struggle when trying to generate specific image compositions. In this paper we present Mixture of Diffusers, an algorithm that builds over existing diffusion models to provide a more detailed control over composition. By harmonizing several diffusion processes acting on different regions of a canvas, it allows generating larger images, where the location of each object and style is controlled by a separate diffusion process."
"Junde Wu, Rao Fu, Huihui Fang, Yu Zhang, Yanwu Xu",3f77a62ae888c3b816eabd354a6dd0fc6b9528ea,MedSegDiff-V2: Diffusion based Medical Image Segmentation with Transformer,ArXiv,2023,1,"The Diffusion Probabilistic Model (DPM) has recently gained popularity in the field of computer vision, thanks to its image generation applications, such as Imagen, Latent Diffusion Models, and Stable Diffusion, which have demonstrated impressive capabilities and sparked much discussion within the community. Recent studies have also found DPM to be useful in the field of medical image analysis, as evidenced by the strong performance of the medical image segmentation model MedSegDiff in various tasks. While these models were originally designed with a UNet backbone, they may also potentially benefit from the incorporation of vision transformer techniques. However, we discovered that simply combining these two approaches resulted in subpar performance. In this paper, we propose a novel transformer-based conditional UNet framework, as well as a new Spectrum-Space Transformer (SS-Former) to model the interaction between noise and semantic features. This architectural improvement leads to a new diffusion-based medical image segmentation method called MedSegDiff-V2, which significantly improves the performance of MedSegDiff. We have verified the effectiveness of MedSegDiff-V2 on eighteen organs of five segmentation datasets with different image modalities. Our experimental results demonstrate that MedSegDiff-V2 outperforms state-of-the-art (SOTA) methods by a considerable margin, further proving the generalizability and effectiveness of the proposed model."
,90e4ebaa16df6ead9c34e31d0621aae4e5739ce2,Taming Encoder for Zero Fine-tuning Image Customization with Text-to-Image Diffusion Models,,2023,0,"This paper proposes a method for generating images of customized objects specified by users. The method is based on a general framework that bypasses the lengthy optimization required by previous approaches, which often employ a per-object optimization paradigm. Our framework adopts an encoder to capture high-level identifiable semantics of objects, producing an object-specific embedding with only a single feed-forward pass. The acquired object embedding is then passed to a text-to-image synthesis model for subsequent generation. To effectively blend a object-aware embedding space into a well developed text-to-image model under the same generation context, we investigate different network designs and training strategies, and propose a simple yet effective regularized joint training scheme with an object identity preservation loss. Additionally, we propose a caption generation scheme that become a critical piece in fostering object specific embedding faithfully reflected into the generation process, while keeping control and editing abilities. Once trained, the network is able to produce diverse content and styles, conditioned on both texts and objects. We demonstrate through experiments that our proposed method is able to synthesize images with compelling output quality, appearance diversity, and object fidelity, without the need of test-time optimization. Systematic studies are also conducted to analyze our models, providing insights for future work."
,710d86a4354df14c30458d92a4fbc4808e097afc,A Diffusion-based Method for Multi-turn Compositional Image Generation,,2023,0,"Multi-turn compositional image generation (M-CIG) is a challenging task that aims to iteratively manipulate a reference image given a modification text. While most of the existing methods for M-CIG are based on generative adversarial networks (GANs), recent advances in image generation have demonstrated the superiority of diffusion models over GANs. In this paper, we propose a diffusion-based method for M-CIG named conditional denoising diffusion with image compositional matching (CDD-ICM). We leverage CLIP as the backbone of image and text encoders, and incorporate a gated fusion mechanism, originally proposed for question answering, to compositionally fuse the reference image and the modification text at each turn of M-CIG. We introduce a conditioning scheme to generate the target image based on the fusion results. To prioritize the semantic quality of the generated target image, we learn an auxiliary image compositional match (ICM) objective, along with the conditional denoising diffusion (CDD) objective in a multi-task learning framework. Additionally, we also perform ICM guidance and classifier-free guidance to improve performance. Experimental results show that CDD-ICM achieves state-of-the-art results on two benchmark datasets for M-CIG, i.e., CoDraw and i-CLEVR."
,d24c5ae008fed22f01ead9f2de1e9feea743d2c1,Multimodal Garment Designer: Human-Centric Latent Diffusion Models for Fashion Image Editing,,2023,0,"Fashion illustration is used by designers to communicate their vision and to bring the design idea from conceptualization to realization, showing how clothes interact with the human body. In this context, computer vision can thus be used to improve the fashion design process. Differently from previous works that mainly focused on the virtual try-on of garments, we propose the task of multimodal-conditioned fashion image editing, guiding the generation of human-centric fashion images by following multimodal prompts, such as text, human body poses, and garment sketches. We tackle this problem by proposing a new architecture based on latent diffusion models, an approach that has not been used before in the fashion domain. Given the lack of existing datasets suitable for the task, we also extend two existing fashion datasets, namely Dress Code and VITON-HD, with multimodal annotations collected in a semi-automatic manner. Experimental results on these new datasets demonstrate the effectiveness of our proposal, both in terms of realism and coherence with the given multimodal inputs. Source code and collected multimodal annotations will be publicly released at: https://github.com/aimagelab/multimodal-garment-designer."
,f313ddb445c003b795e812d898743cf9e50e703f,Waving Goodbye to Low-Res: A Diffusion-Wavelet Approach for Image Super-Resolution,,2023,0,"This paper presents a novel Diffusion-Wavelet (DiWa) approach for Single-Image Super-Resolution (SISR). It leverages the strengths of Denoising Diffusion Probabilistic Models (DDPMs) and Discrete Wavelet Transformation (DWT). By enabling DDPMs to operate in the DWT domain, our DDPM models effectively hallucinate high-frequency information for super-resolved images on the wavelet spectrum, resulting in high-quality and detailed reconstructions in image space. Quantitatively, we outperform state-of-the-art diffusion-based SISR methods, namely SR3 and SRDiff, regarding PSNR, SSIM, and LPIPS on both face (8x scaling) and general (4x scaling) SR benchmarks. Meanwhile, using DWT enabled us to use fewer parameters than the compared models: 92M parameters instead of 550M compared to SR3 and 9.3M instead of 12M compared to SRDiff. Additionally, our method outperforms other state-of-the-art generative methods on classical general SR datasets while saving inference time. Finally, our work highlights its potential for various applications."
,177304f625352974689f39cd3bfb06b181268a0f,PODIA-3D: Domain Adaptation of 3D Generative Model Across Large Domain Gap Using Pose-Preserved Text-to-Image Diffusion,,2023,0,"Recently, significant advancements have been made in 3D generative models, however training these models across diverse domains is challenging and requires an huge amount of training data and knowledge of pose distribution. Text-guided domain adaptation methods have allowed the generator to be adapted to the target domains using text prompts, thereby obviating the need for assembling numerous data. Recently, DATID-3D presents impressive quality of samples in text-guided domain, preserving diversity in text by leveraging text-to-image diffusion. However, adapting 3D generators to domains with significant domain gaps from the source domain still remains challenging due to issues in current text-to-image diffusion models as following: 1) shape-pose trade-off in diffusion-based translation, 2) pose bias, and 3) instance bias in the target domain, resulting in inferior 3D shapes, low text-image correspondence, and low intra-domain diversity in the generated samples. To address these issues, we propose a novel pipeline called PODIA-3D, which uses pose-preserved text-to-image diffusion-based domain adaptation for 3D generative models. We construct a pose-preserved text-to-image diffusion model that allows the use of extremely high-level noise for significant domain changes. We also propose specialized-to-general sampling strategies to improve the details of the generated samples. Moreover, to overcome the instance bias, we introduce a text-guided debiasing method that improves intra-domain diversity. Consequently, our method successfully adapts 3D generators across significant domain gaps. Our qualitative results and user study demonstrates that our approach outperforms existing 3D text-guided domain adaptation methods in terms of text-image correspondence, realism, diversity of rendered images, and sense of depth of 3D shapes in the generated samples"
,e4372b07702014056f99750db2e6c7338c8ac797,Quantitative perfusion and water transport time model from multi b-value diffusion magnetic resonance imaging validated against neutron capture microspheres,,2023,0,"Intravoxel Incoherent Motion (IVIM) is a non-contrast magnetic resonance imaging diffusion-based scan that uses a multitude of b-values to measure various speeds of molecular perfusion and diffusion, sidestepping inaccuracy of arterial input functions or bolus kinetics in quantitative imaging. We test a new method of IVIM quantification and compare our values to reference standard neutron capture microspheres across normocapnia, CO2 induced hypercapnia, and middle cerebral artery occlusion in a controlled animal model. Perfusion quantification in ml/100g/min compared to microsphere perfusion uses the 3D gaussian probability distribution and defined water transport time as when 50% of the molecules remain in the tissue of interest. Perfusion, water transport time, and infarct volume was compared to reference standards. Simulations were studied to suppress non-specific cerebrospinal fluid (CSF). Linear regression analysis of quantitative perfusion returned correlation (slope = .55, intercept = 52.5, $R^2$= .64). Linear regression for water transport time asymmetry in infarcted tissue was excellent (slope = .59, intercept = .3, $R^2$ = .93). Strong linear agreement also was found for infarct volume (slope = 1.01, $R^2$= .79). Simulation of CSF suppression via inversion recovery returned blood signal reduced by 82% from combined T1 and T2 effects. Intra-physiologic state comparison of perfusion shows potential partial volume effects which require further study especially in disease states. The accuracy and sensitivity of IVIM provides evidence that observed signal changes reflect cytotoxic edema and tissue perfusion. Partial volume contamination of CSF may be better removed during post-processing rather than with inversion recovery to avoid artificial loss of blood signal."
,5549dc3ceff07561d9fb59610c0f78c71617901a,Generative Diffusion Prior for Unified Image Restoration and Enhancement,,2023,0,"Existing image restoration methods mostly leverage the posterior distribution of natural images. However, they often assume known degradation and also require supervised training, which restricts their adaptation to complex real applications. In this work, we propose the Generative Diffusion Prior (GDP) to effectively model the posterior distributions in an unsupervised sampling manner. GDP utilizes a pre-train denoising diffusion generative model (DDPM) for solving linear inverse, non-linear, or blind problems. Specifically, GDP systematically explores a protocol of conditional guidance, which is verified more practical than the commonly used guidance way. Furthermore, GDP is strength at optimizing the parameters of degradation model during the denoising process, achieving blind image restoration. Besides, we devise hierarchical guidance and patch-based methods, enabling the GDP to generate images of arbitrary resolutions. Experimentally, we demonstrate GDP's versatility on several image datasets for linear problems, such as super-resolution, deblurring, inpainting, and colorization, as well as non-linear and blind issues, such as low-light enhancement and HDR image recovery. GDP outperforms the current leading unsupervised methods on the diverse benchmarks in reconstruction quality and perceptual quality. Moreover, GDP also generalizes well for natural images or synthesized images with arbitrary sizes from various tasks out of the distribution of the ImageNet training set."
,da43f32f274794f65443e92283e4eb77fdb3635e,ViT-DAE: Transformer-driven Diffusion Autoencoder for Histopathology Image Analysis,,2023,0,"Generative AI has received substantial attention in recent years due to its ability to synthesize data that closely resembles the original data source. While Generative Adversarial Networks (GANs) have provided innovative approaches for histopathological image analysis, they suffer from limitations such as mode collapse and overfitting in discriminator. Recently, Denoising Diffusion models have demonstrated promising results in computer vision. These models exhibit superior stability during training, better distribution coverage, and produce high-quality diverse images. Additionally, they display a high degree of resilience to noise and perturbations, making them well-suited for use in digital pathology, where images commonly contain artifacts and exhibit significant variations in staining. In this paper, we present a novel approach, namely ViT-DAE, which integrates vision transformers (ViT) and diffusion autoencoders for high-quality histopathology image synthesis. This marks the first time that ViT has been introduced to diffusion autoencoders in computational pathology, allowing the model to better capture the complex and intricate details of histopathology images. We demonstrate the effectiveness of ViT-DAE on three publicly available datasets. Our approach outperforms recent GAN-based and vanilla DAE methods in generating realistic images."
,8e1ad8e0f4b86db4ac986f1c493d4ae673b63fed,3D-aware Image Generation using 2D Diffusion Models,,2023,0,"In this paper, we introduce a novel 3D-aware image generation method that leverages 2D diffusion models. We formulate the 3D-aware image generation task as multiview 2D image set generation, and further to a sequential unconditional-conditional multiview image generation process. This allows us to utilize 2D diffusion models to boost the generative modeling power of the method. Additionally, we incorporate depth information from monocular depth estimators to construct the training data for the conditional diffusion model using only still images. We train our method on a large-scale dataset, i.e., ImageNet, which is not addressed by previous methods. It produces high-quality images that significantly outperform prior methods. Furthermore, our approach showcases its capability to generate instances with large view angles, even though the training images are diverse and unaligned, gathered from""in-the-wild""real-world environments."
"Wen Wang, Kangyang Xie, Zide Liu, Hao Chen, Yue Cao, Xinlong Wang, Chunhua Shen",b3c032ac14a8a2e24df1d76a397739eb2b02aaf2,Zero-Shot Video Editing Using Off-The-Shelf Image Diffusion Models,,2023,0,"Large-scale text-to-image diffusion models achieve unprecedented success in image generation and editing. However, how to extend such success to video editing is unclear. Recent initial attempts at video editing require significant text-to-video data and computation resources for training, which is often not accessible. In this work, we propose vid2vid-zero, a simple yet effective method for zero-shot video editing. Our vid2vid-zero leverages off-the-shelf image diffusion models, and doesn't require training on any video. At the core of our method is a null-text inversion module for text-to-video alignment, a cross-frame modeling module for temporal consistency, and a spatial regularization module for fidelity to the original video. Without any training, we leverage the dynamic nature of the attention mechanism to enable bi-directional temporal modeling at test time. Experiments and analyses show promising results in editing attributes, subjects, places, etc., in real-world videos. Code will be made available at \url{https://github.com/baaivision/vid2vid-zero}."
"Eric Zhang, Kai Wang, Xingqian Xu, Zhangyang Wang, Humphrey Shi",d9b95937934d7291b7c253b28b6c9aaee033c91d,Forget-Me-Not: Learning to Forget in Text-to-Image Diffusion Models,,2023,0,"The unlearning problem of deep learning models, once primarily an academic concern, has become a prevalent issue in the industry. The significant advances in text-to-image generation techniques have prompted global discussions on privacy, copyright, and safety, as numerous unauthorized personal IDs, content, artistic creations, and potentially harmful materials have been learned by these models and later utilized to generate and distribute uncontrolled content. To address this challenge, we propose \textbf{Forget-Me-Not}, an efficient and low-cost solution designed to safely remove specified IDs, objects, or styles from a well-configured text-to-image model in as little as 30 seconds, without impairing its ability to generate other content. Alongside our method, we introduce the \textbf{Memorization Score (M-Score)} and \textbf{ConceptBench} to measure the models' capacity to generate general concepts, grouped into three primary categories: ID, object, and style. Using M-Score and ConceptBench, we demonstrate that Forget-Me-Not can effectively eliminate targeted concepts while maintaining the model's performance on other concepts. Furthermore, Forget-Me-Not offers two practical extensions: a) removal of potentially harmful or NSFW content, and b) enhancement of model accuracy, inclusion and diversity through \textbf{concept correction and disentanglement}. It can also be adapted as a lightweight model patch for Stable Diffusion, allowing for concept manipulation and convenient distribution. To encourage future research in this critical area and promote the development of safe and inclusive generative models, we will open-source our code and ConceptBench at \href{https://github.com/SHI-Labs/Forget-Me-Not}{https://github.com/SHI-Labs/Forget-Me-Not}."
"Vidit Goel, Elia Peruzzo, Yifan Jiang, Dejia Xu, Nicu Sebe, Trevor Darrell, Zhangyang Wang, Humphrey Shi",a31a6dc544174e83f6bd55fcc648e2c693f995a9,PAIR-Diffusion: Object-Level Image Editing with Structure-and-Appearance Paired Diffusion Models,,2023,0,"Image editing using diffusion models has witnessed extremely fast-paced growth recently. There are various ways in which previous works enable controlling and editing images. Some works use high-level conditioning such as text, while others use low-level conditioning. Nevertheless, most of them lack fine-grained control over the properties of the different objects present in the image, i.e. object-level image editing. In this work, we consider an image as a composition of multiple objects, each defined by various properties. Out of these properties, we identify structure and appearance as the most intuitive to understand and useful for editing purposes. We propose Structure-and-Appearance Paired Diffusion model (PAIR-Diffusion), which is trained using structure and appearance information explicitly extracted from the images. The proposed model enables users to inject a reference image's appearance into the input image at both the object and global levels. Additionally, PAIR-Diffusion allows editing the structure while maintaining the style of individual components of the image unchanged. We extensively evaluate our method on LSUN datasets and the CelebA-HQ face dataset, and we demonstrate fine-grained control over both structure and appearance at the object level. We also applied the method to Stable Diffusion to edit any real image at the object level."
"Guangcong Zheng, Xianpan Zhou, Xuewei Li, Zhongang Qi, Ying Shan, Xi Li",1fe4628388d9e3bc8d4ab0d4cefc6316739af202,LayoutDiffusion: Controllable Diffusion Model for Layout-to-image Generation,,2023,0,"Recently, diffusion models have achieved great success in image synthesis. However, when it comes to the layout-to-image generation where an image often has a complex scene of multiple objects, how to make strong control over both the global layout map and each detailed object remains a challenging task. In this paper, we propose a diffusion model named LayoutDiffusion that can obtain higher generation quality and greater controllability than the previous works. To overcome the difficult multimodal fusion of image and layout, we propose to construct a structural image patch with region information and transform the patched image into a special layout to fuse with the normal layout in a unified form. Moreover, Layout Fusion Module (LFM) and Object-aware Cross Attention (OaCA) are proposed to model the relationship among multiple objects and designed to be object-aware and position-sensitive, allowing for precisely controlling the spatial related information. Extensive experiments show that our LayoutDiffusion outperforms the previous SOTA methods on FID, CAS by relatively 46.35%, 26.70% on COCO-stuff and 44.29%, 41.82% on VG. Code is available at https://github.com/ZGCTroy/LayoutDiffusion."
"Idan Schwartz, V'esteinn Snaebjarnarson, Sagie Benaim, Hila Chefer, Ryan Cotterell, Lior Wolf, Serge Belongie",71005b6606250ae79d70ddc68a557d63eb886cdd,Discriminative Class Tokens for Text-to-Image Diffusion Models,,2023,0,"Recent advances in text-to-image diffusion models have enabled the generation of diverse and high-quality images. However, generated images often fall short of depicting subtle details and are susceptible to errors due to ambiguity in the input text. One way of alleviating these issues is to train diffusion models on class-labeled datasets. This comes with a downside, doing so limits their expressive power: (i) supervised datasets are generally small compared to large-scale scraped text-image datasets on which text-to-image models are trained, and so the quality and diversity of generated images are severely affected, or (ii) the input is a hard-coded label, as opposed to free-form text, which limits the control over the generated images. In this work, we propose a non-invasive fine-tuning technique that capitalizes on the expressive potential of free-form text while achieving high accuracy through discriminative signals from a pretrained classifier, which guides the generation. This is done by iteratively modifying the embedding of a single input token of a text-to-image diffusion model, using the classifier, by steering generated images toward a given target class. Our method is fast compared to prior fine-tuning methods and does not require a collection of in-class images or retraining of a noise-tolerant classifier. We evaluate our method extensively, showing that the generated images are: (i) more accurate and of higher quality than standard diffusion models, (ii) can be used to augment training data in a low-resource setting, and (iii) reveal information about the data used to train the guiding classifier. The code is available at \url{https://github.com/idansc/discriminative_class_tokens}"
"Qian Wang, Biao Zhang, Michael Birsak, Peter Wonka",cea059ebc8cddb672488162f67c7e337018288cc,MDP: A Generalized Framework for Text-Guided Image Editing by Manipulating the Diffusion Path,,2023,0,"Image generation using diffusion can be controlled in multiple ways. In this paper, we systematically analyze the equations of modern generative diffusion networks to propose a framework, called MDP, that explains the design space of suitable manipulations. We identify 5 different manipulations, including intermediate latent, conditional embedding, cross attention maps, guidance, and predicted noise. We analyze the corresponding parameters of these manipulations and the manipulation schedule. We show that some previous editing methods fit nicely into our framework. Particularly, we identified one specific configuration as a new type of control by manipulating the predicted noise, which can perform higher-quality edits than previous work for a variety of local and global edits."
"Animesh Karnewar, Andrea Vedaldi, David Novotny, Niloy Mitra",f7f3a93ae00407bab56f12787ba75550d59a2788,HOLODIFFUSION: Training a 3D Diffusion Model using 2D Images,,2023,0,"Diffusion models have emerged as the best approach for generative modeling of 2D images. Part of their success is due to the possibility of training them on millions if not billions of images with a stable learning objective. However, extending these models to 3D remains difficult for two reasons. First, finding a large quantity of 3D training data is much more complex than for 2D images. Second, while it is conceptually trivial to extend the models to operate on 3D rather than 2D grids, the associated cubic growth in memory and compute complexity makes this infeasible. We address the first challenge by introducing a new diffusion setup that can be trained, end-to-end, with only posed 2D images for supervision; and the second challenge by proposing an image formation model that decouples model memory from spatial memory. We evaluate our method on real-world data, using the CO3D dataset which has not been used to train 3D generative models before. We show that our diffusion models are scalable, train robustly, and are competitive in terms of sample quality and fidelity to existing approaches for 3D generative modeling."
"R'emy Gardier, Juan Luis Villarreal Haro, Erick J. Canales-Rodriguez, Ileana O. Jelescu, Gabriel Girard, Jonathan Rafael-Patino, Jean-Philippe Thiran Signal Processing Laboratory, 'Ecole Polytechnique F'ed'erale de Lausanne, Lausanne, Switzerland., Radiology Department, Centre Hospitalier Universitaire Vaudois, University of Lausanne, School of Biology, Medicine, Department of Computer Science, Universit'e de Sherbrooke, Sherbrooke, Canada., CIBM Center for Biomedical Imaging",ab192f33a809773efae7236bd93ee7cbd219ff82,Cellular EXchange Imaging (CEXI): Evaluation of a diffusion model including water exchange in cells using numerical phantoms of permeable spheres,,2023,0,"Purpose: Biophysical models of diffusion MRI have been developed to characterize microstructure in various tissues, but existing models are not suitable for tissue composed of permeable spherical cells. In this study we introduce Cellular Exchange Imaging (CEXI), a model tailored for permeable spherical cells, and compares its performance to a related Ball \&Sphere (BS) model that neglects permeability. Methods: We generated DW-MRI signals using Monte-Carlo simulations with a PGSE sequence in numerical substrates made of spherical cells and their extracellular space for a range of membrane permeability. From these signals, the properties of the substrates were inferred using both BS and CEXI models. Results: CEXI outperformed the impermeable model by providing more stable estimates cell size and intracellular volume fraction that were diffusion time-independent. Notably, CEXI accurately estimated the exchange time for low to moderate permeability levels previously reported in other studies ($\kappa<25\mu m/s$). However, in highly permeable substrates ($\kappa=50\mu m/s$), the estimated parameters were less stable, particularly the diffusion coefficients. Conclusion: This study highlights the importance of modeling the exchange time to accurately quantify microstructure properties in permeable cellular substrates. Future studies should evaluate CEXI in clinical applications such as lymph nodes, investigate exchange time as a potential biomarker of tumor severity, and develop more appropriate tissue models that account for anisotropic diffusion and highly permeable membranes."
"Xiaoyue Li, K. Shang, Gaoang Wang, Mark D. Butala",8fbe4a7c06c078e20af4f96afc734fb49991aa0e,DDMM-Synth: A Denoising Diffusion Model for Cross-modal Medical Image Synthesis with Sparse-view Measurement Embedding,,2023,0,"Reducing the radiation dose in computed tomography (CT) is important to mitigate radiation-induced risks. One option is to employ a well-trained model to compensate for incomplete information and map sparse-view measurements to the CT reconstruction. However, reconstruction from sparsely sampled measurements is insufficient to uniquely characterize an object in CT, and a learned prior model may be inadequate for unencountered cases. Medical modal translation from magnetic resonance imaging (MRI) to CT is an alternative but may introduce incorrect information into the synthesized CT images in addition to the fact that there exists no explicit transformation describing their relationship. To address these issues, we propose a novel framework called the denoising diffusion model for medical image synthesis (DDMM-Synth) to close the performance gaps described above. This framework combines an MRI-guided diffusion model with a new CT measurement embedding reverse sampling scheme. Specifically, the null-space content of the one-step denoising result is refined by the MRI-guided data distribution prior, and its range-space component derived from an explicit operator matrix and the sparse-view CT measurements is directly integrated into the inference stage. DDMM-Synth can adjust the projection number of CT a posteriori for a particular clinical application and its modified version can even improve the results significantly for noisy cases. Our results show that DDMM-Synth outperforms other state-of-the-art supervised-learning-based baselines under fair experimental conditions."
"Florentin Bieder, Julia Wolleb, Alicia Durrer, Robin Sandkuhler, Philippe C. Cattin",662d67be03107f0c892c4e1b78b39b4b764c93e9,Diffusion Models for Memory-efficient Processing of 3D Medical Images,,2023,0,"Denoising diffusion models have recently achieved state-of-the-art performance in many image-generation tasks. They do, however, require a large amount of computational resources. This limits their application to medical tasks, where we often deal with large 3D volumes, like high-resolution three-dimensional data. In this work, we present a number of different ways to reduce the resource consumption for 3D diffusion models and apply them to a dataset of 3D images. The main contribution of this paper is the memory-efficient patch-based diffusion model \textit{PatchDDM}, which can be applied to the total volume during inference while the training is performed only on patches. While the proposed diffusion model can be applied to any image generation tasks, we evaluate the method on the tumor segmentation task of the BraTS2020 dataset and demonstrate that we can generate meaningful three-dimensional segmentations."
"Junshu Tang, Tengfei Wang, Bo Zhang, Ting Zhang, Ran Yi, Lizhuang Ma, Dong Chen",d84616f108ccbd958735fef7622e58d148b32139,Make-It-3D: High-Fidelity 3D Creation from A Single Image with Diffusion Prior,,2023,0,"In this work, we investigate the problem of creating high-fidelity 3D content from only a single image. This is inherently challenging: it essentially involves estimating the underlying 3D geometry while simultaneously hallucinating unseen textures. To address this challenge, we leverage prior knowledge from a well-trained 2D diffusion model to act as 3D-aware supervision for 3D creation. Our approach, Make-It-3D, employs a two-stage optimization pipeline: the first stage optimizes a neural radiance field by incorporating constraints from the reference image at the frontal view and diffusion prior at novel views; the second stage transforms the coarse model into textured point clouds and further elevates the realism with diffusion prior while leveraging the high-quality textures from the reference image. Extensive experiments demonstrate that our method outperforms prior works by a large margin, resulting in faithful reconstructions and impressive visual quality. Our method presents the first attempt to achieve high-quality 3D creation from a single image for general objects and enables various applications such as text-to-3D creation and texture editing."
"Yizhuo Lu, Changde Du, Dianpeng Wang, Huiguang He",f81bda850d829460c33844dd01e775c23abdf9f3,MindDiffuser: Controlled Image Reconstruction from Human Brain Activity with Semantic and Structural Diffusion,,2023,0,"Reconstructing visual stimuli from measured functional magnetic resonance imaging (fMRI) has been a meaningful and challenging task. Previous studies have successfully achieved reconstructions with structures similar to the original images, such as the outlines and size of some natural images. However, these reconstructions lack explicit semantic information and are difficult to discern. In recent years, many studies have utilized multi-modal pre-trained models with stronger generative capabilities to reconstruct images that are semantically similar to the original ones. However, these images have uncontrollable structural information such as position and orientation. To address both of the aforementioned issues simultaneously, we propose a two-stage image reconstruction model called MindDiffuser, utilizing Stable Diffusion. In Stage 1, the VQ-VAE latent representations and the CLIP text embeddings decoded from fMRI are put into the image-to-image process of Stable Diffusion, which yields a preliminary image that contains semantic and structural information. In Stage 2, we utilize the low-level CLIP visual features decoded from fMRI as supervisory information, and continually adjust the two features in Stage 1 through backpropagation to align the structural information. The results of both qualitative and quantitative analyses demonstrate that our proposed model has surpassed the current state-of-the-art models in terms of reconstruction results on Natural Scenes Dataset (NSD). Furthermore, the results of ablation experiments indicate that each component of our model is effective for image reconstruction."
"Haomiao Ni, Changhao Shi, Kaican Li, Sharon X. Huang, Martin Renqiang Min",b8b5015b153709176385873e34339f9e520d128f,Conditional Image-to-Video Generation with Latent Flow Diffusion Models,,2023,0,"Conditional image-to-video (cI2V) generation aims to synthesize a new plausible video starting from an image (e.g., a person's face) and a condition (e.g., an action class label like smile). The key challenge of the cI2V task lies in the simultaneous generation of realistic spatial appearance and temporal dynamics corresponding to the given image and condition. In this paper, we propose an approach for cI2V using novel latent flow diffusion models (LFDM) that synthesize an optical flow sequence in the latent space based on the given condition to warp the given image. Compared to previous direct-synthesis-based works, our proposed LFDM can better synthesize spatial details and temporal motion by fully utilizing the spatial content of the given image and warping it in the latent space according to the generated temporally-coherent flow. The training of LFDM consists of two separate stages: (1) an unsupervised learning stage to train a latent flow auto-encoder for spatial content generation, including a flow predictor to estimate latent flow between pairs of video frames, and (2) a conditional learning stage to train a 3D-UNet-based diffusion model (DM) for temporal latent flow generation. Unlike previous DMs operating in pixel space or latent feature space that couples spatial and temporal information, the DM in our LFDM only needs to learn a low-dimensional latent flow space for motion generation, thus being more computationally efficient. We conduct comprehensive experiments on multiple datasets, where LFDM consistently outperforms prior arts. Furthermore, we show that LFDM can be easily adapted to new domains by simply finetuning the image decoder. Our code is available at https://github.com/nihaomiao/CVPR23_LFDM."
"T. Hollon, Cheng Jiang, A. Chowdury, M. Nasir-Moin, Akhil Kondepudi, A. Aabedi, A. Adapa, W. Al-Holou, J. Heth, O. Sagher, P. Lowenstein, Maria Castro, L. Wadiura, G. Widhalm, V. Neuschmelting, D. Reinecke, N. von Spreckelsen, Mitchel S Berger, S. Hervey-Jumper, J. Golfinos, M. Snuderl, S. Camelo-Piragua, C. Freudiger, Ho Hin Lee, D. Orringer",116f63722179f665696d8720ddc3911d80fd7b78,"Artificial-intelligence-based molecular classification of diffuse gliomas using rapid, label-free optical imaging.",Nature Network Boston,2023,0,
"Nupur Kumari, Bin Zhang, Sheng-Yu Wang, Eli Shechtman, Richard Zhang, Jun-Yan Zhu",0717abd176bf5ebe9a5fd5b35685d064c9c5b78c,Ablating Concepts in Text-to-Image Diffusion Models,,2023,0,"Large-scale text-to-image diffusion models can generate high-fidelity images with powerful compositional ability. However, these models are typically trained on an enormous amount of Internet data, often containing copyrighted material, licensed images, and personal photos. Furthermore, they have been found to replicate the style of various living artists or memorize exact training samples. How can we remove such copyrighted concepts or images without retraining the model from scratch? To achieve this goal, we propose an efficient method of ablating concepts in the pretrained model, i.e., preventing the generation of a target concept. Our algorithm learns to match the image distribution for a target style, instance, or text prompt we wish to ablate to the distribution corresponding to an anchor concept. This prevents the model from generating target concepts given its text condition. Extensive experiments show that our method can successfully prevent the generation of the ablated concept while preserving closely related concepts in the model."
"Ziqi Huang, Tianxing Wu, Yuming Jiang, Kelvin C. K. Chan, Ziwei Liu",f677fc0f6a7a4f7b324b8f14700e14715cb06bca,ReVersion: Diffusion-Based Relation Inversion from Images,,2023,0,"Diffusion models gain increasing popularity for their generative capabilities. Recently, there have been surging needs to generate customized images by inverting diffusion models from exemplar images. However, existing inversion methods mainly focus on capturing object appearances. How to invert object relations, another important pillar in the visual world, remains unexplored. In this work, we propose ReVersion for the Relation Inversion task, which aims to learn a specific relation (represented as""relation prompt"") from exemplar images. Specifically, we learn a relation prompt from a frozen pre-trained text-to-image diffusion model. The learned relation prompt can then be applied to generate relation-specific images with new objects, backgrounds, and styles. Our key insight is the""preposition prior""- real-world relation prompts can be sparsely activated upon a set of basis prepositional words. Specifically, we propose a novel relation-steering contrastive learning scheme to impose two critical properties of the relation prompt: 1) The relation prompt should capture the interaction between objects, enforced by the preposition prior. 2) The relation prompt should be disentangled away from object appearances. We further devise relation-focal importance sampling to emphasize high-level interactions over low-level appearances (e.g., texture, color). To comprehensively evaluate this new task, we contribute ReVersion Benchmark, which provides various exemplar images with diverse relations. Extensive experiments validate the superiority of our approach over existing methods across a wide range of visual relations."
"B. D. Wilde, A. Saha, R. T. Broek, H. Huisman",41579777836a07a1bd8b4d8593fcda7983b68e67,Medical diffusion on a budget: textual inversion for medical image generation,,2023,0,"Diffusion-based models for text-to-image generation have gained immense popularity due to recent advancements in efficiency, accessibility, and quality. Although it is becoming increasingly feasible to perform inference with these systems using consumer-grade GPUs, training them from scratch still requires access to large datasets and significant computational resources. In the case of medical image generation, the availability of large, publicly accessible datasets that include text reports is limited due to legal and ethical concerns. While training a diffusion model on a private dataset may address this issue, it is not always feasible for institutions lacking the necessary computational resources. This work demonstrates that pre-trained Stable Diffusion models, originally trained on natural images, can be adapted to various medical imaging modalities by training text embeddings with textual inversion. In this study, we conducted experiments using medical datasets comprising only 100 samples from three medical modalities. Embeddings were trained in a matter of hours, while still retaining diagnostic relevance in image generation. Experiments were designed to achieve several objectives. Firstly, we fine-tuned the training and inference processes of textual inversion, revealing that larger embeddings and more examples are required. Secondly, we validated our approach by demonstrating a 2\% increase in the diagnostic accuracy (AUC) for detecting prostate cancer on MRI, which is a challenging multi-modal imaging modality, from 0.78 to 0.80. Thirdly, we performed simulations by interpolating between healthy and diseased states, combining multiple pathologies, and inpainting to show embedding flexibility and control of disease appearance. Finally, the embeddings trained in this study are small (less than 1 MB), which facilitates easy sharing of medical data with reduced privacy concerns."
"Matthew Tivnan, Jacopo Teneggi, Tzu-Cheng Lee, Ruoqiao Zhang, K. Boedeker, L. Cai, G. Gang, Jeremias Sulam, J. Stayman",2b5584e00340d5f699b68236d30cd7a7a9f2e71c,Fourier Diffusion Models: A Method to Control MTF and NPS in Score-Based Stochastic Image Generation,,2023,0,"Score-based stochastic denoising models have recently been demonstrated as powerful machine learning tools for conditional and unconditional image generation. The existing methods are based on a forward stochastic process wherein the training images are scaled to zero over time and white noise is gradually added such that the final time step is approximately zero-mean identity-covariance Gaussian noise. A neural network is then trained to approximate the time-dependent score function, or the gradient of the logarithm of the probability density, for that time step. Using this score estimator, it is possible to run an approximation of the time-reversed stochastic process to sample new images from the training data distribution. These score-based generative models have been shown to out-perform generative adversarial neural networks using standard benchmarks and metrics. However, one issue with this approach is that it requires a large number of forward passes of the neural network. Additionally, the images at intermediate time steps are not useful, since the signal-to-noise ratio is low. In this work we present a new method called Fourier Diffusion Models which replaces the scalar operations of the forward process with shift-invariant convolutions and the additive white noise with additive stationary noise. This allows for control of MTF and NPS at intermediate time steps. Additionally, the forward process can be crafted to converge to the same MTF and NPS as the measured images. This way, we can model continuous probability flow from true images to measurements. In this way, the sample time can be used to control the tradeoffs between measurement uncertainty and generative uncertainty of posterior estimates. We compare Fourier diffusion models to existing scalar diffusion models and show that they achieve a higher level of performance and allow for a smaller number of time steps."
"Jing Zhao, Heliang Zheng, Chaoyue Wang, L. Lan, Wenjing Yang",f79bdce242433a528d47111fb7aa51118efaf595,MagicFusion: Boosting Text-to-Image Generation Performance by Fusing Diffusion Models,,2023,0,"The advent of open-source AI communities has produced a cornucopia of powerful text-guided diffusion models that are trained on various datasets. While few explorations have been conducted on ensembling such models to combine their strengths. In this work, we propose a simple yet effective method called Saliency-aware Noise Blending (SNB) that can empower the fused text-guided diffusion models to achieve more controllable generation. Specifically, we experimentally find that the responses of classifier-free guidance are highly related to the saliency of generated images. Thus we propose to trust different models in their areas of expertise by blending the predicted noises of two diffusion models in a saliency-aware manner. SNB is training-free and can be completed within a DDIM sampling process. Additionally, it can automatically align the semantics of two noise spaces without requiring additional annotations such as masks. Extensive experiments show the impressive effectiveness of SNB in various applications. Project page is available at https://magicfusion.github.io/."
"K. Pnvr, Bharat Singh, P. Ghosh, Behjat Siddiquie, David Jacobs",97084b7e4af5733a65c1e5e72e03d7543d516535,LD-ZNet: A Latent Diffusion Approach for Text-Based Image Segmentation,,2023,0,"We present a technique for segmenting real and AI-generated images using latent diffusion models (LDMs) trained on internet-scale datasets. First, we show that the latent space of LDMs (z-space) is a better input representation compared to other feature representations like RGB images or CLIP encodings for text-based image segmentation. By training the segmentation models on the latent z-space, which creates a compressed representation across several domains like different forms of art, cartoons, illustrations, and photographs, we are also able to bridge the domain gap between real and AI-generated images. We show that the internal features of LDMs contain rich semantic information and present a technique in the form of LD-ZNet to further boost the performance of text-based segmentation. Overall, we show up to 6% improvement over standard baselines for text-to-image segmentation on natural images. For AI-generated imagery, we show close to 20% improvement compared to state-of-the-art techniques."
"Geonmo Gu, Sanghyuk Chun, Wonjae Kim, HeeJae Jun, Yoohoon Kang, Sangdoo Yun",38b57043b6bdf4adcd637a3e63c5fa210160a4aa,CompoDiff: Versatile Composed Image Retrieval With Latent Diffusion,ArXiv,2023,0,"This paper proposes a novel diffusion-based model, CompoDiff, for solving Composed Image Retrieval (CIR) with latent diffusion and presents a newly created dataset of 18 million reference images, conditions, and corresponding target image triplets to train the model. CompoDiff not only achieves a new zero-shot state-of-the-art on a CIR benchmark such as FashionIQ but also enables a more versatile CIR by accepting various conditions, such as negative text and image mask conditions, which are unavailable with existing CIR methods. In addition, the CompoDiff features are on the intact CLIP embedding space so that they can be directly used for all existing models exploiting the CLIP space. The code and dataset used for the training, and the pre-trained weights are available at https://github.com/navervision/CompoDiff"
"Weijia Wu, Yuzhong Zhao, Mike Zheng Shou, Hong Zhou, Chunhua Shen",8b7b52b79894fabfa76ecfaee0107c6bef6dbb0a,DiffuMask: Synthesizing Images with Pixel-level Annotations for Semantic Segmentation Using Diffusion Models,ArXiv,2023,0,"Collecting and annotating images with pixel-wise labels is time-consuming and laborious. In contrast, synthetic data can be freely available using a generative model (e.g., DALL-E, Stable Diffusion). In this paper, we show that it is possible to automatically obtain accurate semantic masks of synthetic images generated by the Off-the-shelf Stable Diffusion model, which uses only text-image pairs during training. Our approach, called DiffuMask, exploits the potential of the cross-attention map between text and image, which is natural and seamless to extend the text-driven image synthesis to semantic mask generation. DiffuMask uses text-guided cross-attention information to localize class/word-specific regions, which are combined with practical techniques to create a novel high-resolution and class-discriminative pixel-wise mask. The methods help to reduce data collection and annotation costs obviously. Experiments demonstrate that the existing segmentation methods trained on synthetic data of DiffuMask can achieve a competitive performance over the counterpart of real data (VOC 2012, Cityscapes). For some classes (e.g., bird), DiffuMask presents promising performance, close to the stateof-the-art result of real data (within 3% mIoU gap). Moreover, in the open-vocabulary segmentation (zero-shot) setting, DiffuMask achieves a new SOTA result on Unseen class of VOC 2012. The project website can be found at https://weijiawu.github.io/DiffusionMask/."
"A. Shrivastava, P. Fletcher",9ec7bc53535a8e0773a9373e80d31f0d75b3e416,NASDM: Nuclei-Aware Semantic Histopathology Image Generation Using Diffusion Models,ArXiv,2023,0,"In recent years, computational pathology has seen tremendous progress driven by deep learning methods in segmentation and classification tasks aiding prognostic and diagnostic settings. Nuclei segmentation, for instance, is an important task for diagnosing different cancers. However, training deep learning models for nuclei segmentation requires large amounts of annotated data, which is expensive to collect and label. This necessitates explorations into generative modeling of histopathological images. In this work, we use recent advances in conditional diffusion modeling to formulate a first-of-its-kind nuclei-aware semantic tissue generation framework (NASDM) which can synthesize realistic tissue samples given a semantic instance mask of up to six different nuclei types, enabling pixel-perfect nuclei localization in generated samples. These synthetic images are useful in applications in pathology pedagogy, validation of models, and supplementation of existing nuclei segmentation datasets. We demonstrate that NASDM is able to synthesize high-quality histopathology images of the colon with superior quality and semantic controllability over existing generative methods."
"Or Patashnik, Daniel Garibi, Idan Azuri, Hadar Averbuch-Elor, D. Cohen-Or",2f49d847c94a5e08bf1fecb7540d7d32b7086800,Localizing Object-level Shape Variations with Text-to-Image Diffusion Models,ArXiv,2023,0,"Text-to-image models give rise to workflows which often begin with an exploration step, where users sift through a large collection of generated images. The global nature of the text-to-image generation process prevents users from narrowing their exploration to a particular object in the image. In this paper, we present a technique to generate a collection of images that depicts variations in the shape of a specific object, enabling an object-level shape exploration process. Creating plausible variations is challenging as it requires control over the shape of the generated object while respecting its semantics. A particular challenge when generating object variations is accurately localizing the manipulation applied over the object's shape. We introduce a prompt-mixing technique that switches between prompts along the denoising process to attain a variety of shape choices. To localize the image-space operation, we present two techniques that use the self-attention layers in conjunction with the cross-attention layers. Moreover, we show that these localization techniques are general and effective beyond the scope of generating object variations. Extensive results and comparisons demonstrate the effectiveness of our method in generating object variations, and the competence of our localization techniques."
"Yijun Yang, H. Fu, Angelica I. Avilés-Rivero, C. Schonlieb, Lei Zhu",39fb354acc5cc0775e5f227661bd0f5c06ea6aae,DiffMIC: Dual-Guidance Diffusion Network for Medical Image Classification,ArXiv,2023,0,"Diffusion Probabilistic Models have recently shown remarkable performance in generative image modeling, attracting significant attention in the computer vision community. However, while a substantial amount of diffusion-based research has focused on generative tasks, few studies have applied diffusion models to general medical image classification. In this paper, we propose the first diffusion-based model (named DiffMIC) to address general medical image classification by eliminating unexpected noise and perturbations in medical images and robustly capturing semantic representation. To achieve this goal, we devise a dual conditional guidance strategy that conditions each diffusion step with multiple granularities to improve step-wise regional attention. Furthermore, we propose learning the mutual information in each granularity by enforcing Maximum-Mean Discrepancy regularization during the diffusion forward process. We evaluate the effectiveness of our DiffMIC on three medical classification tasks with different image modalities, including placental maturity grading on ultrasound images, skin lesion classification using dermatoscopic images, and diabetic retinopathy grading using fundus images. Our experimental results demonstrate that DiffMIC outperforms state-of-the-art methods by a significant margin, indicating the universality and effectiveness of the proposed model. Our code will be publicly available at https://github.com/scott-yjyang/DiffMIC."
"Matthew A. Chan, Sean I. Young, Christopher A. Metzler",02231a0d3f0e29f0bb69b74e2634e86c5753fb48,SUD2: Supervision by Denoising Diffusion Models for Image Reconstruction,ArXiv,2023,0,"Many imaging inverse problems$\unicode{x2014}$such as image-dependent in-painting and dehazing$\unicode{x2014}$are challenging because their forward models are unknown or depend on unknown latent parameters. While one can solve such problems by training a neural network with vast quantities of paired training data, such paired training data is often unavailable. In this paper, we propose a generalized framework for training image reconstruction networks when paired training data is scarce. In particular, we demonstrate the ability of image denoising algorithms and, by extension, denoising diffusion models to supervise network training in the absence of paired training data."
"Savvas Panagiotou, A. Bosman",75ced0b03ef77a234037a1b7105eecd15112e49d,Denoising Diffusion Post-Processing for Low-Light Image Enhancement,ArXiv,2023,0,"Low-light image enhancement (LLIE) techniques attempt to increase the visibility of images captured in low-light scenarios. However, as a result of enhancement, a variety of image degradations such as noise and color bias are revealed. Furthermore, each particular LLIE approach may introduce a different form of flaw within its enhanced results. To combat these image degradations, post-processing denoisers have widely been used, which often yield oversmoothed results lacking detail. We propose using a diffusion model as a post-processing approach, and we introduce Low-light Post-processing Diffusion Model (LPDM) in order to model the conditional distribution between under-exposed and normally-exposed images. We apply LPDM in a manner which avoids the computationally expensive generative reverse process of typical diffusion models, and post-process images in one pass through LPDM. Extensive experiments demonstrate that our approach outperforms competing post-processing denoisers by increasing the perceptual quality of enhanced low-light images on a variety of challenging low-light datasets. Source code is available at https://github.com/savvaki/LPDM."
"Bin Xia, Yulun Zhang, Shi-Shen Wang, Yitong Wang, Xing Wu, Yapeng Tian, Wenming Yang, L. Gool",df5559649c1f47693c9ebef155de8c0a628ea72e,DiffIR: Efficient Diffusion Model for Image Restoration,ArXiv,2023,0,"Diffusion model (DM) has achieved SOTA performance by modeling the image synthesis process into a sequential application of a denoising network. However, different from image synthesis generating each pixel from scratch, most pixels of image restoration (IR) are given. Thus, for IR, traditional DMs running massive iterations on a large model to estimate whole images or feature maps is inefficient. To address this issue, we propose an efficient DM for IR (DiffIR), which consists of a compact IR prior extraction network (CPEN), dynamic IR transformer (DIRformer), and denoising network. Specifically, DiffIR has two training stages: pretraining and training DM. In pretraining, we input ground-truth images into CPEN$_{S1}$ to capture a compact IR prior representation (IPR) to guide DIRformer. In the second stage, we train the DM to directly estimate the same IRP as pretrained CPEN$_{S1}$ only using LQ images. We observe that since the IPR is only a compact vector, DiffIR can use fewer iterations than traditional DM to obtain accurate estimations and generate more stable and realistic results. Since the iterations are few, our DiffIR can adopt a joint optimization of CPEN$_{S2}$, DIRformer, and denoising network, which can further reduce the estimation error influence. We conduct extensive experiments on several IR tasks and achieve SOTA performance while consuming less computational costs."
"Zhendong Wang, Jianmin Bao, Wen-gang Zhou, Weilun Wang, Hezhen Hu, Hong Chen, Houqiang Li",d9d82eb6a8886226724ea230a7e5923d660a0bad,DIRE for Diffusion-Generated Image Detection,ArXiv,2023,0,"Diffusion models have shown remarkable success in visual synthesis, but have also raised concerns about potential abuse for malicious purposes. In this paper, we seek to build a detector for telling apart real images from diffusion-generated images. We find that existing detectors struggle to detect images generated by diffusion models, even if we include generated images from a specific diffusion model in their training data. To address this issue, we propose a novel image representation called DIffusion Reconstruction Error (DIRE), which measures the error between an input image and its reconstruction counterpart by a pre-trained diffusion model. We observe that diffusion-generated images can be approximately reconstructed by a diffusion model while real images cannot. It provides a hint that DIRE can serve as a bridge to distinguish generated and real images. DIRE provides an effective way to detect images generated by most diffusion models, and it is general for detecting generated images from unseen diffusion models and robust to various perturbations. Furthermore, we establish a comprehensive diffusion-generated benchmark including images generated by eight diffusion models to evaluate the performance of diffusion-generated image detectors. Extensive experiments on our collected benchmark demonstrate that DIRE exhibits superiority over previous generated-image detectors. The code and dataset are available at https://github.com/ZhendongWang6/DIRE."
"D. Kothandaraman, Tianyi Zhou, Ming Lin, Dinesh Manocha",03d7c81386718f1abca7eb397917e281839618bf,Aerial Diffusion: Text Guided Ground-to-Aerial View Translation from a Single Image using Diffusion Models,ArXiv,2023,0,"We present a novel method, Aerial Diffusion, for generating aerial views from a single ground-view image using text guidance. Aerial Diffusion leverages a pretrained text-image diffusion model for prior knowledge. We address two main challenges corresponding to domain gap between the ground-view and the aerial view and the two views being far apart in the text-image embedding manifold. Our approach uses a homography inspired by inverse perspective mapping prior to finetuning the pretrained diffusion model. Additionally, using the text corresponding to the ground-view to finetune the model helps us capture the details in the ground-view image at a relatively low bias towards the ground-view image. Aerial Diffusion uses an alternating sampling strategy to compute the optimal solution on complex high-dimensional manifold and generate a high-fidelity (w.r.t. ground view) aerial image. We demonstrate the quality and versatility of Aerial Diffusion on a plethora of images from various domains including nature, human actions, indoor scenes, etc. We qualitatively prove the effectiveness of our method with extensive ablations and comparisons. To the best of our knowledge, Aerial Diffusion is the first approach that performs ground-to-aerial translation in an unsupervised manner."
"J. Cross-Zamirski, P. Anand, Guy Williams, E. Mouchet, Yinhai Wang, C. Schönlieb",e2f4ffbb02f50b50f81bd3070d266b32dab0800a,Class-Guided Image-to-Image Diffusion: Cell Painting from Brightfield Images with Class Labels,ArXiv,2023,0,"Image-to-image reconstruction problems with free or inexpensive metadata in the form of class labels appear often in biological and medical image domains. Existing text-guided or style-transfer image-to-image approaches do not translate to datasets where additional information is provided as discrete classes. We introduce and implement a model which combines image-to-image and class-guided denoising diffusion probabilistic models. We train our model on a real-world dataset of microscopy images used for drug discovery, with and without incorporating metadata labels. By exploring the properties of image-to-image diffusion with relevant labels, we show that class-guided image-to-image diffusion can improve the meaningful content of the reconstructed images and outperform the unguided model in useful downstream tasks."
"Inhwa Han, Serin Yang, Taesung Kwon, Jong-Chul Ye",ff48a602ce6b32d0045b6752abb16f9f297567d1,Highly Personalized Text Embedding for Image Manipulation by Stable Diffusion,ArXiv,2023,0,"Diffusion models have shown superior performance in image generation and manipulation, but the inherent stochasticity presents challenges in preserving and manipulating image content and identity. While previous approaches like DreamBooth and Textual Inversion have proposed model or latent representation personalization to maintain the content, their reliance on multiple reference images and complex training limits their practicality. In this paper, we present a simple yet highly effective approach to personalization using highly personalized (HiPer) text embedding by decomposing the CLIP embedding space for personalization and content manipulation. Our method does not require model fine-tuning or identifiers, yet still enables manipulation of background, texture, and motion with just a single image and target text. Through experiments on diverse target texts, we demonstrate that our approach produces highly personalized and complex semantic image edits across a wide range of tasks. We believe that the novel understanding of the text embedding space presented in this work has the potential to inspire further research across various tasks."
"Shuyao Shang, Zhengyang Shan, Guangxing Liu, Jingling Zhang",1b8452be196d943241c76c170e93ea1d49aa07ea,ResDiff: Combining CNN and Diffusion Model for Image Super-Resolution,ArXiv,2023,0,"Adapting the Diffusion Probabilistic Model (DPM) for direct image super-resolution is wasteful, given that a simple Convolutional Neural Network (CNN) can recover the main low-frequency content. Therefore, we present ResDiff, a novel Diffusion Probabilistic Model based on Residual structure for Single Image Super-Resolution (SISR). ResDiff utilizes a combination of a CNN, which restores primary low-frequency components, and a DPM, which predicts the residual between the ground-truth image and the CNN-predicted image. In contrast to the common diffusion-based methods that directly use LR images to guide the noise towards HR space, ResDiff utilizes the CNN's initial prediction to direct the noise towards the residual space between HR space and CNN-predicted space, which not only accelerates the generation process but also acquires superior sample quality. Additionally, a frequency-domain-based loss function for CNN is introduced to facilitate its restoration, and a frequency-domain guided diffusion is designed for DPM on behalf of predicting high-frequency details. The extensive experiments on multiple benchmark datasets demonstrate that ResDiff outperforms previous diffusion-based methods in terms of shorter model convergence time, superior generation quality, and more diverse samples."
"Serin Yang, Hyun-joo Hwang, Jong-Chul Ye",7f971b88d4fda36a6a0529e618a015b2410e802f,Zero-Shot Contrastive Loss for Text-Guided Diffusion Image Style Transfer,ArXiv,2023,0,"Diffusion models have shown great promise in text-guided image style transfer, but there is a trade-off between style transformation and content preservation due to their stochastic nature. Existing methods require computationally expensive fine-tuning of diffusion models or additional neural network. To address this, here we propose a zero-shot contrastive loss for diffusion models that doesn't require additional fine-tuning or auxiliary networks. By leveraging patch-wise contrastive loss between generated samples and original image embeddings in the pre-trained diffusion model, our method can generate images with the same semantic content as the source image in a zero-shot manner. Our approach outperforms existing methods while preserving content and requiring no additional training, not only for image style transfer but also for image-to-image translation and manipulation. Our experimental results validate the effectiveness of our proposed method."
"Suhyeon Lee, Hyungjin Chung, Minyoung Park, Jonghyuk Park, Wi-Sun Ryu, J. C. Ye",b5b0a02cfe9dfc67c8b4a4e0e5ddfa46d98ea012,Improving 3D Imaging with Pre-Trained Perpendicular 2D Diffusion Models,ArXiv,2023,0,"Diffusion models have become a popular approach for image generation and reconstruction due to their numerous advantages. However, most diffusion-based inverse problem-solving methods only deal with 2D images, and even recently published 3D methods do not fully exploit the 3D distribution prior. To address this, we propose a novel approach using two perpendicular pre-trained 2D diffusion models to solve the 3D inverse problem. By modeling the 3D data distribution as a product of 2D distributions sliced in different directions, our method effectively addresses the curse of dimensionality. Our experimental results demonstrate that our method is highly effective for 3D medical image reconstruction tasks, including MRI Z-axis super-resolution, compressed sensing MRI, and sparse-view CT. Our method can generate high-quality voxel volumes suitable for medical applications."
"Alicia Durrer, Julia Wolleb, Florentin Bieder, T. Sinnecker, M. Weigel, Robin Sandkühler, C. Granziera, Ö. Yaldizli, P. Cattin",cf817a94b49ae19cf7ea36f4f2e6fa0d22fdbfd2,Diffusion Models for Contrast Harmonization of Magnetic Resonance Images,ArXiv,2023,0,"Magnetic resonance (MR) images from multiple sources often show differences in image contrast related to acquisition settings or the used scanner type. For long-term studies, longitudinal comparability is essential but can be impaired by these contrast differences, leading to biased results when using automated evaluation tools. This study presents a diffusion model-based approach for contrast harmonization. We use a data set consisting of scans of 18 Multiple Sclerosis patients and 22 healthy controls. Each subject was scanned in two MR scanners of different magnetic field strengths (1.5 T and 3 T), resulting in a paired data set that shows scanner-inherent differences. We map images from the source contrast to the target contrast for both directions, from 3 T to 1.5 T and from 1.5 T to 3 T. As we only want to change the contrast, not the anatomical information, our method uses the original image to guide the image-to-image translation process by adding structural information. The aim is that the mapped scans display increased comparability with scans of the target contrast for downstream tasks. We evaluate this method for the task of segmentation of cerebrospinal fluid, grey matter and white matter. Our method achieves good and consistent results for both directions of the mapping."
"Tao Yang, Peiran Ren, Xuansong Xie, Lei Zhang",4b4f73a0534fbb2414bc409f6a3364eafa5dccbd,Synthesizing Realistic Image Restoration Training Pairs: A Diffusion Approach,ArXiv,2023,0,"In supervised image restoration tasks, one key issue is how to obtain the aligned high-quality (HQ) and low-quality (LQ) training image pairs. Unfortunately, such HQ-LQ training pairs are hard to capture in practice, and hard to synthesize due to the complex unknown degradation in the wild. While several sophisticated degradation models have been manually designed to synthesize LQ images from their HQ counterparts, the distribution gap between the synthesized and real-world LQ images remains large. We propose a new approach to synthesizing realistic image restoration training pairs using the emerging denoising diffusion probabilistic model (DDPM). First, we train a DDPM, which could convert a noisy input into the desired LQ image, with a large amount of collected LQ images, which define the target data distribution. Then, for a given HQ image, we synthesize an initial LQ image by using an off-the-shelf degradation model, and iteratively add proper Gaussian noises to it. Finally, we denoise the noisy LQ image using the pre-trained DDPM to obtain the final LQ image, which falls into the target distribution of real-world LQ images. Thanks to the strong capability of DDPM in distribution approximation, the synthesized HQ-LQ image pairs can be used to train robust models for real-world image restoration tasks, such as blind face image restoration and blind image super-resolution. Experiments demonstrated the superiority of our proposed approach to existing degradation models. Code and data will be released."
"Zixiang Zhao, Hao Bai, Yu Zhu, Jiangshe Zhang, Shuang Xu, Yulun Zhang, K. Zhang, Deyu Meng, R. Timofte, L. Gool",d2431d5540db0fc146bd228dd3ffe770b44bcd8a,DDFM: Denoising Diffusion Model for Multi-Modality Image Fusion,ArXiv,2023,0,"Multi-modality image fusion aims to combine different modalities to produce fused images that retain the complementary features of each modality, such as functional highlights and texture details. To leverage strong generative priors and address challenges such as unstable training and lack of interpretability for GAN-based generative methods, we propose a novel fusion algorithm based on the denoising diffusion probabilistic model (DDPM). The fusion task is formulated as a conditional generation problem under the DDPM sampling framework, which is further divided into an unconditional generation subproblem and a maximum likelihood subproblem. The latter is modeled in a hierarchical Bayesian manner with latent variables and inferred by the expectation-maximization algorithm. By integrating the inference solution into the diffusion sampling iteration, our method can generate high-quality fused images with natural image generative priors and cross-modality information from source images. Note that all we required is an unconditional pre-trained generative model, and no fine-tuning is needed. Our extensive experiments indicate that our approach yields promising fusion results in infrared-visible image fusion and medical image fusion. The code will be released."
"Yu-Chun Miao, Lefei Zhang, L. Zhang, D. Tao",2e76f9e4ae025c93ca9c5439d2d15960f0c97fb0,DDS2M: Self-Supervised Denoising Diffusion Spatio-Spectral Model for Hyperspectral Image Restoration,ArXiv,2023,0,"Diffusion models have recently received a surge of interest due to their impressive performance for image restoration, especially in terms of noise robustness. However, existing diffusion-based methods are trained on a large amount of training data and perform very well in-distribution, but can be quite susceptible to distribution shift. This is especially inappropriate for data-starved hyperspectral image (HSI) restoration. To tackle this problem, this work puts forth a self-supervised diffusion model for HSI restoration, namely Denoising Diffusion Spatio-Spectral Model (\texttt{DDS2M}), which works by inferring the parameters of the proposed Variational Spatio-Spectral Module (VS2M) during the reverse diffusion process, solely using the degraded HSI without any extra training data. In VS2M, a variational inference-based loss function is customized to enable the untrained spatial and spectral networks to learn the posterior distribution, which serves as the transitions of the sampling chain to help reverse the diffusion process. Benefiting from its self-supervised nature and the diffusion process, \texttt{DDS2M} enjoys stronger generalization ability to various HSIs compared to existing diffusion-based methods and superior robustness to noise compared to existing HSI restoration methods. Extensive experiments on HSI denoising, noisy HSI completion and super-resolution on a variety of HSIs demonstrate \texttt{DDS2M}'s superiority over the existing task-specific state-of-the-arts."
"Gemma Canet Tarr'es, Dan Ruta, Tu Bui, J. Collomosse",7ae9a67624af75ed2e4df07185c8609bac05a61d,PARASOL: Parametric Style Control for Diffusion Image Synthesis,ArXiv,2023,0,"We propose PARASOL, a multi-modal synthesis model that enables disentangled, parametric control of the visual style of the image by jointly conditioning synthesis on both content and a fine-grained visual style embedding. We train a latent diffusion model (LDM) using specific losses for each modality and adapt the classifier-free guidance for encouraging disentangled control over independent content and style modalities at inference time. We leverage auxiliary semantic and style-based search to create training triplets for supervision of the LDM, ensuring complementarity of content and style cues. PARASOL shows promise for enabling nuanced control over visual style in diffusion models for image creation and stylization, as well as generative search where text-based search results may be adapted to more closely match user intent by interpolating both content and style descriptors."
"Xuhang Chen, Baiying Lei, Chi-Man Pun, Shuqiang Wang",62bcf8f08269e523b3f734aa6d9f38122dabc3c0,Brain Diffuser: An End-to-End Brain Image to Brain Network Pipeline,ArXiv,2023,0,"Brain network analysis is essential for diagnosing and intervention for Alzheimer's disease (AD). However, previous research relied primarily on specific time-consuming and subjective toolkits. Only few tools can obtain the structural brain networks from brain diffusion tensor images (DTI). In this paper, we propose a diffusion based end-to-end brain network generative model Brain Diffuser that directly shapes the structural brain networks from DTI. Compared to existing toolkits, Brain Diffuser exploits more structural connectivity features and disease-related information by analyzing disparities in structural brain networks across subjects. For the case of Alzheimer's disease, the proposed model performs better than the results from existing toolkits on the Alzheimer's Disease Neuroimaging Initiative (ADNI) database."
"Zhucheng Shao, Liuxi Dai, Yifeng Wang, Haoqian Wang, Yongbing Zhang",44029649b85c7e59bced3cacd1344d44fbd82526,AugDiff: Diffusion based Feature Augmentation for Multiple Instance Learning in Whole Slide Image,ArXiv,2023,0,"Multiple Instance Learning (MIL), a powerful strategy for weakly supervised learning, is able to perform various prediction tasks on gigapixel Whole Slide Images (WSIs). However, the tens of thousands of patches in WSIs usually incur a vast computational burden for image augmentation, limiting the MIL model's improvement in performance. Currently, the feature augmentation-based MIL framework is a promising solution, while existing methods such as Mixup often produce unrealistic features. To explore a more efficient and practical augmentation method, we introduce the Diffusion Model (DM) into MIL for the first time and propose a feature augmentation framework called AugDiff. Specifically, we employ the generation diversity of DM to improve the quality of feature augmentation and the step-by-step generation property to control the retention of semantic information. We conduct extensive experiments over three distinct cancer datasets, two different feature extractors, and three prevalent MIL algorithms to evaluate the performance of AugDiff. Ablation study and visualization further verify the effectiveness. Moreover, we highlight AugDiff's higher-quality augmented feature over image augmentation and its superiority over self-supervised learning. The generalization over external datasets indicates its broader applications."
"D. Coccomini, Andrea Esuli, F. Falchi, C. Gennaro, G. Amato",487531566c2d0f1475cae77cb794f67246afd1f3,Detecting Images Generated by Diffusers,ArXiv,2023,0,"This paper explores the task of detecting images generated by text-to-image diffusion models. To evaluate this, we consider images generated from captions in the MSCOCO and Wikimedia datasets using two state-of-the-art models: Stable Diffusion and GLIDE. Our experiments show that it is possible to detect the generated images using simple Multi-Layer Perceptrons (MLPs), starting from features extracted by CLIP, or traditional Convolutional Neural Networks (CNNs). We also observe that models trained on images generated by Stable Diffusion can detect images generated by GLIDE relatively well, however, the reverse is not true. Lastly, we find that incorporating the associated textual information with the images rarely leads to significant improvement in detection results but that the type of subject depicted in the image can have a significant impact on performance. This work provides insights into the feasibility of detecting generated images, and has implications for security and privacy concerns in real-world applications. The code to reproduce our results is available at: https://github.com/davide-coccomini/Detecting-Images-Generated-by-Diffusers"
"F. Bruckmaier, R. D. Allert, N. R. Neuling, P. Amrein, S. Littin, K. Briegel, P. Schatzle, P. Knittel, M. Zaitsev, D. Bucher",d9e97eeebf041f8efe5dce3226d53a0a0a2b0831,Imaging local diffusion in microstructures using NV-based pulsed field gradient NMR,,2023,0,"Understanding diffusion in microstructures plays a crucial role in many scientific fields, including neuroscience, cancer- or energy research. While magnetic resonance methods are the gold standard for quantitative diffusion measurements, they lack sensitivity in resolving and measuring diffusion within individual microstructures. Here, we introduce nitrogen-vacancy (NV) center based nuclear magnetic resonance (NMR) spectroscopy as a novel tool to probe diffusion in individual structures on microscopic length scales. We have developed a novel experimental scheme combining pulsed gradient spin echo (PGSE) with optically detected NV-NMR, which allows for the quantification of molecular diffusion and flow within nano-to-picoliter sample volumes. We demonstrate correlated optical imaging with spatially resolved PGSE NV-NMR experiments to probe anisotropic water diffusion within a model microstructure. Our method will extend the current capabilities of investigating diffusion processes to the microscopic length scale with the potential of probing single-cells, tissue microstructures, or ion mobility in thin film materials for battery applications."
"I. Leppert, Pietro Bontempi, C. Rowley, J. Campbell, Mark C. Nelson, S. Schiavi, G. B. Pike, Alessandro Daducci, C. Tardif",6b27d95cf04816d0a65657be9a312a99363f0a44,Dual-encoded magnetization transfer and diffusion imaging and its application to tract-specific microstructure mapping,,2023,0,"We present a novel dual-encoded magnetization transfer (MT) and diffusion-weighted sequence and demonstrate its potential to resolve distinct properties of white matter fiber tracts at the sub-voxel level. The sequence was designed and optimized for maximal MT contrast efficiency. The resulting whole brain 2.6 mm isotropic protocol to measure tract-specific MT ratio (MTR) has a scan time under 7 minutes. Ten healthy subjects were scanned twice to assess repeatability. Two different analysis methods were contrasted: a technique to extract tract-specific MTR using Convex Optimization Modeling for Microstructure Informed Tractography (COMMIT), a global optimization technique; and conventional MTR tractometry. The results demonstrate that the tract-specific method can reliably resolve the MT ratios of major white matter fiber pathways and is less affected by partial volume effects than conventional multi-modal tractometry. Dual-encoded MT and diffusion is expected to both increase the sensitivity to microstructure alterations of specific tracts due to disease, ageing or learning, as well as lead to weighted structural connectomes with more anatomical specificity."
"Wenliang Zhao, Yongming Rao, Zuyan Liu, Benlin Liu, Jie Zhou, Jiwen Lu",c09ca9da1fce13b1560f45c38321c7bb971f13fc,Unleashing Text-to-Image Diffusion Models for Visual Perception,ArXiv,2023,0,"Diffusion models (DMs) have become the new trend of generative models and have demonstrated a powerful ability of conditional synthesis. Among those, text-to-image diffusion models pre-trained on large-scale image-text pairs are highly controllable by customizable prompts. Unlike the unconditional generative models that focus on low-level attributes and details, text-to-image diffusion models contain more high-level knowledge thanks to the vision-language pre-training. In this paper, we propose VPD (Visual Perception with a pre-trained Diffusion model), a new framework that exploits the semantic information of a pre-trained text-to-image diffusion model in visual perception tasks. Instead of using the pre-trained denoising autoencoder in a diffusion-based pipeline, we simply use it as a backbone and aim to study how to take full advantage of the learned knowledge. Specifically, we prompt the denoising decoder with proper textual inputs and refine the text features with an adapter, leading to a better alignment to the pre-trained stage and making the visual contents interact with the text prompts. We also propose to utilize the cross-attention maps between the visual features and the text features to provide explicit guidance. Compared with other pre-training methods, we show that vision-language pre-trained diffusion models can be faster adapted to downstream visual perception tasks using the proposed VPD. Extensive experiments on semantic segmentation, referring image segmentation and depth estimation demonstrates the effectiveness of our method. Notably, VPD attains 0.254 RMSE on NYUv2 depth estimation and 73.3% oIoU on RefCOCO-val referring image segmentation, establishing new records on these two benchmarks. Code is available at https://github.com/wl-zhao/VPD"
"L. Guarnera, O. Giudice, S. Battiato",225abbd89d031023860d51376c1da899ad5e2eb1,Level Up the Deepfake Detection: a Method to Effectively Discriminate Images Generated by GAN Architectures and Diffusion Models,ArXiv,2023,0,"The image deepfake detection task has been greatly addressed by the scientific community to discriminate real images from those generated by Artificial Intelligence (AI) models: a binary classification task. In this work, the deepfake detection and recognition task was investigated by collecting a dedicated dataset of pristine images and fake ones generated by 9 different Generative Adversarial Network (GAN) architectures and by 4 additional Diffusion Models (DM). A hierarchical multi-level approach was then introduced to solve three different deepfake detection and recognition tasks: (i) Real Vs AI generated; (ii) GANs Vs DMs; (iii) AI specific architecture recognition. Experimental results demonstrated, in each case, more than 97% classification accuracy, outperforming state-of-the-art methods."
"Sahra Ghalebikesabi, Leonard Berrada, Sven Gowal, Ira Ktena, Robert Stanforth, Jamie Hayes, Soham De, Samuel L. Smith, Olivia Wiles, B. Balle",510a068ba6ce4979202e309a0eafb82d6d89f243,Differentially Private Diffusion Models Generate Useful Synthetic Images,ArXiv,2023,0,"The ability to generate privacy-preserving synthetic versions of sensitive image datasets could unlock numerous ML applications currently constrained by data availability. Due to their astonishing image generation quality, diffusion models are a prime candidate for generating high-quality synthetic data. However, recent studies have found that, by default, the outputs of some diffusion models do not preserve training data privacy. By privately fine-tuning ImageNet pre-trained diffusion models with more than 80M parameters, we obtain SOTA results on CIFAR-10 and Camelyon17 in terms of both FID and the accuracy of downstream classifiers trained on synthetic data. We decrease the SOTA FID on CIFAR-10 from 26.2 to 9.8, and increase the accuracy from 51.0% to 88.0%. On synthetic data from Camelyon17, we achieve a downstream accuracy of 91.1% which is close to the SOTA of 96.5% when training on the real data. We leverage the ability of generative models to create infinite amounts of data to maximise the downstream prediction performance, and further show how to use synthetic data for hyperparameter tuning. Our results demonstrate that diffusion models fine-tuned with differential privacy can produce useful and provably private synthetic data, even in applications with significant distribution shift between the pre-training and fine-tuning distributions."
"Yingnan Xue, Min-Jie Wen, Qiong Ye",c3106fff366baf3fd74748c2478d641937494dcb,Characterize the non-Gaussian diffusion property of cerebrospinal fluid using Diffusion Kurtosis Imaging and explore its diagnostic efficacy for Alzheimer's disease,,2023,0,"Differentiating Alzheimer's disease (AD) patients from healthy controls (HCs) remains a challenge. The changes of protein level in cerebrospinal fluid (CSF) of AD patients have been reported in the literature. Macromolecules will hinder the movement of water in CSF and lead to non-Gaussian diffusion. Diffusion kurtosis imaging (DKI) is a commonly used technique for quantifying non-Gaussian diffusivity. In this study, we used DKI to evaluate the non-Gaussian diffusion of CSF in AD patients and HC. Between-group difference was explored. In addition, we have built a prediction model using cross-validation Support Vector Machines (SVM), and achieved excellent performance. The validated area under the receiver operating characteristic curve(AUC) is in the range of 0.96-1.00, and the correct prediction is in the range of 87.1% - 90.0%."
Haoran Ma,50c1aa7b296aa4ebb4f007b4ffa4d3416ca300ab,Text Semantics to Image Generation: A method of building facades design base on Stable Diffusion model,,2023,0,"Stable Diffusion model has been extensively employed in the study of archi-tectural image generation, but there is still an opportunity to enhance in terms of the controllability of the generated image content. A multi-network combined text-to-building facade image generating method is proposed in this work. We first fine-tuned the Stable Diffusion model on the CMP Fa-cades dataset using the LoRA (Low-Rank Adaptation) approach, then we ap-ply the ControlNet model to further control the output. Finally, we contrast-ed the facade generating outcomes under various architectural style text con-tents and control strategies. The results demonstrate that the LoRA training approach significantly decreases the possibility of fine-tuning the Stable Dif-fusion large model, and the addition of the ControlNet model increases the controllability of the creation of text to building facade images. This pro-vides a foundation for subsequent studies on the generation of architectural images."
"Nisha Huang, Fan Tang, Weiming Dong, Tong-Yee Lee, Changsheng Xu",cdd53edde3c989381bb4e71aec4bea0a2755d3fe,Region-Aware Diffusion for Zero-shot Text-driven Image Editing,ArXiv,2023,0,"Image manipulation under the guidance of textual descriptions has recently received a broad range of attention. In this study, we focus on the regional editing of images with the guidance of given text prompts. Different from current mask-based image editing methods, we propose a novel region-aware diffusion model (RDM) for entity-level image editing, which could automatically locate the region of interest and replace it following given text prompts. To strike a balance between image fidelity and inference speed, we design the intensive diffusion pipeline by combing latent space diffusion and enhanced directional guidance. In addition, to preserve image content in non-edited regions, we introduce regional-aware entity editing to modify the region of interest and preserve the out-of-interest region. We validate the proposed RDM beyond the baseline methods through extensive qualitative and quantitative experiments. The results show that RDM outperforms the previous approaches in terms of visual quality, overall harmonization, non-editing region content preservation, and text-image semantic consistency. The codes are available at https://github.com/haha-lisa/RDM-Region-Aware-Diffusion-Model."
"Xiaodong Wang, Chenfei Wu, S. Yin, Minheng Ni, Jianfeng Wang, Linjie Li, Zhengyuan Yang, Fan Yang, Lijuan Wang, Zicheng Liu, Yuejian Fang, Nan Duan",0aeb1cde8d78b5dfe9f6a2e9afde596a94268e56,Learning 3D Photography Videos via Self-supervised Diffusion on Single Images,ArXiv,2023,0,"3D photography renders a static image into a video with appealing 3D visual effects. Existing approaches typically first conduct monocular depth estimation, then render the input frame to subsequent frames with various viewpoints, and finally use an inpainting model to fill those missing/occluded regions. The inpainting model plays a crucial role in rendering quality, but it is normally trained on out-of-domain data. To reduce the training and inference gap, we propose a novel self-supervised diffusion model as the inpainting module. Given a single input image, we automatically construct a training pair of the masked occluded image and the ground-truth image with random cycle-rendering. The constructed training samples are closely aligned to the testing instances, without the need of data annotation. To make full use of the masked images, we design a Masked Enhanced Block (MEB), which can be easily plugged into the UNet and enhance the semantic conditions. Towards real-world animation, we present a novel task: out-animation, which extends the space and time of input objects. Extensive experiments on real datasets show that our method achieves competitive results with existing SOTA methods."
"Luke Melas-Kyriazi, C. Rupprecht, A. Vedaldi",1443e79c8ae586d792d3546c46a31d305225664c,PC2: Projection-Conditioned Point Cloud Diffusion for Single-Image 3D Reconstruction,ArXiv,2023,0,"Reconstructing the 3D shape of an object from a single RGB image is a long-standing and highly challenging problem in computer vision. In this paper, we propose a novel method for single-image 3D reconstruction which generates a sparse point cloud via a conditional denoising diffusion process. Our method takes as input a single RGB image along with its camera pose and gradually denoises a set of 3D points, whose positions are initially sampled randomly from a three-dimensional Gaussian distribution, into the shape of an object. The key to our method is a geometrically-consistent conditioning process which we call projection conditioning: at each step in the diffusion process, we project local image features onto the partially-denoised point cloud from the given camera pose. This projection conditioning process enables us to generate high-resolution sparse geometries that are well-aligned with the input image, and can additionally be used to predict point colors after shape reconstruction. Moreover, due to the probabilistic nature of the diffusion process, our method is naturally capable of generating multiple different shapes consistent with a single input image. In contrast to prior work, our approach not only performs well on synthetic benchmarks, but also gives large qualitative improvements on complex real-world data."
"Martin Zach, T. Pock, Erich Kobler, A. Chambolle",b994823ff2d2e9e06aeca31c5ce7fa34f9127aa9,Explicit Diffusion of Gaussian Mixture Model Based Image Priors,ArXiv,2023,0,"In this work we tackle the problem of estimating the density $f_X$ of a random variable $X$ by successive smoothing, such that the smoothed random variable $Y$ fulfills $(\partial_t - \Delta_1)f_Y(\,\cdot\,, t) = 0$, $f_Y(\,\cdot\,, 0) = f_X$. With a focus on image processing, we propose a product/fields of experts model with Gaussian mixture experts that admits an analytic expression for $f_Y (\,\cdot\,, t)$ under an orthogonality constraint on the filters. This construction naturally allows the model to be trained simultaneously over the entire diffusion horizon using empirical Bayes. We show preliminary results on image denoising where our model leads to competitive results while being tractable, interpretable, and having only a small number of learnable parameters. As a byproduct, our model can be used for reliable noise estimation, allowing blind denoising of images corrupted by heteroscedastic noise."
"Jiaxin Cheng, Xiao Liang, Xingjian Shi, Tong He, Tianjun Xiao, Mu Li",00b167a24f57f96294a4581bb185a57b0a4af365,LayoutDiffuse: Adapting Foundational Diffusion Models for Layout-to-Image Generation,ArXiv,2023,0,"Layout-to-image generation refers to the task of synthesizing photo-realistic images based on semantic layouts. In this paper, we propose LayoutDiffuse that adapts a foundational diffusion model pretrained on large-scale image or text-image datasets for layout-to-image generation. By adopting a novel neural adaptor based on layout attention and task-aware prompts, our method trains efficiently, generates images with both high perceptual quality and layout alignment, and needs less data. Experiments on three datasets show that our method significantly outperforms other 10 generative models based on GANs, VQ-VAE, and diffusion models."
"Zhi-Ke Liu, Yang Shen, Han-Ling Li, B. Cao",946a5198f56033c3744a0429bb0bc20093050f05,Observation of ballistic-diffusive thermal transport in GaN transistors using thermoreflectance thermal imaging,,2023,0,"To develop effective thermal management strategies for GaN transistors, it is essential to accurately predict the device junction temperature. Since the width of the heat generation in the devices is comparable to phonon mean free paths of GaN, phonon ballistic transport exists and can significantly affect the heat transport process, which necessitates a thorough understanding of the influence of the phonon ballistic effects in GaN transistors. In this paper, the ballistic-diffusive phonon transport in GaN-on-SiC devices is examined by measuring the hotspot temperature using the thermoreflectance thermal imaging TTI combined with the hybrid phonon Monte Carlo-diffusion simulations. A series of Au heaters are fabricated on the top of the GaN layer to quantitatively mimic the different heat source distributions during device operation. The experimental and simulation results show a good consistency and both indicate that the phonon ballistic effects can significantly increase the hotspot temperature. With the size of the heat source decreasing, the errors of Fourier's law-based predictions increase, which emphasizes the necessity to carefully consider the phonon ballistic transport in device thermal simulations."
"Hareesh Ravi, Sachin Kelkar, Midhun Harikumar, Ajinkya Kale",7dd7e87772799a62a6d4dbe26616c3b5eb7ae72c,PRedItOR: Text Guided Image Editing with Diffusion Prior,ArXiv,2023,0,"Diffusion models have shown remarkable capabilities in generating high quality and creative images conditioned on text. An interesting application of such models is structure preserving text guided image editing. Existing approaches rely on text conditioned diffusion models such as Stable Diffusion or Imagen and require compute intensive optimization of text embeddings or fine-tuning the model weights for text guided image editing. We explore text guided image editing with a Hybrid Diffusion Model (HDM) architecture similar to DALLE-2. Our architecture consists of a diffusion prior model that generates CLIP image embedding conditioned on a text prompt and a custom Latent Diffusion Model trained to generate images conditioned on CLIP image embedding. We discover that the diffusion prior model can be used to perform text guided conceptual edits on the CLIP image embedding space without any finetuning or optimization. We combine this with structure preserving edits on the image decoder using existing approaches such as reverse DDIM to perform text guided image editing. Our approach, PRedItOR does not require additional inputs, fine-tuning, optimization or objectives and shows on par or better results than baselines qualitatively and quantitatively. We provide further analysis and understanding of the diffusion prior model and believe this opens up new possibilities in diffusion models research."
Y. Sabharwal,7af7ab8d6f0cdea4f39da9f6036073331bb46157,NephroNet: A Novel Program for Identifying Renal Cell Carcinoma and Generating Synthetic Training Images with Convolutional Neural Networks and Diffusion Models,ArXiv,2023,0,"Renal cell carcinoma (RCC) is a type of cancer that originates in the kidneys and is the most common type of kidney cancer in adults. It can be classified into several subtypes, including clear cell RCC, papillary RCC, and chromophobe RCC. In this study, an artificial intelligence model was developed and trained for classifying different subtypes of RCC using ResNet-18, a convolutional neural network that has been widely used for image classification tasks. The model was trained on a dataset of RCC histopathology images, which consisted of digital images of RCC surgical resection slides that were annotated with the corresponding subtype labels. The performance of the trained model was evaluated using several metrics, including accuracy, precision, and recall. Additionally, in this research, a novel synthetic image generation tool, NephroNet, is developed on diffusion models that are used to generate original images of RCC surgical resection slides. Diffusion models are a class of generative models capable of synthesizing high-quality images from noise. Several diffusers such as Stable Diffusion, Dreambooth Text-to-Image, and Textual Inversion were trained on a dataset of RCC images and were used to generate a series of original images that resembled RCC surgical resection slides, all within the span of fewer than four seconds. The generated images were visually realistic and could be used for creating new training datasets, testing the performance of image analysis algorithms, and training medical professionals. NephroNet is provided as an open-source software package and contains files for data preprocessing, training, and visualization. Overall, this study demonstrates the potential of artificial intelligence and diffusion models for classifying and generating RCC images, respectively. These methods could be useful for improving the diagnosis and treatment of RCC and more."
"Bo Li, Xiaolin K. Wei, F. Chen, Bin Liu",5a3a84f8663f72050c7314038b4969ad13b804f7,3D Colored Shape Reconstruction from a Single RGB Image through Diffusion,ArXiv,2023,0,"We propose a novel 3d colored shape reconstruction method from a single RGB image through diffusion model. Diffusion models have shown great development potentials for high-quality 3D shape generation. However, most existing work based on diffusion models only focus on geometric shape generation, they cannot either accomplish 3D reconstruction from a single image, or produce 3D geometric shape with color information. In this work, we propose to reconstruct a 3D colored shape from a single RGB image through a novel conditional diffusion model. The reverse process of the proposed diffusion model is consisted of three modules, shape prediction module, color prediction module and NeRF-like rendering module. In shape prediction module, the reference RGB image is first encoded into a high-level shape feature and then the shape feature is utilized as a condition to predict the reverse geometric noise in diffusion model. Then the color of each 3D point updated in shape prediction module is predicted by color prediction module. Finally, a NeRF-like rendering module is designed to render the colored point cloud predicted by the former two modules to 2D image space to guide the training conditioned only on a reference image. As far as the authors know, the proposed method is the first diffusion model for 3D colored shape reconstruction from a single RGB image. Experimental results demonstrate that the proposed method achieves competitive performance on colored 3D shape reconstruction, and the ablation study validates the positive role of the color prediction module in improving the reconstruction quality of 3D geometric point cloud."
"Haiyang Yu, M. Zhu, Jin-Long Xu, M. Ai, P. Jiang, Yanbin Yang",1d8258377c1a2575abb6ca3214f5a2b49dc49e08,High sensitivity HI image of diffuse gas and new tidal features in M51 observed by FAST,,2023,0,"We observed the classical interacting galaxy M51 with FAST and obtain high sensitivity HI image with column density down to 3.8 $\times$ 10$^{18}$ cm$^{-2}$. In the image we can see a diffuse extended envelope around the system and several new tidal features. We also get a deeper look at M51b's probable gas, which has an approximated velocity range of 560 to 740 km s$^{-1}$ and a flux of 7.5 Jy km s$^{-1}$. Compared to the VLA image, we observe more complete structures of the Southeast Tail, Northeast Cloud and Northwest Plume, as well as new features of the Northwest Cloud and Southwest Plume. M51's most prominent tidal feature, the Southeast Tail, looks very long and broad, in addition with two small detached clouds at the periphery. Due to the presence of optical and simulated counterparts, the Northwest cloud appears to be the tail of M51a, while the Northwest Plume is more likely a tidal tail of M51b. The large mass of the Northwest Plume suggests that M51b may have been as gas-rich as M51a before the interaction. In addition, the formation process of the Northeast Cloud and Southwest Plume is obscured by the lack of optical and simulated counterparts. These novel tidal features, together with M51b's probable gas, will inspire future simulations and provide a deeper understanding of the evolution of this interacting system."
"Yutong Xie, Minne Yuan, Bin Dong, Quanzheng Li",6c08f74b8b41cb6f4c36816e81212dc9dbdfadac,Diffusion Model for Generative Image Denoising,ArXiv,2023,0,"In supervised learning for image denoising, usually the paired clean images and noisy images are collected or synthesised to train a denoising model. L2 norm loss or other distance functions are used as the objective function for training. It often leads to an over-smooth result with less image details. In this paper, we regard the denoising task as a problem of estimating the posterior distribution of clean images conditioned on noisy images. We apply the idea of diffusion model to realize generative image denoising. According to the noise model in denoising tasks, we redefine the diffusion process such that it is different from the original one. Hence, the sampling of the posterior distribution is a reverse process of dozens of steps from the noisy image. We consider three types of noise model, Gaussian, Gamma and Poisson noise. With the guarantee of theory, we derive a unified strategy for model training. Our method is verified through experiments on three types of noise models and achieves excellent performance."
"Zuopeng Yang, Tianshu Chu, Xin Lin, Erdun Gao, Daqing Liu, J. Yang, Chaoyue Wang",d4a8cc570b311d8b6566608856202fa7ccc57e4a,Eliminating Prior Bias for Semantic Image Editing via Dual-Cycle Diffusion,ArXiv,2023,0,"The recent success of text-to-image generation diffusion models has also revolutionized semantic image editing, enabling the manipulation of images based on query/target texts. Despite these advancements, a significant challenge lies in the potential introduction of prior bias in pre-trained models during image editing, e.g., making unexpected modifications to inappropriate regions. To this point, we present a novel Dual-Cycle Diffusion model that addresses the issue of prior bias by generating an unbiased mask as the guidance of image editing. The proposed model incorporates a Bias Elimination Cycle that consists of both a forward path and an inverted path, each featuring a Structural Consistency Cycle to ensure the preservation of image content during the editing process. The forward path utilizes the pre-trained model to produce the edited image, while the inverted path converts the result back to the source image. The unbiased mask is generated by comparing differences between the processed source image and the edited image to ensure that both conform to the same distribution. Our experiments demonstrate the effectiveness of the proposed method, as it significantly improves the D-CLIP score from 0.272 to 0.283. The code will be available at https://github.com/JohnDreamer/DualCycleDiffsion."
"Shiqi Sun, Shancheng Fang, Qian He, Wei Liu",caad1ac46f688d6623c95c81f1bbd0613d8c17e9,Design Booster: A Text-Guided Diffusion Model for Image Translation with Spatial Layout Preservation,ArXiv,2023,0,"Diffusion models are able to generate photorealistic images in arbitrary scenes. However, when applying diffusion models to image translation, there exists a trade-off between maintaining spatial structure and high-quality content. Besides, existing methods are mainly based on test-time optimization or fine-tuning model for each input image, which are extremely time-consuming for practical applications. To address these issues, we propose a new approach for flexible image translation by learning a layout-aware image condition together with a text condition. Specifically, our method co-encodes images and text into a new domain during the training phase. In the inference stage, we can choose images/text or both as the conditions for each time step, which gives users more flexible control over layout and content. Experimental comparisons of our method with state-of-the-art methods demonstrate our model performs best in both style image translation and semantic image translation and took the shortest time."
"Arian Bakhtiarnia, Qi Zhang, A. Iosifidis",27a2fcf61e056590959099b551ed9709caa5b7bd,PromptMix: Text-to-image diffusion models enhance the performance of lightweight networks,ArXiv,2023,0,"Many deep learning tasks require annotations that are too time consuming for human operators, resulting in small dataset sizes. This is especially true for dense regression problems such as crowd counting which requires the location of every person in the image to be annotated. Techniques such as data augmentation and synthetic data generation based on simulations can help in such cases. In this paper, we introduce PromptMix, a method for artificially boosting the size of existing datasets, that can be used to improve the performance of lightweight networks. First, synthetic images are generated in an end-to-end data-driven manner, where text prompts are extracted from existing datasets via an image captioning deep network, and subsequently introduced to text-to-image diffusion models. The generated images are then annotated using one or more high-performing deep networks, and mixed with the real dataset for training the lightweight network. By extensive experiments on five datasets and two tasks, we show that PromptMix can significantly increase the performance of lightweight networks by up to 26%."
"Shangrong Yang, Chunyu Lin, K. Liao, Yao Zhao",fdb3f2663de9ead6a6f013faa9706e44e3ba510b,Dual Diffusion Architecture for Fisheye Image Rectification: Synthetic-to-Real Generalization,ArXiv,2023,0,"Fisheye image rectification has a long-term unresolved issue with synthetic-to-real generalization. In most previous works, the model trained on the synthetic images obtains unsatisfactory performance on the real-world fisheye image. To this end, we propose a Dual Diffusion Architecture (DDA) for the fisheye rectification with a better generalization ability. The proposed DDA is simultaneously trained with paired synthetic fisheye images and unlabeled real fisheye images. By gradually introducing noises, the synthetic and real fisheye images can eventually develop into a consistent noise distribution, improving the generalization and achieving unlabeled real fisheye correction. The original image serves as the prior guidance in existing DDPMs (Denoising Diffusion Probabilistic Models). However, the non-negligible indeterminate relationship between the prior condition and the target affects the generation performance. Especially in the rectification task, the radial distortion can cause significant artifacts. Therefore, we provide an unsupervised one-pass network that produces a plausible new condition to strengthen guidance. This network can be regarded as an alternate scheme for fast producing reliable results without iterative inference. Compared with the state-of-the-art methods, our approach can reach superior performance in both synthetic and real fisheye image corrections."
"Mingqiang Wei, Yiyang Shen, Yongzhen Wang, H. Xie, F. Wang",7a896376f47f42a86414800f5f3c805b9ee6717b,RainDiffusion: When Unsupervised Learning Meets Diffusion Models for Real-world Image Deraining,ArXiv,2023,0,"Recent diffusion models show great potential in generative modeling tasks. This motivates us to raise an intriguing question - What will happen when unsupervised learning meets diffusion models for real-world image deraining? Before answering it, we observe two major obstacles of diffusion models in real-world image deraining: the need for paired training data and the limited utilization of multi-scale rain patterns. To overcome the obstacles, we propose RainDiffusion, the first real-world image deraining paradigm based on diffusion models. RainDiffusion is a non-adversarial training paradigm that introduces stable training of unpaired real-world data, rather than weakly adversarial training, serving as a new standard bar for real-world image deraining. It consists of two cooperative branches: Non-diffusive Translation Branch (NTB) and Diffusive Translation Branch (DTB). NTB exploits a cycle-consistent architecture to bypass the difficulty in unpaired training of regular diffusion models by generating initial clean/rainy image pairs. Given initial image pairs, DTB leverages multi-scale diffusion models to progressively refine the desired output via diffusive generative and multi-scale priors, to obtain a better generalization capacity of real-world image deraining. Extensive experiments confirm the superiority of our RainDiffusion over eight un/semi-supervised methods and show its competitive advantages over seven fully-supervised ones."
"Mona Selim, J. Zhang, Michael A. Brooks, Ge Wang, Jin Chen",3167120a52ed5103cc13b807aae7eb1379707ff0,DiffusionCT: Latent Diffusion Model for CT Image Standardization,ArXiv,2023,0,"Computed tomography (CT) is one of the modalities for effective lung cancer screening, diagnosis, treatment, and prognosis. The features extracted from CT images are now used to quantify spatial and temporal variations in tumors. However, CT images obtained from various scanners with customized acquisition protocols may introduce considerable variations in texture features, even for the same patient. This presents a fundamental challenge to downstream studies that require consistent and reliable feature analysis. Existing CT image harmonization models rely on GAN-based supervised or semi-supervised learning, with limited performance. This work addresses the issue of CT image harmonization using a new diffusion-based model, named DiffusionCT, to standardize CT images acquired from different vendors and protocols. DiffusionCT operates in the latent space by mapping a latent non-standard distribution into a standard one. DiffusionCT incorporates an Unet-based encoder-decoder, augmented by a diffusion model integrated into the bottleneck part. The model is designed in two training phases. The encoder-decoder is first trained, without embedding the diffusion model, to learn the latent representation of the input data. The latent diffusion model is then trained in the next training phase while fixing the encoder-decoder. Finally, the decoder synthesizes a standardized image with the transformed latent representation. The experimental results demonstrate a significant improvement in the performance of the standardization task using DiffusionCT."
"Jun Yue, Leyuan Fang, Shaobo Xia, Yue Deng, Jiayi Ma",170f080ad2f8a9a0914ac791690a5a5878dbd636,Dif-Fusion: Towards High Color Fidelity in Infrared and Visible Image Fusion with Diffusion Models,ArXiv,2023,0,"Color plays an important role in human visual perception, reflecting the spectrum of objects. However, the existing infrared and visible image fusion methods rarely explore how to handle multi-spectral/channel data directly and achieve high color fidelity. This paper addresses the above issue by proposing a novel method with diffusion models, termed as Dif-Fusion, to generate the distribution of the multi-channel input data, which increases the ability of multi-source information aggregation and the fidelity of colors. In specific, instead of converting multi-channel images into single-channel data in existing fusion methods, we create the multi-channel data distribution with a denoising network in a latent space with forward and reverse diffusion process. Then, we use the the denoising network to extract the multi-channel diffusion features with both visible and infrared information. Finally, we feed the multi-channel diffusion features to the multi-channel fusion module to directly generate the three-channel fused image. To retain the texture and intensity information, we propose multi-channel gradient loss and intensity loss. Along with the current evaluation metrics for measuring texture and intensity fidelity, we introduce a new evaluation metric to quantify color fidelity. Extensive experiments indicate that our method is more effective than other state-of-the-art image fusion methods, especially in color fidelity."
"Yuhang Li, Yilin Luo, Deniz Mengu, Bijie Bai, Aydogan Ozcan",60837ad1f883434d27ce375f9b3e6c97c907e256,Quantitative phase imaging (QPI) through random diffusers using a diffractive optical network,,2023,0,"Quantitative phase imaging (QPI) is a label-free computational imaging technique used in various fields, including biology and medical research. Modern QPI systems typically rely on digital processing using iterative algorithms for phase retrieval and image reconstruction. Here, we report a diffractive optical network trained to convert the phase information of input objects positioned behind random diffusers into intensity variations at the output plane, all-optically performing phase recovery and quantitative imaging of phase objects completely hidden by unknown, random phase diffusers. This QPI diffractive network is composed of successive diffractive layers, axially spanning in total ~70 𝜆𝜆 , where 𝜆𝜆 is the illumination wavelength; unlike existing digital image reconstruction and phase retrieval methods, it forms an all-optical processor that does not require external power beyond the illumination beam to complete its QPI reconstruction at the speed of light propagation. This all-optical diffractive processor can provide a low-power, high frame rate and compact alternative for quantitative imaging of phase objects through random, unknown diffusers and can operate at different parts of the electromagnetic spectrum for various applications in biomedical imaging and sensing. The presented QPI diffractive designs can be integrated onto the active area of standard CCD/CMOS-based image sensors to convert an existing optical microscope into a diffractive QPI microscope, performing phase recovery and image reconstruction on a chip through light diffraction within passive structured layers."
Jiageng Zheng,e08536a44637d8c7f39cc6af0e9bfee4911ac20c,Targeted Image Reconstruction by Sampling Pre-trained Diffusion Model,ArXiv,2023,0,"A trained neural network model contains information on the training data. Given such a model, malicious parties can leverage the ”knowledge” in this model and design ways to print out any usable information. Therefore, it is valuable to explore the ways to conduct a such attack and demonstrate its severity. In this work, we proposed ways to generate a data point of the target class without prior knowledge of the exact target distribution by using a pre-trained diffusion model."
"Michael Cahyadi, M. Rafi, William Shan, J. Moniaga, Henry Lucky",a0d828956d0703c08992e7f0e6eb257955b85725,Accuracy and Fidelity Comparison of Luna and DALL-E 2 Diffusion-Based Image Generation Systems,ArXiv,2023,0,"We qualitatively examine the accuracy and fidelity between two diffusion-based image generation systems, namely DALL-E 2 and Luna, which have massive differences in training datasets, algorithmic approaches, prompt resolvement, and output upscaling. The methodology used is a qualitative benchmark created by Saharia et al. and in our research we conclude that DALL-E 2 significantly edges Luna in both alignment and fidelity comparisons."
"N. Dehouche, Kullathida Dehouche",39e7cdc762118540c3b942a21535ac1caa5c341d,What is in a Text-to-Image Prompt: The Potential of Stable Diffusion in Visual Arts Education,ArXiv,2023,0,": Text-to-Image artiﬁcial intelligence (AI) recently saw a major breakthrough with the release of Dall-E and its open-source counterpart, Stable Diﬀusion. These programs allow anyone to create original visual art pieces by simply providing descriptions in natural language (prompts). Using a sample of 72,980 Stable Diﬀusion prompts, we propose a formalization of this new medium of art creation and assess its potential for teaching the history of art, aesthetics, and technique. Our ﬁndings indicate that text-to-Image AI has the potential to revolutionize the way art is taught, oﬀering new, cost-eﬀective possibilities for experimentation and expression. However, it also raises important questions about the ownership of artistic works. As more and more art is created using these programs, it will be crucial to establish new legal and economic models to protect the rights of artists."
"D. Eschweiler, J. Stegmaier",62f8ba2079aaa11896b48db9a4681948a37af32e,Denoising Diffusion Probabilistic Models for Generation of Realistic Fully-Annotated Microscopy Image Data Sets,ArXiv,2023,0,". Denoising diﬀusion probabilistic models have shown great potential in generating realistic image data. We show how those models can be used to generate realistic microscopy image data in 2D and 3D based on simulated sketches of cellular structures. Multiple data sets are used as an inspiration to simulate sketches of diﬀerent cellular structures, allowing to generate fully-annotated image data sets without requiring human interactions. Those data sets are used to train segmentation approaches and demonstrate that annotation-free segmentation of cellular structures in ﬂuorescence microscopy image data can be achieved, thereby leaping towards the ultimate goal of eliminating the necessity of human annotation eﬀorts."
"Shizhan Gong, Cheng Chen, Yuqi Gong, Nga Yan Chan, Wenao Ma, C. Mak, J. Abrigo, Q. Dou",50ca0a8858e8b56169134608844c824ab2f67d83,Diffusion Model based Semi-supervised Learning on Brain Hemorrhage Images for Efficient Midline Shift Quantification,ArXiv,2023,0,". Brain midline shift (MLS) is one of the most critical factors to be considered for clinical diagnosis and treatment decision-making for intracranial hemorrhage. Existing computational methods on MLS quantiﬁcation not only require intensive labeling in millimeter-level measurement but also suﬀer from poor performance due to their dependence on speciﬁc landmarks or simpliﬁed anatomical assumptions. In this paper, we propose a novel semi-supervised framework to accurately measure the scale of MLS from head CT scans. We formulate the MLS measurement task as a deformation estimation problem and solve it using a few MLS slices with sparse labels. Meanwhile, with the help of diﬀusion models, we are able to use a great number of unlabeled MLS data and 2793 non-MLS cases for representation learning and regularization. The extracted representation reﬂects how the image is diﬀerent from a non-MLS image and regularization serves an important role in the sparse-to-dense reﬁnement of the deformation ﬁeld. Our experiment on a real clinical brain hemorrhage dataset has achieved state-of-the-art performance and can generate interpretable deformation ﬁelds."
"Chitwan Saharia, William Chan, Saurabh Saxena, Lala Li, Jay Whang, Emily L. Denton, Seyed Kamyar Seyed Ghasemipour, Burcu Karagol Ayan, S. S. Mahdavi, Raphael Gontijo Lopes, Tim Salimans, Jonathan Ho, David J. Fleet, Mohammad Norouzi",9695824d7a01fad57ba9c01d7d76a519d78d65e7,Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding,ArXiv,2022,716,"We present Imagen, a text-to-image diffusion model with an unprecedented degree of photorealism and a deep level of language understanding. Imagen builds on the power of large transformer language models in understanding text and hinges on the strength of diffusion models in high-fidelity image generation. Our key discovery is that generic large language models (e.g. T5), pretrained on text-only corpora, are surprisingly effective at encoding text for image synthesis: increasing the size of the language model in Imagen boosts both sample fidelity and image-text alignment much more than increasing the size of the image diffusion model. Imagen achieves a new state-of-the-art FID score of 7.27 on the COCO dataset, without ever training on COCO, and human raters find Imagen samples to be on par with the COCO data itself in image-text alignment. To assess text-to-image models in greater depth, we introduce DrawBench, a comprehensive and challenging benchmark for text-to-image models. With DrawBench, we compare Imagen with recent methods including VQ-GAN+CLIP, Latent Diffusion Models, and DALL-E 2, and find that human raters prefer Imagen over other models in side-by-side comparisons, both in terms of sample quality and image-text alignment. See https://imagen.research.google/ for an overview of the results."
"Jonathan Ho, William Chan, Chitwan Saharia, Jay Whang, Ruiqi Gao, A. Gritsenko, Diederik P. Kingma, Ben Poole, Mohammad Norouzi, David J. Fleet, Tim Salimans",498ac9b2e494601d20a3d0211c16acf2b7954a54,Imagen Video: High Definition Video Generation with Diffusion Models,ArXiv,2022,118,"We present Imagen Video, a text-conditional video generation system based on a cascade of video diffusion models. Given a text prompt, Imagen Video generates high definition videos using a base video generation model and a sequence of interleaved spatial and temporal video super-resolution models. We describe how we scale up the system as a high definition text-to-video model including design decisions such as the choice of fully-convolutional temporal and spatial super-resolution models at certain resolutions, and the choice of the v-parameterization of diffusion models. In addition, we confirm and transfer findings from previous work on diffusion-based image generation to the video generation setting. Finally, we apply progressive distillation to our video models with classifier-free guidance for fast, high quality sampling. We find Imagen Video not only capable of generating videos of high fidelity, but also having a high degree of controllability and world knowledge, including the ability to generate diverse videos and text animations in various artistic styles and with 3D object understanding. See https://imagen.research.google/video/ for samples."
"Bahjat Kawar, Shiran Zada, Oran Lang, Omer Tov, Hui-Tang Chang, Tali Dekel, Inbar Mosseri, M. Irani",23e261a20a315059b4de5492ed071c97a20c12e7,Imagic: Text-Based Real Image Editing with Diffusion Models,ArXiv,2022,104,"Text-conditioned image editing has recently attracted considerable interest. However, most methods are currently either limited to specific editing types (e.g., object overlay, style transfer), or apply to synthetically generated images, or require multiple input images of a common object. In this paper we demonstrate, for the very first time, the ability to apply complex (e.g., non-rigid) text-guided semantic edits to a single real image. For example, we can change the posture and composition of one or multiple objects inside an image, while preserving its original characteristics. Our method can make a standing dog sit down or jump, cause a bird to spread its wings, etc. -- each within its single high-resolution natural image provided by the user. Contrary to previous work, our proposed method requires only a single input image and a target text (the desired edit). It operates on real images, and does not require any additional inputs (such as image masks or additional views of the object). Our method, which we call""Imagic"", leverages a pre-trained text-to-image diffusion model for this task. It produces a text embedding that aligns with both the input image and the target text, while fine-tuning the diffusion model to capture the image-specific appearance. We demonstrate the quality and versatility of our method on numerous inputs from various domains, showcasing a plethora of high quality complex semantic image edits, all within a single unified framework."
"Nataniel Ruiz, Yuanzhen Li, Varun Jampani, Y. Pritch, Michael Rubinstein, Kfir Aberman",5b19bf6c3f4b25cac96362c98b930cf4b37f6744,DreamBooth: Fine Tuning Text-to-Image Diffusion Models for Subject-Driven Generation,ArXiv,2022,94,"Large text-to-image models achieved a remarkable leap in the evolution of AI, enabling high-quality and diverse synthesis of images from a given text prompt. However, these models lack the ability to mimic the appearance of subjects in a given reference set and synthesize novel renditions of them in different contexts. In this work, we present a new approach for""personalization""of text-to-image diffusion models. Given as input just a few images of a subject, we fine-tune a pretrained text-to-image model such that it learns to bind a unique identifier with that specific subject. Once the subject is embedded in the output domain of the model, the unique identifier can be used to synthesize novel photorealistic images of the subject contextualized in different scenes. By leveraging the semantic prior embedded in the model with a new autogenous class-specific prior preservation loss, our technique enables synthesizing the subject in diverse scenes, poses, views and lighting conditions that do not appear in the reference images. We apply our technique to several previously-unassailable tasks, including subject recontextualization, text-guided view synthesis, and artistic rendering, all while preserving the subject's key features. We also provide a new dataset and evaluation protocol for this new task of subject-driven generation. Project page: https://dreambooth.github.io/"
"Y. Balaji, Seungjun Nah, Xun Huang, Arash Vahdat, Jiaming Song, Qinsheng Zhang, Karsten Kreis, M. Aittala, Timo Aila, S. Laine, Bryan Catanzaro, Tero Karras, Ming-Yu Liu",e24f4b28167b05fbf7d29000490fc0a4e4c109c7,eDiff-I: Text-to-Image Diffusion Models with an Ensemble of Expert Denoisers,ArXiv,2022,76,"Large-scale diffusion-based generative models have led to breakthroughs in text-conditioned high-resolution image synthesis. Starting from random noise, such text-to-image diffusion models gradually synthesize images in an iterative fashion while conditioning on text prompts. We find that their synthesis behavior qualitatively changes throughout this process: Early in sampling, generation strongly relies on the text prompt to generate text-aligned content, while later, the text conditioning is almost entirely ignored. This suggests that sharing model parameters throughout the entire generation process may not be ideal. Therefore, in contrast to existing works, we propose to train an ensemble of text-to-image diffusion models specialized for different synthesis stages. To maintain training efficiency, we initially train a single model, which is then split into specialized models that are trained for the specific stages of the iterative generation process. Our ensemble of diffusion models, called eDiff-I, results in improved text alignment while maintaining the same inference computation cost and preserving high visual quality, outperforming previous large-scale text-to-image diffusion models on the standard benchmark. In addition, we train our model to exploit a variety of embeddings for conditioning, including the T5 text, CLIP text, and CLIP image embeddings. We show that these different embeddings lead to different behaviors. Notably, the CLIP image embedding allows an intuitive way of transferring the style of a reference image to the target text-to-image output. Lastly, we show a technique that enables eDiff-I's""paint-with-words""capability. A user can select the word in the input text and paint it in a canvas to control the output, which is very handy for crafting the desired image in mind. The project page is available at https://deepimagination.cc/eDiff-I/"
"Florinel-Alin Croitoru, Vlad Hondru, Radu Tudor Ionescu, M. Shah",efa1647594b236361610a20d507127f0586a379b,Diffusion Models in Vision: A Survey,IEEE Transactions on Pattern Analysis and Machine Intelligence,2022,64,"Denoising diffusion models represent a recent emerging topic in computer vision, demonstrating remarkable results in the area of generative modeling. A diffusion model is a deep generative model that is based on two stages, a forward diffusion stage and a reverse diffusion stage. In the forward diffusion stage, the input data is gradually perturbed over several steps by adding Gaussian noise. In the reverse stage, a model is tasked at recovering the original input data by learning to gradually reverse the diffusion process, step by step. Diffusion models are widely appreciated for the quality and diversity of the generated samples, despite their known computational burdens, i.e. low speeds due to the high number of steps involved during sampling. In this survey, we provide a comprehensive review of articles on denoising diffusion models applied in vision, comprising both theoretical and practical contributions in the field. First, we identify and present three generic diffusion modeling frameworks, which are based on denoising diffusion probabilistic models, noise conditioned score networks, and stochastic differential equations. We further discuss the relations between diffusion models and other deep generative models, including variational auto-encoders, generative adversarial networks, energy-based models, autoregressive models and normalizing flows. Then, we introduce a multi-perspective categorization of diffusion models applied in computer vision. Finally, we illustrate the current limitations of diffusion models and envision some interesting directions for future research."
"Arpit Bansal, Eitan Borgnia, Hong-Min Chu, Jie Li, Hamideh Kazemi, Furong Huang, Micah Goldblum, Jonas Geiping, T. Goldstein",525f459f369032e2f2fa3eb1d60da34ab99191bc,Cold Diffusion: Inverting Arbitrary Image Transforms Without Noise,ArXiv,2022,51,"Standard diffusion models involve an image transform -- adding Gaussian noise -- and an image restoration operator that inverts this degradation. We observe that the generative behavior of diffusion models is not strongly dependent on the choice of image degradation, and in fact an entire family of generative models can be constructed by varying this choice. Even when using completely deterministic degradations (e.g., blur, masking, and more), the training and test-time update rules that underlie diffusion models can be easily generalized to create generative models. The success of these fully deterministic models calls into question the community's understanding of diffusion models, which relies on noise in either gradient Langevin dynamics or variational inference, and paves the way for generalized diffusion models that invert arbitrary processes. Our code is available at https://github.com/arpitbansal297/Cold-Diffusion-Models"
"Ron Mokady, Amir Hertz, Kfir Aberman, Y. Pritch, D. Cohen-Or",4de94949daf9bc8dd0e5161d20dfe83198d20ec1,Null-text Inversion for Editing Real Images using Guided Diffusion Models,ArXiv,2022,40,"Recent text-guided diffusion models provide powerful image generation capabilities. Currently, a massive effort is given to enable the modification of these images using text only as means to offer intuitive and versatile editing. To edit a real image using these state-of-the-art tools, one must first invert the image with a meaningful text prompt into the pretrained model's domain. In this paper, we introduce an accurate inversion technique and thus facilitate an intuitive text-based modification of the image. Our proposed inversion consists of two novel key components: (i) Pivotal inversion for diffusion models. While current methods aim at mapping random noise samples to a single input image, we use a single pivotal noise vector for each timestamp and optimize around it. We demonstrate that a direct inversion is inadequate on its own, but does provide a good anchor for our optimization. (ii) NULL-text optimization, where we only modify the unconditional textual embedding that is used for classifier-free guidance, rather than the input text embedding. This allows for keeping both the model weights and the conditional embedding intact and hence enables applying prompt-based editing while avoiding the cumbersome tuning of the model's weights. Our Null-text inversion, based on the publicly available Stable Diffusion model, is extensively evaluated on a variety of images and prompt editing, showing high-fidelity editing of real images."
"Oron Ashual, Shelly Sheynin, A. Polyak, Uriel Singer, Oran Gafni, Eliya Nachmani, Yaniv Taigman",a225d5d846ba5110232ed5bb32d54ea742b1c2d4,KNN-Diffusion: Image Generation via Large-Scale Retrieval,ArXiv,2022,38,"Recent text-to-image models have achieved impressive results. However, since they require large-scale datasets of text-image pairs, it is impractical to train them on new domains where data is scarce or not labeled. In this work, we propose using large-scale retrieval methods, in particular, efficient k-Nearest-Neighbors (kNN), which offers novel capabilities: (1) training a substantially small and efficient text-to-image diffusion model without any text, (2) generating out-of-distribution images by simply swapping the retrieval database at inference time, and (3) performing text-driven local semantic manipulations while preserving object identity. To demonstrate the robustness of our method, we apply our kNN approach on two state-of-the-art diffusion backbones, and show results on several different datasets. As evaluated by human studies and automatic metrics, our method achieves state-of-the-art results compared to existing approaches that train text-to-image generation models using images only (without paired text data)"
"Guillaume Couairon, Jakob Verbeek, Holger Schwenk, M. Cord",064ccebc03d3afabaae30fe29a457c1cfcdff7e3,DiffEdit: Diffusion-based semantic image editing with mask guidance,ArXiv,2022,37,"Image generation has recently seen tremendous advances, with diffusion models allowing to synthesize convincing images for a large variety of text prompts. In this article, we propose DiffEdit, a method to take advantage of text-conditioned diffusion models for the task of semantic image editing, where the goal is to edit an image based on a text query. Semantic image editing is an extension of image generation, with the additional constraint that the generated image should be as similar as possible to a given input image. Current editing methods based on diffusion models usually require to provide a mask, making the task much easier by treating it as a conditional inpainting task. In contrast, our main contribution is able to automatically generate a mask highlighting regions of the input image that need to be edited, by contrasting predictions of a diffusion model conditioned on different text prompts. Moreover, we rely on latent inference to preserve content in those regions of interest and show excellent synergies with mask-based diffusion. DiffEdit achieves state-of-the-art editing performance on ImageNet. In addition, we evaluate semantic image editing in more challenging settings, using images from the COCO dataset as well as text-based generated images."
"Muzaffer Ozbey, S. Dar, H. A. Bedel, Onat Dalmaz, cSaban Ozturk, Alper Gungor, Tolga cCukur",f9583f36414287bd4b7f34a9b178aa9cc3cd471a,Unsupervised Medical Image Translation with Adversarial Diffusion Models,ArXiv,2022,28,"Imputation of missing images via source-to-target modality translation can improve diversity in medical imaging protocols. A pervasive approach for synthesizing target images involves one-shot mapping through generative adversarial networks (GAN). Yet, GAN models that implicitly characterize the image distribution can suffer from limited sample fidelity. Here, we propose a novel method based on adversarial diffusion modeling, SynDiff, for improved performance in medical image translation. To capture a direct correlate of the image distribution, SynDiff leverages a conditional diffusion process that progressively maps noise and source images onto the target image. For fast and accurate image sampling during inference, large diffusion steps are taken with adversarial projections in the reverse diffusion direction. To enable training on unpaired datasets, a cycle-consistent architecture is devised with coupled diffusive and non-diffusive modules that bilaterally translate between two modalities. Extensive assessments are reported on the utility of SynDiff against competing GAN and diffusion models in multi-contrast MRI and MRI-CT translation. Our demonstrations indicate that SynDiff offers quantitatively and qualitatively superior performance against competing baselines."
"W. H. Pinaya, Petru-Daniel Tudosiu, J. Dafflon, P. F. D. Costa, Virginia Fernandez, P. Nachev, S. Ourselin, M. Cardoso",e924a5cc4739f18fb225b7a8b506099042567ffa,Brain Imaging Generation with Latent Diffusion Models,DGM4MICCAI@MICCAI,2022,28,"Deep neural networks have brought remarkable breakthroughs in medical image analysis. However, due to their data-hungry nature, the modest dataset sizes in medical imaging projects might be hindering their full potential. Generating synthetic data provides a promising alternative, allowing to complement training datasets and conducting medical image research at a larger scale. Diffusion models recently have caught the attention of the computer vision community by producing photorealistic synthetic images. In this study, we explore using Latent Diffusion Models to generate synthetic images from high-resolution 3D brain images. We used T1w MRI images from the UK Biobank dataset (N=31,740) to train our models to learn about the probabilistic distribution of brain images, conditioned on covariables, such as age, sex, and brain structure volumes. We found that our models created realistic data, and we could use the conditioning variables to control the data generation effectively. Besides that, we created a synthetic dataset with 100,000 brain images and made it openly available to the scientific community."
"Nupur Kumari, Bin Zhang, Richard Zhang, Eli Shechtman, Jun-Yan Zhu",21dfd128af04af9f109b7638fe5ef2e11cc7a75d,Multi-Concept Customization of Text-to-Image Diffusion,ArXiv,2022,24,"While generative models produce high-quality images of concepts learned from a large-scale database, a user often wishes to synthesize instantiations of their own concepts (for example, their family, pets, or items). Can we teach a model to quickly acquire a new concept, given a few examples? Furthermore, can we compose multiple new concepts together? We propose Custom Diffusion, an efficient method for augmenting existing text-to-image models. We find that only optimizing a few parameters in the text-to-image conditioning mechanism is sufficiently powerful to represent new concepts while enabling fast tuning (~6 minutes). Additionally, we can jointly train for multiple concepts or combine multiple fine-tuned models into one via closed-form constrained optimization. Our fine-tuned model generates variations of multiple, new concepts and seamlessly composes them with existing concepts in novel settings. Our method outperforms several baselines and concurrent works, regarding both qualitative and quantitative evaluations, while being memory and computationally efficient."
"Xu Su, Jiaming Song, Chenlin Meng, S. Ermon",ba2657152a383b6e3099f5c0995a99ebd85351f8,Dual Diffusion Implicit Bridges for Image-to-Image Translation,ArXiv,2022,24,"Common image-to-image translation methods rely on joint training over data from both source and target domains. The training process requires concurrent access to both datasets, which hinders data separation and privacy protection; and existing models cannot be easily adapted for translation of new domain pairs. We present Dual Diffusion Implicit Bridges (DDIBs), an image translation method based on diffusion models, that circumvents training on domain pairs. Image translation with DDIBs relies on two diffusion models trained independently on each domain, and is a two-step process: DDIBs first obtain latent encodings for source images with the source diffusion model, and then decode such encodings using the target model to construct target images. Both steps are defined via ordinary differential equations (ODEs), thus the process is cycle consistent only up to discretization errors of the ODE solvers. Theoretically, we interpret DDIBs as concatenation of source to latent, and latent to target Schrodinger Bridges, a form of entropy-regularized optimal transport, to explain the efficacy of the method. Experimentally, we apply DDIBs on synthetic and high-resolution image datasets, to demonstrate their utility in a wide variety of translation tasks and their inherent optimal transport properties."
"Weilun Wang, Jianmin Bao, Wen-gang Zhou, Dongdong Chen, Dong Chen, Lu Yuan, Houqiang Li",e79614372e420f1211ab7afd0676af1a98b3d657,Semantic Image Synthesis via Diffusion Models,ArXiv,2022,20,"Denoising Diffusion Probabilistic Models (DDPMs) have achieved remarkable success in various image generation tasks compared with Generative Adversarial Nets (GANs). Recent work on semantic image synthesis mainly follows the \emph{de facto} GAN-based approaches, which may lead to unsatisfactory quality or diversity of generated images. In this paper, we propose a novel framework based on DDPM for semantic image synthesis. Unlike previous conditional diffusion model directly feeds the semantic layout and noisy image as input to a U-Net structure, which may not fully leverage the information in the input semantic mask, our framework processes semantic layout and noisy image differently. It feeds noisy image to the encoder of the U-Net structure while the semantic layout to the decoder by multi-layer spatially-adaptive normalization operators. To further improve the generation quality and semantic interpretability in semantic image synthesis, we introduce the classifier-free guidance sampling strategy, which acknowledge the scores of an unconditional model for sampling process. Extensive experiments on three benchmark datasets demonstrate the effectiveness of our proposed method, achieving state-of-the-art performance in terms of fidelity (FID) and diversity (LPIPS)."
"A. Voynov, Kfir Aberman, D. Cohen-Or",55036dea7f6068d6b5de6ffe178bb324d01918a0,Sketch-Guided Text-to-Image Diffusion Models,ArXiv,2022,18,"Text-to-Image models have introduced a remarkable leap in the evolution of machine learning, demonstrating high-quality synthesis of images from a given text-prompt. How-ever, these powerful pretrained models still lack control handles that can guide spatial properties of the synthesized images. In this work, we introduce a universal approach to guide a pretrained text-to-image diffusion model, with a spatial map from another domain (e.g., sketch) during inference time. Unlike previous works, our method does not require to train a dedicated model or a specialized encoder for the task. which allows technique to free-hand take a particular focus on the sketch-to-image translation task, revealing a robust and ex-pressive way to generate images that follow the guidance of a sketch of arbitrary style or domain."
"Wanshu Fan, Yen-Chun Chen, Dongdong Chen, Yu Cheng, Lu Yuan, Yu-Chiang Frank Wang",a888dd6d8dd0087fc7d74da8a005922d0923ad2b,Frido: Feature Pyramid Diffusion for Complex Scene Image Synthesis,ArXiv,2022,18,"Diffusion models (DMs) have shown great potential for high-quality image synthesis. However, when it comes to producing images with complex scenes, how to properly describe both image global structures and object details remains a challenging task. In this paper, we present Frido, a Feature Pyramid Diffusion model performing a multi-scale coarse-to-fine denoising process for image synthesis. Our model decomposes an input image into scale-dependent vector quantized features, followed by a coarse-to-fine gating for producing image output. During the above multi-scale representation learning stage, additional input conditions like text, scene graph, or image layout can be further exploited. Thus, Frido can be also applied for conditional or cross-modality image synthesis. We conduct extensive experiments over various unconditioned and conditional image generation tasks, ranging from text-to-image synthesis, layout-to-image, scene-graph-to-image, to label-to-image. More specifically, we achieved state-of-the-art FID scores on five benchmarks, namely layout-to-image on COCO and OpenImages, scene-graph-to-image on COCO and Visual Genome, and label-to-image on COCO. Code is available at https://github.com/davidhalladay/Frido."
"Gihyun Kwon, Jong-Chul Ye",52472459ea81b6ebc65d16a0c80005f749542cba,Diffusion-based Image Translation using Disentangled Style and Content Representation,ArXiv,2022,18,"Diffusion-based image translation guided by semantic texts or a single target image has enabled flexible style transfer which is not limited to the specific domains. Unfortunately, due to the stochastic nature of diffusion models, it is often difficult to maintain the original content of the image during the reverse diffusion. To address this, here we present a novel diffusion-based unsupervised image translation method using disentangled style and content representation. Specifically, inspired by the splicing Vision Transformer, we extract intermediate keys of multihead self attention layer from ViT model and used them as the content preservation loss. Then, an image guided style transfer is performed by matching the [CLS] classification token from the denoised samples and target image, whereas additional CLIP loss is used for the text-driven style transfer. To further accelerate the semantic change during the reverse diffusion, we also propose a novel semantic divergence loss and resampling strategy. Our experimental results show that the proposed method outperforms state-of-the-art baseline models in both text-guided and image-guided translation tasks."
"Yinhuai Wang, Jiwen Yu, Jian Zhang",3a75ed3e9e81c9db573ef73d20e2c66c12aaedf8,Zero-Shot Image Restoration Using Denoising Diffusion Null-Space Model,ArXiv,2022,17,"Most existing Image Restoration (IR) models are task-specific, which can not be generalized to different degradation operators. In this work, we propose the Denoising Diffusion Null-Space Model (DDNM), a novel zero-shot framework for arbitrary linear IR problems, including but not limited to image super-resolution, colorization, inpainting, compressed sensing, and deblurring. DDNM only needs a pre-trained off-the-shelf diffusion model as the generative prior, without any extra training or network modifications. By refining only the null-space contents during the reverse diffusion process, we can yield diverse results satisfying both data consistency and realness. We further propose an enhanced and robust version, dubbed DDNM+, to support noisy restoration and improve restoration quality for hard tasks. Our experiments on several IR tasks reveal that DDNM outperforms other state-of-the-art zero-shot IR methods. We also demonstrate that DDNM+ can solve complex real-world applications, e.g., old photo restoration."
"Jay Zhangjie Wu, Yixiao Ge, Xintao Wang, Weixian Lei, Yuchao Gu, W. Hsu, Ying Shan, Xiaohu Qie, Mike Zheng Shou",1367dcff4ccb927a5e95c452041288b3f0dd0eff,Tune-A-Video: One-Shot Tuning of Image Diffusion Models for Text-to-Video Generation,ArXiv,2022,16,"To replicate the success of text-to-image (T2I) generation, recent works employ large-scale video datasets to train a text-to-video (T2V) generator. Despite their promising results, such paradigm is computationally expensive. In this work, we propose a new T2V generation setting$\unicode{x2014}$One-Shot Video Tuning, where only one text-video pair is presented. Our model is built on state-of-the-art T2I diffusion models pre-trained on massive image data. We make two key observations: 1) T2I models can generate still images that represent verb terms; 2) extending T2I models to generate multiple images concurrently exhibits surprisingly good content consistency. To further learn continuous motion, we introduce Tune-A-Video, which involves a tailored spatio-temporal attention mechanism and an efficient one-shot tuning strategy. At inference, we employ DDIM inversion to provide structure guidance for sampling. Extensive qualitative and numerical experiments demonstrate the remarkable ability of our method across various applications."
"Zhidan Feng, Zhenyu Zhang, Xintong Yu, Yewei Fang, Lanxin Li, Xuyi Chen, Yuxiang Lu, Jiaxiang Liu, Weichong Yin, Shi Feng, Yu Sun, Hao Tian, Hua Wu, Haifeng Wang",9a6d83c836ce6389b526b941d971eee775aa573e,ERNIE-ViLG 2.0: Improving Text-to-Image Diffusion Model with Knowledge-Enhanced Mixture-of-Denoising-Experts,ArXiv,2022,16,"Recent progress in diffusion models has revolutionized the popular technology of text-to-image generation. While existing approaches could produce photorealistic high-resolution images with text conditions, there are still several open problems to be solved, which limits the further improvement of image fidelity and text relevancy. In this paper, we propose ERNIE-ViLG 2.0, a large-scale Chinese text-to-image diffusion model, to progressively upgrade the quality of generated images by: (1) incorporating fine-grained textual and visual knowledge of key elements in the scene, and (2) utilizing different denoising experts at different denoising stages. With the proposed mechanisms, ERNIE-ViLG 2.0 not only achieves a new state-of-the-art on MS-COCO with zero-shot FID score of 6.75, but also significantly outperforms recent models in terms of image fidelity and image-text alignment, with side-by-side human evaluation on the bilingual prompt set ViLG-300."
"Weixi Feng, Xuehai He, Tsu-Jui Fu, Varun Jampani, Arjun Reddy Akula, P. Narayana, Sugato Basu, X. Wang, William Yang Wang",25de00096c45121a06668bc501f91adec5d0aff9,Training-Free Structured Diffusion Guidance for Compositional Text-to-Image Synthesis,ArXiv,2022,15,"Large-scale diffusion models have achieved state-of-the-art results on text-to-image synthesis (T2I) tasks. Despite their ability to generate high-quality yet creative images, we observe that attribution-binding and compositional capabilities are still considered major challenging issues, especially when involving multiple objects. In this work, we improve the compositional skills of T2I models, specifically more accurate attribute binding and better image compositions. To do this, we incorporate linguistic structures with the diffusion guidance process based on the controllable properties of manipulating cross-attention layers in diffusion-based T2I models. We observe that keys and values in cross-attention layers have strong semantic meanings associated with object layouts and content. Therefore, we can better preserve the compositional semantics in the generated image by manipulating the cross-attention representations based on linguistic insights. Built upon Stable Diffusion, a SOTA T2I model, our structured cross-attention design is efficient that requires no additional training samples. We achieve better compositional skills in qualitative and quantitative results, leading to a 5-8% advantage in head-to-head user comparison studies. Lastly, we conduct an in-depth analysis to reveal potential causes of incorrect image compositions and justify the properties of cross-attention layers in the generation process."
"Hyungjin Chung, Eunha Lee, Jong-Chul Ye",2b009e12a42efe77b8daeffd218b912fd23c19aa,MR Image Denoising and Super-Resolution Using Regularized Reverse Diffusion,IEEE Transactions on Medical Imaging,2022,15,"Patient scans from MRI often suffer from noise, which hampers the diagnostic capability of such images. As a method to mitigate such artifact, denoising is largely studied both within the medical imaging community and beyond the community as a general subject. However, recent deep neural network-based approaches mostly rely on the minimum mean squared error (MMSE) estimates, which tend to produce a blurred output. Moreover, such models suffer when deployed in real-world sitautions: out-of-distribution data, and complex noise distributions that deviate from the usual parametric noise models. In this work, we propose a new denoising method based on score-based reverse diffusion sampling, which overcomes all the aforementioned drawbacks. Our network, trained only with coronal knee scans, excels even on out-of-distribution in vivo liver MRI data, contaminated with complex mixture of noise. Even more, we propose a method to enhance the resolution of the denoised image with the same network. With extensive experiments, we show that our method establishes state-of-the-art performance, while having desirable properties which prior MMSE denoisers did not have: flexibly choosing the extent of denoising, and quantifying uncertainty."
"Sangyun Lee, Hyungjin Chung, Jaehyeon Kim, Jong-Chul Ye",5172800e7952c671ab9bc7bd666ab1fefd19a540,Progressive Deblurring of Diffusion Models for Coarse-to-Fine Image Synthesis,ArXiv,2022,15,"Recently, diffusion models have shown remarkable results in image synthesis by gradually removing noise and amplifying signals. Although the simple generative process surprisingly works well, is this the best way to generate image data? For instance, despite the fact that human perception is more sensitive to the low frequencies of an image, diffusion models themselves do not consider any relative importance of each frequency component. Therefore, to incorporate the inductive bias for image data, we propose a novel generative process that synthesizes images in a coarse-to-fine manner. First, we generalize the standard diffusion models by enabling diffusion in a rotated coordinate system with different velocities for each component of the vector. We further propose a blur diffusion as a special case, where each frequency component of an image is diffused at different speeds. Specifically, the proposed blur diffusion consists of a forward process that blurs an image and adds noise gradually, after which a corresponding reverse process deblurs an image and removes noise progressively. Experiments show that the proposed model outperforms the previous method in FID on LSUN bedroom and church datasets. Code is available at https://github.com/sangyun884/blur-diffusion."
"A. Kazerouni, Ehsan Khodapanah Aghdam, Moein Heidari, Reza Azad, Mohsen Fayyaz, I. Hacihaliloglu, D. Merhof",45d1434c3547d10a40c8f467e3c4afd08a5ae700,Diffusion Models for Medical Image Analysis: A Comprehensive Survey,ArXiv,2022,14,"Denoising diffusion models, a class of generative models, have garnered immense interest lately in various deep-learning problems. A diffusion probabilistic model defines a forward diffusion stage where the input data is gradually perturbed over several steps by adding Gaussian noise and then learns to reverse the diffusion process to retrieve the desired noise-free data from noisy data samples. Diffusion models are widely appreciated for their strong mode coverage and quality of the generated samples despite their known computational burdens. Capitalizing on the advances in computer vision, the field of medical imaging has also observed a growing interest in diffusion models. To help the researcher navigate this profusion, this survey intends to provide a comprehensive overview of diffusion models in the discipline of medical image analysis. Specifically, we introduce the solid theoretical foundation and fundamental concepts behind diffusion models and the three generic diffusion modelling frameworks: diffusion probabilistic models, noise-conditioned score networks, and stochastic differential equations. Then, we provide a systematic taxonomy of diffusion models in the medical domain and propose a multi-perspective categorization based on their application, imaging modality, organ of interest, and algorithms. To this end, we cover extensive applications of diffusion models in the medical domain. Furthermore, we emphasize the practical use case of some selected approaches, and then we discuss the limitations of the diffusion models in the medical domain and propose several directions to fulfill the demands of this field. Finally, we gather the overviewed studies with their available open-source implementations at https://github.com/amirhossein-kz/Awesome-Diffusion-Models-in-Medical-Imaging."
"Boah Kim, Jong-Chul Ye",69fe2ed78956f22a36ccb2029b8315cd3bbc36da,Diffusion Deformable Model for 4D Temporal Medical Image Generation,International Conference on Medical Image Computing and Computer-Assisted Intervention,2022,14,"Temporal volume images with 3D+t (4D) information are often used in medical imaging to statistically analyze temporal dynamics or capture disease progression. Although deep-learning-based generative models for natural images have been extensively studied, approaches for temporal medical image generation such as 4D cardiac volume data are limited. In this work, we present a novel deep learning model that generates intermediate temporal volumes between source and target volumes. Specifically, we propose a diffusion deformable model (DDM) by adapting the denoising diffusion probabilistic model that has recently been widely investigated for realistic image generation. Our proposed DDM is composed of the diffusion and the deformation modules so that DDM can learn spatial deformation information between the source and target volumes and provide a latent code for generating intermediate frames along a geodesic path. Once our model is trained, the latent code estimated from the diffusion module is simply interpolated and fed into the deformation module, which enables DDM to generate temporal frames along the continuous trajectory while preserving the topology of the source image. We demonstrate the proposed method with the 4D cardiac MR image generation between the diastolic and systolic phases for each subject. Compared to the existing deformation methods, our DDM achieves high performance on temporal volume generation."
"Yutong Xie, Quanzheng Li",469e9b5c3a9a978c27dd902e18a2dc1a6721a6a9,Measurement-conditioned Denoising Diffusion Probabilistic Model for Under-sampled Medical Image Reconstruction,International Conference on Medical Image Computing and Computer-Assisted Intervention,2022,13,"We propose a novel and unified method, measurement-conditioned denoising diffusion probabilistic model (MC-DDPM), for under-sampled medical image reconstruction based on DDPM. Different from previous works, MC-DDPM is defined in measurement domain (e.g. k-space in MRI reconstruction) and conditioned on under-sampling mask. We apply this method to accelerate MRI reconstruction and the experimental results show excellent performance, outperforming full supervision baseline and the state-of-the-art score-based reconstruction method. Due to its generative nature, MC-DDPM can also quantify the uncertainty of reconstruction. Our code is available on github."
"K. Sandstrom, E. Koch, A. Leroy, E. Rosolowsky, E. Emsellem, Rowan J. Smith, O. Egorov, T. Williams, K. Larson, Janice C. Lee, E. Schinnerer, D. Thilker, A. Barnes, F. Belfiore, F. Bigiel, G. Blanc, A. Bolatto, M. Boquien, Yixian Cao, J. Chastenet, M. Chevance, I. Chiang 江, D. Dale, C. Faesi, S. Glover, K. Grasha, B. Groves, Hamid Hassani, J. Henshaw, A. Hughes, Jaeyeon Kim, R. Klessen, K. Kreckel, J. Kruijssen, L. Lopez, Daizhong Liu, S. Meidt, E. Murphy, H. Pan, M. Querejeta, T. Saito, A. Sardone, M. Sormani, Jessica S. Sutter, A. Usero, E. Watkins",9655910d895681255e6a5bcdd9446c4473d04754,PHANGS–JWST First Results: Tracing the Diffuse Interstellar Medium with JWST Imaging of Polycyclic Aromatic Hydrocarbon Emission in Nearby Galaxies,Astrophysical Journal Letters,2022,13,"JWST observations of polycyclic aromatic hydrocarbon (PAH) emission provide some of the deepest and highest resolution views of the cold interstellar medium (ISM) in nearby galaxies. If PAHs are well mixed with the atomic and molecular gas and illuminated by the average diffuse interstellar radiation field, PAH emission may provide an approximately linear, high-resolution, high-sensitivity tracer of diffuse gas surface density. We present a pilot study that explores using PAH emission in this way based on Mid-Infrared Instrument observations of IC 5332, NGC 628, NGC 1365, and NGC 7496 from the Physics at High Angular resolution in Nearby GalaxieS-JWST Treasury. Using scaling relationships calibrated in Leroy et al., scaled F1130W provides 10–40 pc resolution and 3σ sensitivity of Σgas ∼ 2 M ⊙ pc−2. We characterize the surface densities of structures seen at <7 M ⊙ pc−2 in our targets, where we expect the gas to be H i-dominated. We highlight the existence of filaments, interarm emission, and holes in the diffuse ISM at these low surface densities. Below ∼10 M ⊙ pc−2 for NGC 628, NGC 1365, and NGC 7496 the gas distribution shows a “Swiss cheese”-like topology due to holes and bubbles pervading the relatively smooth distribution of the diffuse ISM. Comparing to recent galaxy simulations, we observe similar topology for the low-surface-density gas, though with notable variations between simulations with different setups and resolution. Such a comparison of high-resolution, low-surface-density gas with simulations is not possible with existing atomic and molecular gas maps, highlighting the unique power of JWST maps of PAH emission."
"Riccardo Corvi, Davide Cozzolino, Giada Zingarini, G. Poggi, Koki Nagano, L. Verdoliva",05ce31d0e48c3e700b4fd606dbba3433ea83ab2b,On the detection of synthetic images generated by diffusion models,ArXiv,2022,12,"Over the past decade, there has been tremendous progress in creating synthetic media, mainly thanks to the development of powerful methods based on generative adversarial networks (GAN). Very recently, methods based on diffusion models (DM) have been gaining the spotlight. In addition to providing an impressive level of photorealism, they enable the creation of text-based visual content, opening up new and exciting opportunities in many different application fields, from arts to video games. On the other hand, this property is an additional asset in the hands of malicious users, who can generate and distribute fake media perfectly adapted to their attacks, posing new challenges to the media forensic community. With this work, we seek to understand how difficult it is to distinguish synthetic images generated by diffusion models from pristine ones and whether current state-of-the-art detectors are suitable for the task. To this end, first we expose the forensics traces left by diffusion models, then study how current detectors, developed for GAN-generated images, perform on these new synthetic images, especially in challenging social-networks scenarios involving image compression and resizing. Datasets and code are available at github.com/grip-unina/DMimageDetection."
"Binxin Yang, Shuyang Gu, Bo Zhang, Ting Zhang, Xuejin Chen, Xiaoyan Sun, Dong Chen, Fang Wen",4f1502111d35aa6651dfaedfeb1184b3c3dd2fcb,Paint by Example: Exemplar-based Image Editing with Diffusion Models,ArXiv,2022,12,"Language-guided image editing has achieved great success recently. In this paper, for the first time, we investigate exemplar-guided image editing for more precise control. We achieve this goal by leveraging self-supervised training to disentangle and re-organize the source image and the exemplar. However, the naive approach will cause obvious fusing artifacts. We carefully analyze it and propose an information bottleneck and strong augmentations to avoid the trivial solution of directly copying and pasting the exemplar image. Meanwhile, to ensure the controllability of the editing process, we design an arbitrary shape mask for the exemplar image and leverage the classifier-free guidance to increase the similarity to the exemplar image. The whole framework involves a single forward of the diffusion model without any iterative optimization. We demonstrate that our method achieves an impressive performance and enables controllable editing on in-the-wild images with high fidelity."
"Junde Wu, Huihui Fang, Yu Zhang, Yehui Yang, Yanwu Xu",c266aedf9660a70d15d02f53242c6fcebe7b4b8c,MedSegDiff: Medical Image Segmentation with Diffusion Probabilistic Model,ArXiv,2022,12,"Diffusion probabilistic model (DPM) recently becomes one of the hottest topic in computer vision. Its image generation application such as Imagen, Latent Diffusion Models and Stable Diffusion have shown impressive generation capabilities, which aroused extensive discussion in the community. Many recent studies also found it is useful in many other vision tasks, like image deblurring, super-resolution and anomaly detection. Inspired by the success of DPM, we propose the first DPM based model toward general medical image segmentation tasks, which we named MedSegDiff. In order to enhance the step-wise regional attention in DPM for the medical image segmentation, we propose dynamic conditional encoding, which establishes the state-adaptive conditions for each sampling step. We further propose Feature Frequency Parser (FF-Parser), to eliminate the negative effect of high-frequency noise component in this process. We verify MedSegDiff on three medical segmentation tasks with different image modalities, which are optic cup segmentation over fundus images, brain tumor segmentation over MRI images and thyroid nodule segmentation over ultrasound images. The experimental results show that MedSegDiff outperforms state-of-the-art (SOTA) methods with considerable performance gap, indicating the generalization and effectiveness of the proposed model. Our code is released at https://github.com/WuJunde/MedSegDiff."
"Xingqian Xu, Zhangyang Wang, Eric Zhang, Kai Wang, Humphrey Shi",78550c60dcdcdd8ca30f5838bcdbace1e8c9ba15,"Versatile Diffusion: Text, Images and Variations All in One Diffusion Model",ArXiv,2022,11,"Recent advances in diffusion models have set an impressive milestone in many generation tasks, and trending works such as DALL-E2, Imagen, and Stable Diffusion have attracted great interest. Despite the rapid landscape changes, recent new approaches focus on extensions and performance rather than capacity, thus requiring separate models for separate tasks. In this work, we expand the existing single-flow diffusion pipeline into a multi-task multimodal network, dubbed Versatile Diffusion (VD), that handles multiple flows of text-to-image, image-to-text, and variations in one unified model. The pipeline design of VD instantiates a unified multi-flow diffusion framework, consisting of sharable and swappable layer modules that enable the crossmodal generality beyond images and text. Through extensive experiments, we demonstrate that VD successfully achieves the following: a) VD outperforms the baseline approaches and handles all its base tasks with competitive quality; b) VD enables novel extensions such as disentanglement of style and semantics, dual- and multi-context blending, etc.; c) The success of our multi-flow multimodal framework over images and text may inspire further diffusion-based universal AI research. Our code and models are open-sourced at https://github.com/SHI-Labs/Versatile-Diffusion."
"Zeyang Sha, Zheng Li, Ning Yu, Yang Zhang",cdd8f95bfd01496eb4ab81ad35afb3bd2000d762,DE-FAKE: Detection and Attribution of Fake Images Generated by Text-to-Image Diffusion Models,ArXiv,2022,11,"Diffusion models emerge to establish the new state of the art in the visual generation. In particular, text-to-image diffusion models that generate images based on caption descriptions have attracted increasing attention, impressed by their user controllability. Despite encouraging performance, they exaggerate concerns of fake image misuse and cast new pres-sures on fake image detection. In this work, we pioneer a systematic study of the authenticity of fake images generated by text-to-image diffusion models. In particular, we conduct comprehensive studies from two perspectives unique to the text-to-image model, namely, visual modality and linguistic modality. For visual modality, we propose universal detection that demonstrates fake images of these text-to-image diffusion models share common cues, which enable us to distinguish them apart from real images. We then propose source attribution that reveals the uniqueness of the ﬁngerprints held by each diffusion model, which can be used to attribute each fake image to its model source. A variety of ablation and analysis studies further interpret the improvements from each of our proposed methods. For linguistic modality, we delve deeper to comprehensively analyze the impacts of text captions (called prompt analysis ) on the image authenticity of text-to-image diffusion models, and reason the impacts to the detection and attribution performance of fake images. All ﬁndings contribute to the community’s insight into the natural properties of text-to-image diffusion models, and we appeal to our community’s consideration on the counterpart solutions, like ours, against the rapidly-evolving fake image generators."
"Jiale Xu, Xintao Wang, Weihao Cheng, Yan-Pei Cao, Ying Shan, Xiaohu Qie, Shenghua Gao",9432bd77fa374d794bf2c8703b0e0e460380771f,Dream3D: Zero-Shot Text-to-3D Synthesis Using 3D Shape Prior and Text-to-Image Diffusion Models,ArXiv,2022,11,"Recent CLIP-guided 3D optimization methods, such as DreamFields and PureCLIPNeRF, have achieved impressive results in zero-shot text-to-3D synthesis. However, due to scratch training and random initialization without prior knowledge, these methods often fail to generate accurate and faithful 3D structures that conform to the input text. In this paper, we make the first attempt to introduce explicit 3D shape priors into the CLIP-guided 3D optimization process. Specifically, we first generate a high-quality 3D shape from the input text in the text-to-shape stage as a 3D shape prior. We then use it as the initialization of a neural radiance field and optimize it with the full prompt. To address the challenging text-to-shape generation task, we present a simple yet effective approach that directly bridges the text and image modalities with a powerful text-to-image diffusion model. To narrow the style domain gap between the images synthesized by the text-to-image diffusion model and shape renderings used to train the image-to-shape generator, we further propose to jointly optimize a learnable text prompt and fine-tune the text-to-image diffusion model for rendering-style image generation. Our method, Dream3D, is capable of generating imaginative 3D content with superior visual quality and shape accuracy compared to state-of-the-art methods."
"Ozan Özdenizci, R. Legenstein",69beb616ffdc42afe86b7487c5db82b6d88638b8,Restoring Vision in Adverse Weather Conditions with Patch-Based Denoising Diffusion Models,IEEE Transactions on Pattern Analysis and Machine Intelligence,2022,9,"Image restoration under adverse weather conditions has been of significant interest for various computer vision applications. Recent successful methods rely on the current progress in deep neural network architectural designs (e.g., with vision transformers). Motivated by the recent progress achieved with state-of-the-art conditional generative models, we present a novel patch-based image restoration algorithm based on denoising diffusion probabilistic models. Our patch-based diffusion modeling approach enables size-agnostic image restoration by using a guided denoising process with smoothed noise estimates across overlapping patches during inference. We empirically evaluate our model on benchmark datasets for image desnowing, combined deraining and dehazing, and raindrop removal. We demonstrate our approach to achieve state-of-the-art performances on both weather-specific and multi-weather image restoration, and experimentally show strong generalization to real-world test images."
"Robin Rombach, A. Blattmann, B. Ommer",0270ec4bc946b59c5cf6204be2553682dee0346c,Text-Guided Synthesis of Artistic Images with Retrieval-Augmented Diffusion Models,ArXiv,2022,9,"Novel architectures have recently improved generative image synthesis leading to excellent visual quality in various tasks. Of particular note is the field of ``AI-Art'', which has seen unprecedented growth with the emergence of powerful multimodal models such as CLIP. By combining speech and image synthesis models, so-called ``prompt-engineering'' has become established, in which carefully selected and composed sentences are used to achieve a certain visual style in the synthesized image. In this note, we present an alternative approach based on retrieval-augmented diffusion models (RDMs). In RDMs, a set of nearest neighbors is retrieved from an external database during training for each training instance, and the diffusion model is conditioned on these informative samples. During inference (sampling), we replace the retrieval database with a more specialized database that contains, for example, only images of a particular visual style. This provides a novel way to prompt a general trained model after training and thereby specify a particular visual style. As shown by our experiments, this approach is superior to specifying the visual style within the text prompt. We open-source code and model weights at https://github.com/CompVis/latent-diffusion ."
"Zijie J. Wang, Evan Montoya, David Munechika, Haoyang Yang, Benjamin Hoover, Duen Horng Chau",eef10b19c7560a8dfe012c773ac29c5038c787fb,DiffusionDB: A Large-scale Prompt Gallery Dataset for Text-to-Image Generative Models,ArXiv,2022,9,"With recent advancements in diffusion models, users can generate high-quality images by writing text prompts in natural language. However, generating images with desired details requires proper prompts, and it is often unclear how a model reacts to different prompts and what the best prompts are. To help researchers tackle these critical challenges, we introduce DiffusionDB, the first large-scale text-to-image prompt dataset. DiffusionDB contains 14 million images generated by Stable Diffusion using prompts and hyperparameters specified by real users. We analyze prompts in the dataset and discuss key properties of these prompts. The unprecedented scale and diversity of this human-actuated dataset provide exciting research opportunities in understanding the interplay between prompts and generative models, detecting deepfakes, and designing human-AI interaction tools to help users more easily use these models. DiffusionDB is publicly available at: https://poloclub.github.io/diffusiondb."
"Bahjat Kawar, Roy Ganz, Michael Elad",fdcd785502144fdee49e4169212962cfd3de4818,Enhancing Diffusion-Based Image Synthesis with Robust Classifier Guidance,ArXiv,2022,9,"Denoising diffusion probabilistic models (DDPMs) are a recent family of generative models that achieve state-of-the-art results. In order to obtain class-conditional generation, it was suggested to guide the diffusion process by gradients from a time-dependent classifier. While the idea is theoretically sound, deep learning-based classifiers are infamously susceptible to gradient-based adversarial attacks. Therefore, while traditional classifiers may achieve good accuracy scores, their gradients are possibly unreliable and might hinder the improvement of the generation results. Recent work discovered that adversarially robust classifiers exhibit gradients that are aligned with human perception, and these could better guide a generative process towards semantically meaningful images. We utilize this observation by defining and training a time-dependent adversarially robust classifier and use it as guidance for a generative diffusion model. In experiments on the highly challenging and diverse ImageNet dataset, our scheme introduces significantly more intelligible intermediate gradients, better alignment with theoretical findings, as well as improved generation results under several evaluation metrics. Furthermore, we conduct an opinion survey whose findings indicate that human raters prefer our method's results."
"Shin-I Cheng, Yu-Jie Chen, Wei-Chen Chiu, Hsin-Ying Lee, Hung-Yu Tseng",166314254ab27888fb49399dcf17764feb347a66,Adaptively-Realistic Image Generation from Stroke and Sketch with Diffusion Model,IEEE Workshop/Winter Conference on Applications of Computer Vision,2022,8,"Generating images from hand-drawings is a crucial and fundamental task in content creation. The translation is difficult as there exist infinite possibilities and the different users usually expect different outcomes. Therefore, we propose a unified framework supporting a three-dimensional control over the image synthesis from sketches and strokes based on diffusion models. Users can not only decide the level of faithfulness to the input strokes and sketches, but also the degree of realism, as the user inputs are usually not consistent with the real images. Qualitative and quantitative experiments demonstrate that our framework achieves state-of-the-art performance while providing flexibility in generating customized images with control over shape, color, and realism. Moreover, our method unleashes applications such as editing on real images, generation with partial sketches and strokes, and multi-domain multi-modal synthesis."
"A. Ulhaq, Naveed Akhtar, Ganna Pogrebna",f170754f8ab3187514292c12b1cbb431c0a8a634,Efficient Diffusion Models for Vision: A Survey,ArXiv,2022,8,"Diffusion Models (DMs) have demonstrated state-of-the-art performance in content generation without requiring adversarial training. These models are trained using a two-step process. First, a forward - diffusion - process gradually adds noise to a datum (usually an image). Then, a backward - reverse diffusion - process gradually removes the noise to turn it into a sample of the target distribution being modelled. DMs are inspired by non-equilibrium thermodynamics and have inherent high computational complexity. Due to the frequent function evaluations and gradient calculations in high-dimensional spaces, these models incur considerable computational overhead during both training and inference stages. This can not only preclude the democratization of diffusion-based modelling, but also hinder the adaption of diffusion models in real-life applications. Not to mention, the efficiency of computational models is fast becoming a significant concern due to excessive energy consumption and environmental scares. These factors have led to multiple contributions in the literature that focus on devising computationally efficient DMs. In this review, we present the most recent advances in diffusion models for vision, specifically focusing on the important design aspects that affect the computational efficiency of DMs. In particular, we emphasize the recently proposed design choices that have led to more efficient DMs. Unlike the other recent reviews, which discuss diffusion models from a broad perspective, this survey is aimed at pushing this research direction forward by highlighting the design strategies in the literature that are resulting in practicable models for the broader research community. We also provide a future outlook of diffusion models in vision from their computational efficiency viewpoint."
"Julia Wolleb, Robin Sandkühler, Florentin Bieder, P. Cattin",b3fd1450250bd8fe209f59247de558b5c14d5785,The Swiss Army Knife for Image-to-Image Translation: Multi-Task Diffusion Models,ArXiv,2022,8,"Recently, diffusion models were applied to a wide range of image analysis tasks. We build on a method for image-to-image translation using denoising diffusion implicit models and include a regression problem and a segmentation problem for guiding the image generation to the desired output. The main advantage of our approach is that the guidance during the denoising process is done by an external gradient. Consequently, the diffusion model does not need to be retrained for the different tasks on the same dataset. We apply our method to simulate the aging process on facial photos using a regression task, as well as on a brain magnetic resonance (MR) imaging dataset for the simulation of brain tumor growth. Furthermore, we use a segmentation model to inpaint tumors at the desired location in healthy slices of brain MR images. We achieve convincing results for all problems."
"Zolnamar Dorjsembe, Furen Xiao",e793a1c2b98c655eb20a1fe253b5eb2971e48917,Three-Dimensional Medical Image Synthesis with Denoising Diffusion Probabilistic Models,,2022,8,"Denoising diffusion probabilistic models (DDPM) have recently shown superior performance in image synthesis and have been extensively studied in various image processing tasks. In this work, we propose a 3D-DDPM for generating three-dimensional (3D) medical images. Different from previous studies, to the best of our knowledge, this work presents the first attempt to investigate the DDPM to enable 3D medical image synthesis. Our study examined the generation of high-resolution magnetic resonance images (MRI) of brain tumors. The proposed method is evaluated through experiments on a semi-public dataset, with both quantitative and qualitative tests showing promising results. Our code will be publicly available at https://github.com/DL-Circle/3D-DDPM."
"Ruihan Yang, S. Mandt",d236674b30807d1cbd0c8c80dd823b1160528717,Lossy Image Compression with Conditional Diffusion Models,ArXiv,2022,8,"This paper outlines an end-to-end optimized lossy image compression framework using diffusion generative models. The approach relies on the transform coding paradigm, where an image is mapped into a latent space for entropy coding and, from there, mapped back to the data space for reconstruction. In contrast to VAE-based neural compression, where the (mean) decoder is a deterministic neural network, our decoder is a conditional diffusion model. Our approach thus introduces an additional ``content'' latent variable on which the reverse diffusion process is conditioned and uses this variable to store information about the image. The remaining ``texture'' latent variables characterizing the diffusion process are synthesized (stochastically or deterministically) at decoding time. We show that the model's performance can be tuned toward perceptual metrics of interest. Our extensive experiments involving five datasets and sixteen image quality assessment metrics show that our approach yields the strongest reported FID scores while also yielding competitive performance with state-of-the-art models in several SIM-based reference metrics."
"Dominik Jens Elias Waibel, Ernst Rooell, Bastian Alexander Rieck, R. Giryes, Carsten Marr",616c95094f582623ae31926e7f95484b7788df4c,A Diffusion Model Predicts 3D Shapes from 2D Microscopy Images,ArXiv,2022,7,"Diffusion models are a special type of generative model, capable of synthesising new data from a learnt distribution. We introduce DISPR, a diffusion-based model for solving the inverse problem of three-dimensional (3D) cell shape prediction from two-dimensional (2D) single cell microscopy images. Using the 2D microscopy image as a prior, DISPR is conditioned to predict realistic 3D shape reconstructions. To showcase the applicability of DISPR as a data augmentation tool in a feature-based single cell classification task, we extract morphological features from the red blood cells grouped into six highly imbalanced classes. Adding features from the DISPR predictions to the three minority classes improved the macro F1 score from $F1_\text{macro} = 55.2 \pm 4.6\%$ to $F1_\text{macro} = 72.2 \pm 4.9\%$. We thus demonstrate that diffusion models can be successfully applied to inverse biomedical problems, and that they learn to reconstruct 3D shapes with realistic morphological features from 2D microscopy images."
"F. Khader, G. Mueller-Franzes, Soroosh Tayebi Arasteh, T. Han, Christoph Haarburger, M. Schulze-Hagen, P. Schad, S. Engelhardt, B. Baessler, S. Foersch, J. Stegmaier, C. Kuhl, S. Nebelung, Jakob Nikolas Kather, D. Truhn",4616d468f2ec5b78206f2d00d0c6704b4bda19b4,Medical Diffusion - Denoising Diffusion Probabilistic Models for 3D Medical Image Generation,ArXiv,2022,7,"Recent advances in computer vision have shown promising results in image generation. Diffusion probabilistic models in particular have generated realistic images from textual input, as demonstrated by DALL-E 2, Imagen and Stable Diffusion. However, their use in medicine, where image data typically comprises three-dimensional volumes, has not been systematically evaluated. Synthetic images may play a crucial role in privacy preserving artificial intelligence and can also be used to augment small datasets. Here we show that diffusion probabilistic models can synthesize high quality medical imaging data, which we show for Magnetic Resonance Images (MRI) and Computed Tomography (CT) images. We provide quantitative measurements of their performance through a reader study with two medical experts who rated the quality of the synthesized images in three categories: Realistic image appearance, anatomical correctness and consistency between slices. Furthermore, we demonstrate that synthetic images can be used in a self-supervised pre-training and improve the performance of breast segmentation models when data is scarce (dice score 0.91 vs. 0.95 without vs. with synthetic data). The code is publicly available on GitHub: https://github.com/FirasGit/medicaldiffusion."
"Sam L. Polk, Kangning Cui, R. Plemmons, James M. Murphy",73ab79b0ac7c5a14a80a36330e45b8065b10aea4,Diffusion and Volume Maximization-Based Clustering of Highly Mixed Hyperspectral Images,ArXiv,2022,7,"Hyperspectral images of a scene or object are a rich data source, often encoding a hundred or more spectral bands of reﬂectance at each pixel. Despite being very high-dimensional, these images typically encode latent low-dimensional structure that can be exploited for material discrimination. However, due to an inherent trade-oﬀ between spectral and spatial resolution, many hyperspectral images are generated at a coarse spatial scale, and single pixels may correspond to spatial regions containing multiple materials. This article introduces the Diﬀusion and Volume maximization-based Image Clustering ( D-VIC ) algorithm for unsupervised material discrimination. D-VIC locates cluster modes—high-density, high-purity pixels in the hyperspectral image that are far in diﬀusion distance (a data-dependent distance metric) from other high-density, high-purity pixels—and assigns these pixels unique labels, as these points are meant to exemplify underlying material structure. Non-modal pixels are labeled according to their diﬀusion distance nearest neighbor of higher density and purity that is already labeled. By directly incorporating pixel purity into its modal and non-modal labeling, D-VIC upweights pixels that correspond to a spatial region containing just a single material, yielding more interpretable clusterings. D-VIC is shown to outperform baseline and comparable state-of-the-art methods in extensive numerical experiments on a range of hyperspectral images, implying that it is well-equipped for material discrimination and clustering of these data."
"Congyue Deng, C. Jiang, C. Qi, Xinchen Yan, Yin Zhou, L. Guibas, Drago Anguelov",e3f5a9251529f34bc15b89e3294e576efbc0af4c,NeRDi: Single-View NeRF Synthesis with Language-Guided Diffusion as General Image Priors,ArXiv,2022,6,"2D-to-3D reconstruction is an ill-posed problem, yet humans are good at solving this problem due to their prior knowledge of the 3D world developed over years. Driven by this observation, we propose NeRDi, a single-view NeRF synthesis framework with general image priors from 2D diffusion models. Formulating single-view reconstruction as an image-conditioned 3D generation problem, we optimize the NeRF representations by minimizing a diffusion loss on its arbitrary view renderings with a pretrained image diffusion model under the input-view constraint. We leverage off-the-shelf vision-language models and introduce a two-section language guidance as conditioning inputs to the diffusion model. This is essentially helpful for improving multiview content coherence as it narrows down the general image prior conditioned on the semantic and visual features of the single-view input image. Additionally, we introduce a geometric loss based on estimated depth maps to regularize the underlying 3D geometry of the NeRF. Experimental results on the DTU MVS dataset show that our method can synthesize novel views with higher quality even compared to existing methods trained on this dataset. We also demonstrate our generalizability in zero-shot NeRF synthesis for in-the-wild images."
"Titas Anciukevivcius, Zexiang Xu, Matthew Fisher, Paul Henderson, Hakan Bilen, N. Mitra, Paul Guerrero",af85b0025fa17bf2b5e816e6a3e95b8f928c9fad,"RenderDiffusion: Image Diffusion for 3D Reconstruction, Inpainting and Generation",ArXiv,2022,6,"Diffusion models currently achieve state-of-the-art performance for both conditional and unconditional image generation. However, so far, image diffusion models do not support tasks required for 3D understanding, such as view-consistent 3D generation or single-view object reconstruction. In this paper, we present RenderDiffusion as the first diffusion model for 3D generation and inference that can be trained using only monocular 2D supervision. At the heart of our method is a novel image denoising architecture that generates and renders an intermediate three-dimensional representation of a scene in each denoising step. This enforces a strong inductive structure into the diffusion process that gives us a 3D consistent representation while only requiring 2D supervision. The resulting 3D representation can be rendered from any viewpoint. We evaluate RenderDiffusion on ShapeNet and Clevr datasets and show competitive performance for generation of 3D scenes and inference of 3D scenes from 2D images. Additionally, our diffusion-based approach allows us to use 2D inpainting to edit 3D scenes. We believe that our work promises to enable full 3D generation at scale when trained on massive image collections, thus circumventing the need to have large-scale 3D model collections for supervision."
"Junyoung Seo, Gyuseong Lee, Seokju Cho, Jiyoung Lee, Seung Wook Kim",1ed3b73719016f3500c5976234111b87c21837bf,MIDMs: Matching Interleaved Diffusion Models for Exemplar-based Image Translation,ArXiv,2022,6,"We present a novel method for exemplar-based image translation, called matching interleaved diffusion models (MIDMs). Most existing methods for this task were formulated as GAN-based matching-then-generation framework. However, in this framework, matching errors induced by the difficulty of semantic matching across cross-domain, e.g., sketch and photo, can be easily propagated to the generation step, which in turn leads to degenerated results. Motivated by the recent success of diffusion models overcoming the shortcomings of GANs, we incorporate the diffusion models to overcome these limitations. Specifically, we formulate a diffusion-based matching-and-generation framework that interleaves cross-domain matching and diffusion steps in the latent space by iteratively feeding the intermediate warp into the noising process and denoising it to generate a translated image. In addition, to improve the reliability of the diffusion process, we design a confidence-aware process using cycle-consistency to consider only confident regions during translation. Experimental results show that our MIDMs generate more plausible images than state-of-the-art methods."
"Hazrat Ali, Shafaq Murad, Zubair Shah",51aafc680ccf6ba7d879e31fce49c55fd299f760,Spot the fake lungs: Generating Synthetic Medical Images using Neural Diffusion Models,Irish Conference on Artificial Intelligence and Cognitive Science,2022,6,"Generative models are becoming popular for the synthesis of medical images. Recently, neural diffusion models have demonstrated the potential to generate photo-realistic images of objects. However, their potential to generate medical images is not explored yet. In this work, we explore the possibilities of synthesis of medical images using neural diffusion models. First, we use a pre-trained DALLE2 model to generate lungs X-Ray and CT images from an input text prompt. Second, we train a stable diffusion model with 3165 X-Ray images and generate synthetic images. We evaluate the synthetic image data through a qualitative analysis where two independent radiologists label randomly chosen samples from the generated data as real, fake, or unsure. Results demonstrate that images generated with the diffusion model can translate characteristics that are otherwise very specific to certain medical conditions in chest X-Ray or CT images. Careful tuning of the model can be very promising. To the best of our knowledge, this is the first attempt to generate lungs X-Ray and CT images using neural diffusion models. This work aims to introduce a new dimension in artificial intelligence for medical imaging. Given that this is a new topic, the paper will serve as an introduction and motivation for the research community to explore the potential of diffusion models for medical image synthesis. We have released the synthetic images on https://www.kaggle.com/datasets/hazrat/awesomelungs."
"Puria Azadi Moghadam, Sanne Van Dalen, Karina C. Martin, J. Lennerz, S. Yip, H. Farahani, A. Bashashati",804989a3687af0b13102569ffbb1c80f81eb454f,A Morphology Focused Diffusion Probabilistic Model for Synthesis of Histopathology Images,IEEE Workshop/Winter Conference on Applications of Computer Vision,2022,5,"Visual microscopic study of diseased tissue by pathologists has been the cornerstone for cancer diagnosis and prognostication for more than a century. Recently, deep learning methods have made significant advances in the analysis and classification of tissue images. However, there has been limited work on the utility of such models in generating histopathology images. These synthetic images have several applications in pathology including utilities in education, proficiency testing, privacy, and data sharing. Recently, diffusion probabilistic models were introduced to generate high quality images. Here, for the first time, we investigate the potential use of such models along with prioritized morphology weighting and color normalization to synthesize high quality histopathology images of brain cancer. Our detailed results show that diffusion probabilistic models are capable of synthesizing a wide range of histopathology images and have superior performance compared to generative adversarial networks."
"J. Ackermann, Minjun Li",6eed3f71e6274d7083b0c193561f0699db76800b,High-Resolution Image Editing via Multi-Stage Blended Diffusion,ArXiv,2022,5,"Diffusion models have shown great results in image generation and in image editing. However, current approaches are limited to low resolutions due to the computational cost of training diffusion models for high-resolution generation. We propose an approach that uses a pre-trained low-resolution diffusion model to edit images in the megapixel range. We first use Blended Diffusion to edit the image at a low resolution, and then upscale it in multiple stages, using a super-resolution model and Blended Diffusion. Using our approach, we achieve higher visual fidelity than by only applying off the shelf super-resolution methods to the output of the diffusion model. We also obtain better global consistency than directly using the diffusion model at a higher resolution."
"Narek Tumanyan, Michal Geyer, S. Bagon, Tali Dekel",b000d6865db824af1563708fb7a545ddd65c6b3a,Plug-and-Play Diffusion Features for Text-Driven Image-to-Image Translation,ArXiv,2022,5,"Large-scale text-to-image generative models have been a revolutionary breakthrough in the evolution of generative AI, allowing us to synthesize diverse images that convey highly complex visual concepts. However, a pivotal chal-lenge in leveraging such models for real-world content creation tasks is providing users with control over the generated content. In this paper, we present a new framework that takes text-to-image synthesis to the realm of image-to-image translation – given a guidance image and a target text prompt as input, our method harnesses the power of a pre-trained text-to-image diffusion model to generate a new image that complies with the target text, while preserving the semantic layout of the guidance image. Speciﬁcally, we observe and empirically demonstrate that ﬁne-grained control over the generated structure can be achieved by manipulating spatial features and their self-attention inside the model. This results in a simple and effective approach, where features extracted from the guidance image are directly injected into the generation process of the translated image, requiring no training or ﬁne-tuning. We demonstrate high-quality results on versatile text-guided image translation tasks, including translating sketches, rough drawings and animations into realistic images, changing of the class and appearance of objects in a given image, and modiﬁca-tions of global qualities such as lighting and color."
"Qing Lyu, Ge Wang",0a44ac19fdbd06e7c650b3d16a05c14dcde8f775,Conversion Between CT and MRI Images Using Diffusion and Score-Matching Models,ArXiv,2022,5,"—MRI and CT are most widely used medical imaging modalities. It is often necessary to acquire multi-modality images for diagnosis and treatment such as radiotherapy planning. However, multi-modality imaging is not only costly but also introduces misalignment between MRI and CT images. To address this challenge, computational conversion is a viable approach between MRI and CT images, especially from MRI to CT images. In this paper, we propose to use an emerging deep learning framework called diffusion and score-matching models in this context. Speciﬁcally, we adapt denoising diffusion probabilistic and score-matching models, use four different sam- pling strategies, and compare their performance metrics with that using a convolutional neural network and a generative adversarial network model. Our results show that the diffusion and score-matching models generate better synthetic CT images than the CNN and GAN models. Furthermore, we investigate the uncertainties associated with the diffusion and score-matching networks using the Monte-Carlo method, and improve the results by averaging their Monte-Carlo outputs. Our study suggests that diffusion and score-matching models are powerful to generate high quality images conditioned on an image obtained using a complementary imaging modality, analytically rigorous with clear explainability, and highly competitive with CNNs and GANs for image synthesis."
"Chaerin Kong, D. Jeon, Oh-Hun Kwon, N. Kwak",2bb7b80739da8f0b63a2a49ef4c7f6e71f3f404f,Leveraging Off-the-shelf Diffusion Model for Multi-attribute Fashion Image Manipulation,IEEE Workshop/Winter Conference on Applications of Computer Vision,2022,5,"Fashion attribute editing is a task that aims to convert the semantic attributes of a given fashion image while preserving the irrelevant regions. Previous works typically employ conditional GANs where the generator explicitly learns the target attributes and directly execute the conversion. These approaches, however, are neither scalable nor generic as they operate only with few limited attributes and a separate generator is required for each dataset or attribute set. Inspired by the recent advancement of diffusion models, we explore the classifier-guided diffusion that leverages the off-the-shelf diffusion model pretrained on general visual semantics such as Imagenet. In order to achieve a generic editing pipeline, we pose this as multi-attribute image manipulation task, where the attribute ranges from item category, fabric, pattern to collar and neckline. We empirically show that conventional methods fail in our challenging setting, and study efficient adaptation scheme that involves recently introduced attention-pooling technique to obtain a multi-attribute classifier guidance. Based on this, we present a mask-free fashion attribute editing framework that leverages the classifier logits and the cross-attention map for manipulation. We empirically demonstrate that our framework achieves convincing sample quality and attribute alignments."
"Minghui Hu, Chuanxia Zheng, Heliang Zheng, Tat-Jen Cham, Chaoyue Wang, Zuopeng Yang, Dacheng Tao, P. Suganthan",0b59a2680806fe518429957a7a19a9b0e4f24e3e,Unified Discrete Diffusion for Simultaneous Vision-Language Generation,ArXiv,2022,5,"The recently developed discrete diffusion models perform extraordinarily well in the text-to-image task, showing significant promise for handling the multi-modality signals. In this work, we harness these traits and present a unified multimodal generation model that can conduct both the""modality translation""and""multi-modality generation""tasks using a single model, performing text-based, image-based, and even vision-language simultaneous generation. Specifically, we unify the discrete diffusion process for multimodal signals by proposing a unified transition matrix. Moreover, we design a mutual attention module with fused embedding layer and a unified objective function to emphasise the inter-modal linkages, which are vital for multi-modality generation. Extensive experiments indicate that our proposed method can perform comparably to the state-of-the-art solutions in various generation tasks."
"Weilun Wang, Jianmin Bao, Wen-gang Zhou, Dongdong Chen, Dong Chen, Lu Yuan, Houqiang Li",017a9334105858aba00e8b4e13e423b8e4a2e7fb,SinDiffusion: Learning a Diffusion Model from a Single Natural Image,ArXiv,2022,5,"We present SinDiffusion, leveraging denoising diffusion models to capture internal distribution of patches from a single natural image. SinDiffusion significantly improves the quality and diversity of generated samples compared with existing GAN-based approaches. It is based on two core designs. First, SinDiffusion is trained with a single model at a single scale instead of multiple models with progressive growing of scales which serves as the default setting in prior work. This avoids the accumulation of errors, which cause characteristic artifacts in generated results. Second, we identify that a patch-level receptive field of the diffusion network is crucial and effective for capturing the image's patch statistics, therefore we redesign the network structure of the diffusion model. Coupling these two designs enables us to generate photorealistic and diverse images from a single image. Furthermore, SinDiffusion can be applied to various applications, i.e., text-guided image generation, and image outpainting, due to the inherent capability of diffusion models. Extensive experiments on a wide range of images demonstrate the superiority of our proposed method for modeling the patch distribution."
"Yaniv Nikankin, Niv Haim, M. Irani",d8fcb72391c9fbf282fe567819c0a323eb2fdf96,SinFusion: Training Diffusion Models on a Single Image or Video,ArXiv,2022,5,"Diffusion models exhibited tremendous progress in image and video generation, exceeding GANs in quality and diversity. However, they are usually trained on very large datasets and are not naturally adapted to manipulate a given input image or video. In this paper we show how this can be resolved by training a diffusion model on a single input image or video. Our image/video-specific diffusion model (SinFusion) learns the appearance and dynamics of the single image or video, while utilizing the conditioning capabilities of diffusion models. It can solve a wide array of image/video-specific manipulation tasks. In particular, our model can learn from few frames the motion and dynamics of a single input video. It can then generate diverse new video samples of the same dynamic scene, extrapolate short videos into long ones (both forward and backward in time) and perform video upsampling. Most of these tasks are not realizable by current video-specific generation methods."
"Sam L. Polk, Kangning Cui, R. Plemmons, James M. Murphy",380b086c71b59f263dfcbf8bf8eb67c3ee38f967,Active Diffusion and VCA-Assisted Image Segmentation of Hyperspectral Images,IEEE International Geoscience and Remote Sensing Symposium,2022,5,"Hyperspectral images encode rich structure that can be ex-ploited for material discrimination by machine learning al-gorithms. This article introduces the Active Diffusion and VCA-Assisted Image Segmentation (ADVIS) for active mate-rial discrimination. ADVIS selects high-purity, high-density pixels that are far in diffusion distance (a data-dependent met-ric) from other high-purity, high-density pixels in the hyper-spectral image. The ground truth labels of these pixels are queried and propagated to the rest of the image. The ADVIS active learning algorithm is shown to strongly outperform its fully unsupervised clustering algorithm counterpart, suggesting that the incorporation of a very small number of carefully-selected ground truth labels can result in substantially supe-rior material discrimination in hyperspectral images."
"Jie Shi, Chenfei Wu, Jian Liang, Xiang Liu, Nan Duan",32b3553d7dc8a263c63d32eeec2916d1647ab178,DiVAE: Photorealistic Images Synthesis with Denoising Diffusion Decoder,ArXiv,2022,4,"Recently most successful image synthesis models are multi stage process to combine the advantages of different methods, which always includes a VAE-like model for faithfully reconstructing embedding to image and a prior model to generate image embedding. At the same time, diffusion models have shown be capacity to generate high-quality synthetic images. Our work proposes a VQ-VAE architecture model with a diffusion decoder (DiVAE) to work as the reconstructing component in image synthesis. We explore how to input image embedding into diffusion model for excellent performance and find that simple modification on diffusion's UNet can achieve it. Training on ImageNet, Our model achieves state-of-the-art results and generates more photorealistic images specifically. In addition, we apply the DiVAE with an Auto-regressive generator on conditional synthesis tasks to perform more human-feeling and detailed samples."
"Ling Yang, Zhilin Huang, Yang Song, Shenda Hong, G. Li, Wentao Zhang, Bin Cui, Bernard Ghanem, Ming-Hsuan Yang",5c99b2ea5fce5ca2ad8bef47fa06b9de9b523f66,Diffusion-Based Scene Graph to Image Generation with Masked Contrastive Pre-Training,ArXiv,2022,4,"Generating images from graph-structured inputs, such as scene graphs, is uniquely challenging due to the difﬁ-culty of aligning nodes and connections in graphs with objects and their relations in images. Most existing methods address this challenge by using scene layouts, which are image-like representations of scene graphs designed to capture the coarse structures of scene images. Be-cause scene layouts are manually crafted, the alignment with images may not be fully optimized, causing suboptimal compliance between the generated images and the original scene graphs. To tackle this issue, we propose to learn scene graph embeddings by directly optimizing their alignment with images. Speciﬁcally, we pre-train an encoder to extract both global and local information from scene graphs that are predictive of the corresponding images, relying on two loss functions: masked autoencoding loss and contrastive loss. The former trains embeddings by reconstructing randomly masked image regions, while the latter trains embeddings to discriminate between compliant and non-compliant images according to the scene graph. Given these embeddings, we build a latent diffusion model to generate images from scene graphs. The resulting method, called SGDiff, allows for the semantic manipulation of generated images by modifying scene graph nodes and connections. On the Visual Genome and COCO-Stuff datasets, we demonstrate that SGDiff outperforms state-of-the-art methods, as measured by both the Inception Score and Fr´echet Inception Distance (FID) metrics. We will release our source code and trained models at"
"Zijiao Chen, Jiaxin Qing, Tiange Xiang, Wan Lin Yue, J. Zhou",c668b80885784a2c02b7837978ee95fefd108f1d,Seeing Beyond the Brain: Conditional Diffusion Model with Sparse Masked Modeling for Vision Decoding,ArXiv,2022,4,"Decoding visual stimuli from brain recordings aims to deepen our understanding of the human visual system and build a solid foundation for bridging human and computer vision through the Brain-Computer Interface. However, reconstructing high-quality images with correct semantics from brain recordings is a challenging problem due to the complex underlying representations of brain signals and the scarcity of data annotations. In this work, we present MinD-Vis: Sparse Masked Brain Modeling with Double-Conditioned Latent Diffusion Model for Human Vision Decoding. Firstly, we learn an effective self-supervised representation of fMRI data using mask modeling in a large latent space inspired by the sparse coding of information in the primary visual cortex. Then by augmenting a latent diffusion model with double-conditioning, we show that MinD-Vis can reconstruct highly plausible images with semantically matching details from brain recordings using very few paired annotations. We benchmarked our model qualitatively and quantitatively; the experimental results indicate that our method outperformed state-of-the-art in both semantic mapping (100-way semantic classification) and generation quality (FID) by 66% and 41% respectively. An exhaustive ablation study was also conducted to analyze our framework."
"Zhixing Zhang, Ligong Han, Arna Ghosh, Dimitris N. Metaxas, Jian Ren",a6ad30123bef4b19ee40c3d63cfabf00d211f0ef,SINE: SINgle Image Editing with Text-to-Image Diffusion Models,ArXiv,2022,4,"Recent works on diffusion models have demonstrated a strong capability for conditioning image generation, e.g., text-guided image synthesis. Such success inspires many efforts trying to use large-scale pre-trained diffusion models for tackling a challenging problem--real image editing. Works conducted in this area learn a unique textual token corresponding to several images containing the same object. However, under many circumstances, only one image is available, such as the painting of the Girl with a Pearl Earring. Using existing works on fine-tuning the pre-trained diffusion models with a single image causes severe overfitting issues. The information leakage from the pre-trained diffusion models makes editing can not keep the same content as the given image while creating new features depicted by the language guidance. This work aims to address the problem of single-image editing. We propose a novel model-based guidance built upon the classifier-free guidance so that the knowledge from the model trained on a single image can be distilled into the pre-trained diffusion model, enabling content creation even with one given image. Additionally, we propose a patch-based fine-tuning that can effectively help the model generate images of arbitrary resolution. We provide extensive experiments to validate the design choices of our approach and show promising editing capabilities, including changing style, content addition, and object manipulation. The code is available for research purposes at https://github.com/zhang-zx/SINE.git ."
"V. Kulikov, Shahar Yadin, Matan Kleiner, T. Michaeli",7f2d496791b8a40ac919667803e1c76f2dcb285d,SinDDM: A Single Image Denoising Diffusion Model,ArXiv,2022,4,"Denoising diffusion models (DDMs) have led to staggering performance leaps in image generation, editing and restoration. However, existing DDMs use very large datasets for training. Here, we introduce a framework for training a DDM on a single image. Our method, which we coin SinDDM, learns the internal statistics of the training image by using a multi-scale diffusion process. To drive the reverse diffusion process, we use a fully-convolutional light-weight denoiser, which is conditioned on both the noise level and the scale. This architecture allows generating samples of arbitrary dimensions, in a coarse-to-fine manner. As we illustrate, SinDDM generates diverse high-quality samples, and is applicable in a wide array of tasks, including style transfer and harmonization. Furthermore, it can be easily guided by external supervision. Particularly, we demonstrate text-guided generation from a single image using a pre-trained CLIP model."
"Wei Li, X. Xu, Xinyan Xiao, Jiacheng Liu, Hu Yang, Guohao Li, Zhanpeng Wang, Zhifan Feng, Qiaoqiao She, Yajuan Lyu, Hua Wu",8ff9667c8c948df1e84606dc086d9a4fba2256f7,UPainting: Unified Text-to-Image Diffusion Generation with Cross-modal Guidance,ArXiv,2022,4,"Diffusion generative models have recently greatly improved the power of text-conditioned image generation. Existing image generation models mainly include text conditional diffusion model and cross-modal guided diffusion model, which are good at small scene image generation and complex scene image generation respectively. In this work, we propose a simple yet effective approach, namely UPainting, to unify simple and complex scene image generation, as shown in Figure 1. Based on architecture improvements and diverse guidance schedules, UPainting effectively integrates cross-modal guidance from a pretrained image-text matching model into a text conditional diffusion model that utilizes a pretrained ∗ Corresponding author. Transformer language model as the text encoder. Our key ﬁndings is that combining the power of large-scale Transformer language model in understanding language and image-text matching model in capturing cross-modal semantics and style, is effective to improve sample ﬁdelity and image-text alignment of image generation. In this way, UPainting has a more general image generation capability, which can generate images of both simple and complex scenes more effectively. To comprehensively compare text-to-image models, we further create a more general benchmark, UniBench, with well-written Chinese and English prompts in both simple and complex scenes. We compare UPainting with recent models and ﬁnd that UPainting greatly outperforms other models in terms of caption similarity and image ﬁdelity in both simple and complex scenes. model and cross-modal matching models."
"Paramanand Chandramouli, Kanchana Vaishnavi Gandikota",679a0d3c21c7320cf1c03ec06305df26cb16c507,LDEdit: Towards Generalized Text Guided Image Manipulation via Latent Diffusion Models,British Machine Vision Conference,2022,4,"Research in vision-language models has seen rapid developments off-late, enabling natural language-based interfaces for image generation and manipulation. Many existing text guided manipulation techniques are restricted to specific classes of images, and often require fine-tuning to transfer to a different style or domain. Nevertheless, generic image manipulation using a single model with flexible text inputs is highly desirable. Recent work addresses this task by guiding generative models trained on the generic image datasets using pretrained vision-language encoders. While promising, this approach requires expensive optimization for each input. In this work, we propose an optimization-free method for the task of generic image manipulation from text prompts. Our approach exploits recent Latent Diffusion Models (LDM) for text to image generation to achieve zero-shot text guided manipulation. We employ a deterministic forward diffusion in a lower dimensional latent space, and the desired manipulation is achieved by simply providing the target text to condition the reverse diffusion process. We refer to our approach as LDEdit. We demonstrate the applicability of our method on semantic image manipulation and artistic style transfer. Our method can accomplish image manipulation on diverse domains and enables editing multiple attributes in a straightforward fashion. Extensive experiments demonstrate the benefit of our approach over competing baselines."
"Simon Welker, H. Chapman, Timo Gerkmann",3e09ee02e0959c00d7be1cd5f52b8486d6916030,DriftRec: Adapting diffusion models to blind image restoration tasks,ArXiv,2022,4,"In this work, we utilize the high-fidelity generation abilities of diffusion models to solve blind image restoration tasks, using JPEG artifact removal at high compression levels as an example. We propose an elegant modification of the forward stochastic differential equation of diffusion models to adapt them to restoration tasks and name our method DriftRec. Comparing DriftRec against an $L_2$ regression baseline with the same network architecture and a state-of-the-art technique for JPEG reconstruction, we show that our approach can escape both baselines' tendency to generate blurry images, and recovers the distribution of clean images significantly more faithfully while only requiring a dataset of clean/corrupted image pairs and no knowledge about the corruption operation. By utilizing the idea that the distributions of clean and corrupted images are much closer to each other than to a Gaussian prior, our approach requires only low levels of added noise, and thus needs comparatively few sampling steps even without further optimizations."
"Kunpeng Song, Ligong Han, Bingchen Liu, Dimitris N. Metaxas, A. Elgammal",ce5bcccd5ab303e73e166b0cbf511d5f5b45acbb,Diffusion Guided Domain Adaptation of Image Generators,ArXiv,2022,3,"Can a text-to-image diffusion model be used as a training objective for adapting a GAN generator to another domain? In this paper, we show that the classifier-free guidance can be leveraged as a critic and enable generators to distill knowledge from large-scale text-to-image diffusion models. Generators can be efficiently shifted into new domains indicated by text prompts without access to groundtruth samples from target domains. We demonstrate the effectiveness and controllability of our method through extensive experiments. Although not trained to minimize CLIP loss, our model achieves equally high CLIP scores and significantly lower FID than prior work on short prompts, and outperforms the baseline qualitatively and quantitatively on long and complicated prompts. To our best knowledge, the proposed method is the first attempt at incorporating large-scale pre-trained diffusion models and distillation sampling for text-driven image generator domain adaptation and gives a quality previously beyond possible. Moreover, we extend our work to 3D-aware style-based generators and DreamBooth guidance."
"Gwanghyun Kim, S. Chun",8f80620a8bf12fc6001248ca0cc3d2449db10a8f,DATID-3D: Diversity-Preserved Domain Adaptation Using Text-to-Image Diffusion for 3D Generative Model,ArXiv,2022,3,"Recent 3D generative models have achieved remarkable performance in synthesizing high resolution photorealistic images with view consistency and detailed 3D shapes, but training them for diverse domains is challenging since it requires massive training images and their camera distribution information. Text-guided domain adaptation methods have shown impressive performance on converting the 2D generative model on one domain into the models on other domains with different styles by leveraging the CLIP (Contrastive Language-Image Pre-training), rather than collecting massive datasets for those domains. However, one drawback of them is that the sample diversity in the original generative model is not well-preserved in the domain-adapted generative models due to the deterministic nature of the CLIP text encoder. Text-guided domain adaptation will be even more challenging for 3D generative models not only because of catastrophic diversity loss, but also because of inferior text-image correspondence and poor image quality. Here we propose DATID-3D, a domain adaptation method tailored for 3D generative models using text-to-image diffusion models that can synthesize diverse images per text prompt without collecting additional images and camera information for the target domain. Unlike 3D extensions of prior text-guided domain adaptation methods, our novel pipeline was able to fine-tune the state-of-the-art 3D generator of the source domain to synthesize high resolution, multi-view consistent images in text-guided targeted domains without additional data, outperforming the existing text-guided domain adaptation methods in diversity and text-image correspondence. Furthermore, we propose and demonstrate diverse 3D image manipulations such as one-shot instance-selected adaptation and single-view manipulated 3D reconstruction to fully enjoy diversity in text."
"Qiucheng Wu, Yujian Liu, Handong Zhao, Ajinkya Kale, T. Bui, Tong Yu, Zhe Lin, Yang Zhang, Shiyu Chang",b916302feec5be76fc4aa935202008f6ae638efa,Uncovering the Disentanglement Capability in Text-to-Image Diffusion Models,ArXiv,2022,3,"Generative models have been widely studied in computer vision. Recently, diffusion models have drawn substantial attention due to the high quality of their generated images. A key desired property of image generative models is the ability to disentangle different attributes, which should enable modification towards a style without changing the semantic content, and the modification parameters should generalize to different images. Previous studies have found that generative adversarial networks (GANs) are inherently endowed with such disentanglement capability, so they can perform disentangled image editing without re-training or fine-tuning the network. In this work, we explore whether diffusion models are also inherently equipped with such a capability. Our finding is that for stable diffusion models, by partially changing the input text embedding from a neutral description (e.g.,""a photo of person"") to one with style (e.g.,""a photo of person with smile"") while fixing all the Gaussian random noises introduced during the denoising process, the generated images can be modified towards the target style without changing the semantic content. Based on this finding, we further propose a simple, light-weight image editing algorithm where the mixing weights of the two text embeddings are optimized for style matching and content preservation. This entire process only involves optimizing over around 50 parameters and does not fine-tune the diffusion model itself. Experiments show that the proposed method can modify a wide range of attributes, with the performance outperforming diffusion-model-based image-editing algorithms that require fine-tuning. The optimized weights generalize well to different images. Our code is publicly available at https://github.com/UCSB-NLP-Chang/DiffusionDisentanglement."
"R. Burgert, Kanchana Ranasinghe, Xiang Li, M. Ryoo",a9bf659c0c0b38af20081fd484b872ae08d851d6,Peekaboo: Text to Image Diffusion Models are Zero-Shot Segmentors,ArXiv,2022,3,"Recent diffusion-based generative models combined with vision-language models are capable of creating realistic images from natural language prompts. While these models are trained on large internet-scale datasets, such pre-trained models are not directly introduced to any semantic localization or grounding. Most current approaches for localization or grounding rely on human-annotated localization information in the form of bounding boxes or segmentation masks. The exceptions are a few unsupervised methods that utilize architectures or loss functions geared towards localization, but they need to be trained separately. In this work, we explore how off-the-shelf diffusion models, trained with no exposure to such localization information, are capable of grounding various semantic phrases with no segmentation-specific re-training. An inference time optimization process is introduced, that is capable of generating segmentation masks conditioned on natural language. We evaluate our proposal Peekaboo for unsupervised semantic segmentation on the Pascal VOC dataset. In addition, we evaluate for referring segmentation on the RefCOCO dataset. In summary, we present a first zero-shot, open-vocabulary, unsupervised (no localization information), semantic grounding technique leveraging diffusion-based generative models with no re-training. Our code will be released publicly."
"Xutao Guo, Yanwu Yang, Chenfei Ye, Shangfeng Lu, Yang Xiang, Tingxia Ma",28e234cd2e93ca8ad4bcac0937c91dea4e173847,Accelerating Diffusion Models via Pre-segmentation Diffusion Sampling for Medical Image Segmentation,ArXiv,2022,3,"Based on the Denoising Diffusion Probabilistic Model (DDPM), medical image segmentation can be described as a conditional image generation task, which allows to compute pixel-wise uncertainty maps of the segmentation and allows an implicit ensemble of segmentations to boost the segmentation performance. However, DDPM requires many itera-tive denoising steps to generate segmentations from Gaussian noise, resulting in extremely inefﬁcient inference. To mitigate the issue, we propose a principled acceleration strategy, called pre-segmentation diffusion sampling DDPM (PD-DDPM), which is specially used for medical image segmentation. The key idea is to obtain pre-segmentation results based on a separately trained segmentation network, and construct noise predictions (non-Gaussian distribution) according to the forward diffusion rule. We can then start with noisy predictions and use fewer reverse steps to generate segmentation results. Experiments show that PD-DDPM yields better segmentation results over representative baseline methods even if the number of reverse steps is signiﬁcantly reduced. Moreover, PD-DDPM is orthogonal to existing advanced segmentation models, which can be combined to further improve the segmentation performance."
"Nisha Huang, Yu-xin Zhang, Fan Tang, Chongyang Ma, Haibin Huang, Yong Zhang, Weiming Dong, Changsheng Xu",662ca5c9ddaae1e5accaa69f588122249a156740,DiffStyler: Controllable Dual Diffusion for Text-Driven Image Stylization,ArXiv,2022,3,"Despite the impressive results of arbitrary image-guided style transfer methods, text-driven image stylization has recently been proposed for transferring a natural image into the stylized one according to textual descriptions of the target style provided by the user. Unlike previous image-to-image transfer approaches, text-guided stylization progress provides users with a more precise and intuitive way to express the desired style. However, the huge discrepancy between cross-modal inputs/outputs makes it challenging to conduct text-driven image stylization in a typical feed-forward CNN pipeline. In this paper, we present DiffStyler on the basis of diffusion models. The cross-modal style information can be easily integrated as guidance during the diffusion progress step-by-step. In particular, we use a dual diffusion processing architecture to control the balance between the content and style of the diffused results. Furthermore, we propose a content image-based learnable noise on which the reverse denoising process is based, enabling the stylization results to better preserve the structure information of the content image. We validate the proposed DiffStyler beyond the baseline methods through extensive qualitative and quantitative experiments."
"Gustav Müller-Franzes, J. Niehues, F. Khader, Soroosh Tayebi Arasteh, Christoph Haarburger, C. Kuhl, Tian Wang, T. Han, S. Nebelung, Jakob Nikolas Kather, D. Truhn",2a43f920e4f1f869a9db402a50135f9f8df06f32,Diffusion Probabilistic Models beat GANs on Medical Images,ArXiv,2022,3,"The success of Deep Learning applications critically depends on the quality and scale of the underlying training data. Generative adversarial networks (GANs) can generate arbitrary large datasets, but diversity and fidelity are limited, which has recently been addressed by denoising diffusion probabilistic models (DDPMs) whose superiority has been demonstrated on natural images. In this study, we propose Medfusion, a conditional latent DDPM for medical images. We compare our DDPM-based model against GAN-based models, which constitute the current state-of-the-art in the medical domain. Medfusion was trained and compared with (i) StyleGan-3 on n=101,442 images from the AIROGS challenge dataset to generate fundoscopies with and without glaucoma, (ii) ProGAN on n=191,027 from the CheXpert dataset to generate radiographs with and without cardiomegaly and (iii) wGAN on n=19,557 images from the CRCMS dataset to generate histopathological images with and without microsatellite stability. In the AIROGS, CRMCS, and CheXpert datasets, Medfusion achieved lower (=better) FID than the GANs (11.63 versus 20.43, 30.03 versus 49.26, and 17.28 versus 84.31). Also, fidelity (precision) and diversity (recall) were higher (=better) for Medfusion in all three datasets. Our study shows that DDPM are a superior alternative to GANs for image synthesis in the medical domain."
"Zixin Zhu, Yixuan Wei, Jianfeng Wang, Zhe Gan, Zheng Zhang, Le Wang, G. Hua, Lijuan Wang, Zicheng Liu, Han Hu",f991d1622949a2dea285d2ad0cfb2e8157cb84b4,Exploring Discrete Diffusion Models for Image Captioning,ArXiv,2022,3,"The image captioning task is typically realized by an auto-regressive method that decodes the text tokens one by one. We present a diffusion-based captioning model, dubbed the name DDCap, to allow more decoding flexibility. Unlike image generation, where the output is continuous and redundant with a fixed length, texts in image captions are categorical and short with varied lengths. Therefore, naively applying the discrete diffusion model to text decoding does not work well, as shown in our experiments. To address the performance gap, we propose several key techniques including best-first inference, concentrated attention mask, text length prediction, and image-free training. On COCO without additional caption pre-training, it achieves a CIDEr score of 117.8, which is +5.0 higher than the auto-regressive baseline with the same architecture in the controlled setting. It also performs +26.8 higher CIDEr score than the auto-regressive baseline (230.3 v.s.203.5) on a caption infilling task. With 4M vision-language pre-training images and the base-sized model, we reach a CIDEr score of 125.1 on COCO, which is competitive to the best well-developed auto-regressive frameworks. The code is available at https://github.com/buxiangzhiren/DDCap."
"L. Luzi, Ali Siahkoohi, P. Mayer, Josue Casco-Rodriguez, Richard Baraniuk",e607c4516c7f2dda67b326ddda8c5afd1b2ff2a9,Boomerang: Local sampling on image manifolds using diffusion models,ArXiv,2022,3,"Diffusion models can be viewed as mapping points in a high-dimensional latent space onto a low-dimensional learned manifold, typically an image manifold. The intermediate values between the latent space and image manifold can be interpreted as noisy images which are determined by the noise scheduling scheme employed during pre-training. We exploit this interpretation to introduce Boomerang, a local image manifold sampling approach using the dynamics of diffusion models. We call it Boomerang because we first add noise to an input image, moving it closer to the latent space, then bring it back to the image space through diffusion dynamics. We use this method to generate images which are similar, but nonidentical, to the original input images on the image manifold. We are able to set how close the generated image is to the original based on how much noise we add. Additionally, the generated images have a degree of stochasticity, allowing us to locally sample as many times as we want without repetition. We show three applications for which Boomerang can be used. First, we provide a framework for constructing privacy-preserving datasets having controllable degrees of anonymity. Second, we show how to use Boomerang for data augmentation while staying on the image manifold. Third, we introduce a framework for image super-resolution with 8x upsampling. Boomerang does not require any modification to the training of diffusion models and can be used with pretrained models on a single, inexpensive GPU."
"Vedant Singh, Surgan Jandial, Ayush Chopra, Siddharth Ramesh, Balaji Krishnamurthy, V. Balasubramanian",d9db5cfec091149662787979c3a50e4386bcacec,On Conditioning the Input Noise for Controlled Image Generation with Diffusion Models,ArXiv,2022,3,"Conditional image generation has paved the way for several breakthroughs in image editing, generating stock pho-tos and 3-D object generation. This continues to be a signiﬁcant area of interest with the rise of new state-of-the-art methods that are based on diffusion models. However, diffusion models provide very little control over the generated image, which led to subsequent works exploring techniques like classiﬁer guidance, that provides a way to trade off di-versity with ﬁdelity. In this work, we explore techniques to condition diffusion models with carefully crafted input noise artifacts. This allows generation of images conditioned on semantic attributes. This is different from existing approaches that input Gaussian noise and further introduce conditioning at the diffusion model’s inference step. Our experiments over several examples and conditional settings show the potential of our approach."
"Leevi Kerkela, K. Seunarine, R. Henriques, J. Clayden, C. Clark",686328c13d26e8c28222c0b77e5300d2e47335a0,Improved reproducibility of diffusion kurtosis imaging using regularized non-linear optimization informed by artificial neural networks,,2022,3,"Diﬀusion kurtosis imaging is an extension of diﬀusion tensor imaging that provides scientiﬁcally and clinically valuable information about brain tissue microstructure but suﬀers from poor robustness to noise, especially in voxels containing tightly packed aligned axons. We present a new algorithm for estimating diﬀusion and kurtosis tensors using regularized non-linear optimization and make it publicly available in an easy-to-use open-source Python software package. Our approach uses fully-connected feed-forward neural networks to predict kurtosis values in voxels where the standard non-linear least squares ﬁt fails. The predicted values are then used in the objective function to avoid implausible kurtosis values. We show that our algorithm is more robust than standard non-linear least squares and a previously proposed regularized non-linear optimization method. The algorithm was then applied on a multi-site scan-rescan dataset acquired using a clinical scan protocol to assess the reproducibility of diﬀusion kurtosis parameter estimation in human white matter using the proposed algorithm. Our results show that the reproducibility of diﬀusion kurtosis parameters is similar to diﬀusion tensor parameters."
"Zhihong Pan, Xiaoxia Zhou, Hao Tian",c072ba0ece15789fb409f22344a992ef6be5ea15,Arbitrary Style Guidance for Enhanced Diffusion-Based Text-to-Image Generation,IEEE Workshop/Winter Conference on Applications of Computer Vision,2022,2,"Diffusion-based text-to-image generation models like GLIDE and DALLE-2 have gained wide success recently for their superior performance in turning complex text inputs into images of high quality and wide diversity. In particular, they are proven to be very powerful in creating graphic arts of various formats and styles. Although current models supported specifying style formats like oil painting or pencil drawing, fine-grained style features like color distributions and brush strokes are hard to specify as they are randomly picked from a conditional distribution based on the given text input. Here we propose a novel style guidance method to support generating images using arbitrary style guided by a reference image. The generation method does not require a separate style transfer model to generate desired styles while maintaining image quality in generated content as controlled by the text input. Additionally, the guidance method can be applied without a style reference, denoted as self style guidance, to generate images of more diverse styles. Comprehensive experiments prove that the proposed method remains robust and effective in a wide range of conditions, including diverse graphic art forms, image content types and diffusion models."
"Ha-Duong Phung, Quan Dao, A. Tran",cff3337f669d615c554b6fb1806e4a84fa0bdee6,Wavelet Diffusion Models are fast and scalable Image Generators,ArXiv,2022,2,"Diffusion models are rising as a powerful solution for high-fidelity image generation, which exceeds GANs in quality in many circumstances. However, their slow training and inference speed is a huge bottleneck, blocking them from being used in real-time applications. A recent DiffusionGAN method significantly decreases the models' running time by reducing the number of sampling steps from thousands to several, but their speeds still largely lag behind the GAN counterparts. This paper aims to reduce the speed gap by proposing a novel wavelet-based diffusion scheme. We extract low-and-high frequency components from both image and feature levels via wavelet decomposition and adaptively handle these components for faster processing while maintaining good generation quality. Furthermore, we propose to use a reconstruction term, which effectively boosts the model training convergence. Experimental results on CelebA-HQ, CIFAR-10, LSUN-Church, and STL-10 datasets prove our solution is a stepping-stone to offering real-time and high-fidelity diffusion models. Our code and pre-trained checkpoints are available at \url{https://github.com/VinAIResearch/WaveDiff.git}."
"Jin Zhu, Huimin Ma, Jiansheng Chen, Jian Yuan",2c525c0a0e058b0f0d0a351c1fd43fd92929433a,Few-shot Image Generation with Diffusion Models,ArXiv,2022,2,"Denoising diffusion probabilistic models (DDPMs) have been proven capable of synthesizing high-quality images with remarkable diversity when trained on large amounts of data. However, to our knowledge, few-shot image generation tasks have yet to be studied with DDPM-based approaches. Modern approaches are mainly built on Generative Adversarial Networks (GANs) and adapt models pre-trained on large source domains to target domains using a few available samples. In this paper, we make the first attempt to study when do DDPMs overfit and suffer severe diversity degradation as training data become scarce. Then we fine-tune DDPMs pre-trained on large source domains to solve the overfitting problem when training data is limited. Although the directly fine-tuned models accelerate convergence and improve generation quality and diversity compared with training from scratch, they still fail to retain some diverse features and can only produce coarse images. Therefore, we design a DDPM pairwise adaptation (DDPM-PA) approach to optimize few-shot DDPM domain adaptation. DDPM-PA efficiently preserves information learned from source domains by keeping the relative pairwise distances between generated samples during adaptation. Besides, DDPM-PA enhances the learning of high-frequency details from source models and limited training data. DDPM-PA further improves generation quality and diversity and achieves results better than current state-of-the-art GAN-based approaches. We demonstrate the effectiveness of our approach on a series of few-shot image generation tasks qualitatively and quantitatively."
"Jaskirat Singh, Stephen Gould, Liang Zheng",2c778a4a128249fafbee25a3057265568ffbdbda,High-Fidelity Guided Image Synthesis with Latent Diffusion Models,ArXiv,2022,2,"Controllable image synthesis with user scribbles has gained huge public interest with the recent advent of text-conditioned latent diffusion models. The user scribbles control the color composition while the text prompt provides control over the overall image semantics. However, we note that prior works in this direction suffer from an intrinsic domain shift problem, wherein the generated outputs often lack details and resemble simplistic representations of the target domain. In this paper, we propose a novel guided image synthesis framework, which addresses this problem by modeling the output image as the solution of a constrained optimization problem. We show that while computing an exact solution to the optimization is infeasible, an approximation of the same can be achieved while just requiring a single pass of the reverse diffusion process. Additionally, we show that by simply defining a cross-attention based correspondence between the input text tokens and the user stroke-painting, the user is also able to control the semantics of different painted regions without requiring any conditional training or finetuning. Human user study results show that the proposed approach outperforms the previous state-of-the-art by over 85.32% on the overall user satisfaction scores. Project page for our paper is available at https://1jsingh.github.io/gradop."
"Hyungjin Chung, Jeongsol Kim, Sehui Kim, J. C. Ye",4fb6b6f7a21c09bdf85aeb7e53ee448eb85cd0ae,Parallel Diffusion Models of Operator and Image for Blind Inverse Problems,ArXiv,2022,2,"Diffusion model-based inverse problem solvers have demonstrated state-of-the-art performance in cases where the forward operator is known (i.e. non-blind). However, the applicability of the method to blind inverse problems has yet to be explored. In this work, we show that we can indeed solve a family of blind inverse problems by constructing another diffusion prior for the forward operator. Specifically, parallel reverse diffusion guided by gradients from the intermediate stages enables joint optimization of both the forward operator parameters as well as the image, such that both are jointly estimated at the end of the parallel reverse diffusion procedure. We show the efficacy of our method on two representative tasks -- blind deblurring, and imaging through turbulence -- and show that our method yields state-of-the-art performance, while also being flexible to be applicable to general blind inverse problems when we know the functional forms."
"Luke Sagers, James A. Diao, Matthew Groh, P. Rajpurkar, A. Adamson, A. Manrai",f63542853f918d905fd109fbc754f90bf2109577,Improving dermatology classifiers across populations using images generated by large diffusion models,ArXiv,2022,2,"Dermatological classiﬁcation algorithms developed without sufﬁciently diverse 1 training data may generalize poorly across populations. While more intentional 2 data collection and annotation is the best way to increase representation, new 3 computational approaches for generating training data may also aid in reducing 4 representation bias. In this paper, we show that DALL·E 2, a large text-to-image dif- 5 fusion model, can generate synthetic and photorealistic skin disease images across 6 skin types. Using the Fitzpatrick 17k dataset as a benchmark, we demonstrate that 7 including DALL·E 2-generated synthetic images improves classiﬁcation accuracy 8 of skin disease models overall and particularly for underrepresented groups."
"Heng Cao, Jianan Wang, Tianhe Ren, Xianbiao Qi, Yihao Chen, Yuan Yao, L. Zhang",1a64454d50795e143d19ec45790eecfd28ef6169,Exploring Vision Transformers as Diffusion Learners,ArXiv,2022,2,"Score-based diffusion models have captured widespread attention and funded fast progress of recent vision generative tasks. In this paper, we focus on diffusion model backbone which has been much neglected before. We systematically explore vision Transformers as diffusion learners for various generative tasks. With our improvements the performance of vanilla ViT-based backbone (IU-ViT) is boosted to be on par with traditional U-Net-based methods. We further provide a hypothesis on the implication of disentangling the generative backbone as an encoder-decoder structure and show proof-of-concept experiments verifying the effectiveness of a stronger encoder for generative tasks with ASymmetriC ENcoder Decoder (ASCEND). Our improvements achieve competitive results on CIFAR-10, CelebA, LSUN, CUB Bird and large-resolution text-to-image tasks. To the best of our knowledge, we are the first to successfully train a single diffusion model on text-to-image task beyond 64x64 resolution. We hope this will motivate people to rethink the modeling choices and the training pipelines for diffusion-based generative models."
"Q. Gao, Hongming Shan",99cd0de0a58db01fee82aabe4ea8256fcf78b6a4,CoCoDiff: a contextual conditional diffusion model for low-dose CT image denoising,Developments in X-Ray Tomography XIV,2022,2,
"Jian-Hao Luo, Yehao Li, Yingwei Pan, Ting Yao, Jianlin Feng, Hongyang Chao, Tao Mei",a6a59c9e4cd446d0d04f76587699e3e8ab5197c2,Semantic-Conditional Diffusion Networks for Image Captioning,ArXiv,2022,2,"Recent advances on text-to-image generation have witnessed the rise of diffusion models which act as powerful generative models. Nevertheless, it is not trivial to exploit such latent variable models to capture the dependency among discrete words and meanwhile pursue complex visual-language alignment in image captioning. In this paper, we break the deeply rooted conventions in learning Transformer-based encoder-decoder, and propose a new diffusion model based paradigm tailored for image captioning, namely Semantic-Conditional Diffusion Networks (SCD-Net). Technically, for each input image, we first search the semantically relevant sentences via cross-modal retrieval model to convey the comprehensive semantic information. The rich semantics are further regarded as semantic prior to trigger the learning of Diffusion Transformer, which produces the output sentence in a diffusion process. In SCD-Net, multiple Diffusion Transformer structures are stacked to progressively strengthen the output sentence with better visional-language alignment and linguistical coherence in a cascaded manner. Furthermore, to stabilize the diffusion process, a new self-critical sequence training strategy is designed to guide the learning of SCD-Net with the knowledge of a standard autoregressive Transformer model. Extensive experiments on COCO dataset demonstrate the promising potential of using diffusion models in the challenging image captioning task. Source code is available at \url{https://github.com/YehLi/xmodaler/tree/master/configs/image_caption/scdnet}."
"Zhihong Pan, Xiaoxia Zhou, Hao Tian",5f817827ec1f6f0f0dadbb139887fe485770176b,Extreme Generative Image Compression by Learning Text Embedding from Diffusion Models,ArXiv,2022,2,"Transferring large amount of high resolution images over limited bandwidth is an important but very challenging task. Compressing images using extremely low bitrates (<0.1 bpp) has been studied but it often results in low quality images of heavy artifacts due to the strong constraint in the number of bits available for the compressed data. It is often said that a picture is worth a thousand words but on the other hand, language is very powerful in capturing the essence of an image using short descriptions. With the recent success of diffusion models for text-to-image generation, we propose a generative image compression method that demonstrates the potential of saving an image as a short text embedding which in turn can be used to generate high-fidelity images which is equivalent to the original one perceptually. For a given image, its corresponding text embedding is learned using the same optimization process as the text-to-image diffusion model itself, using a learnable text embedding as input after bypassing the original transformer. The optimization is applied together with a learning compression model to achieve extreme compression of low bitrates<0.1 bpp. Based on our experiments measured by a comprehensive set of image quality metrics, our method outperforms the other state-of-the-art deep learning methods in terms of both perceptual quality and diversity."
"Tony C. W. Mok, Albert C. S. Chung",f668bf9da1ad8357a07b30cd3c9312803b6fefdf,Robust Image Registration with Absent Correspondences in Pre-operative and Follow-up Brain MRI Scans of Diffuse Glioma Patients,ArXiv,2022,2,"Registration of pre-operative and follow-up brain MRI scans is challenging due to the large variation of tissue appearance and missing correspondences in tumour recurrence regions caused by tumour mass effect. Although recent deep learning-based deformable registration methods have achieved remarkable success in various medical applications, most of them are not capable of registering images with pathologies. In this paper, we propose a 3-step registration pipeline for pre-operative and follow-up brain MRI scans that consists of 1) a multi-level affine registration, 2) a conditional deep Laplacian pyramid image registration network (cLapIRN) with forward-backward consistency constraint, and 3) a non-linear instance optimization method. We apply the method to the Brain Tumor Sequence Registration (BraTS-Reg) Challenge. Our method achieves accurate and robust registration of brain MRI scans with pathologies, which achieves a median absolute error of 1.64 mm and 88\% of successful registration rate in the validation set of BraTS-Reg challenge. Our method ranks 1st place in the 2022 MICCAI BraTS-Reg challenge."
Shi-You Xu,2afa7669096ebcec7b68b7b3cd50d7272b103e1c,CLIP-Diffusion-LM: Apply Diffusion Model on Image Captioning,ArXiv,2022,2,"Image captioning task has been extensively researched by previous work. However, limited experiments focus on generating captions based on non-autoregressive text decoder. Inspired by the recent success of the denoising diffusion model on image synthesis tasks, we apply denoising diffusion probabilistic models to text generation in image captioning tasks. We show that our CLIP-Diffusion-LM is capable of generating image captions using significantly fewer inference steps than autoregressive models. On the Flickr8k dataset, the model achieves 0.1876 BLEU-4 score. By training on the combined Flickr8k and Flickr30k dataset, our model achieves 0.2470 BLEU-4 score. Our code is available at https://github.com/xu-shitong/diffusion-image-captioning."
"Nithin Gopalakrishnan Nair, W. G. C. Bandara, Vishal M. Patel",c6480d46777da8f0e5fa6e65760f0adec31e4bff,Image Generation with Multimodal Priors using Denoising Diffusion Probabilistic Models,ArXiv,2022,2,"Image synthesis under multi-modal priors is a useful and challenging task that has received increasing attention in recent years. A major challenge in using generative models to accomplish this task is the lack of paired data containing all modalities (i.e. priors) and corresponding outputs. In recent work, a variational auto-encoder (VAE) model was trained in a weakly supervised manner to address this challenge. Since the generative power of VAEs is usually limited, it is difficult for this method to synthesize images belonging to complex distributions. To this end, we propose a solution based on a denoising diffusion probabilistic models to synthesise images under multi-model priors. Based on the fact that the distribution over each time step in the diffusion model is Gaussian, in this work we show that there exists a closed-form expression to the generate the image corresponds to the given modalities. The proposed solution does not require explicit retraining for all modalities and can leverage the outputs of individual modalities to generate realistic images according to different constraints. We conduct studies on two real-world datasets to demonstrate the effectiveness of our approach."
"Kangning Cui, R. Li, Sam L. Polk, James M. Murphy, R. Plemmons, R. Chan",3a8e439485c802f2f2927ebdc6d8bbf26985fcfa,Unsupervised Spatial-Spectral Hyperspectral Image Reconstruction And Clustering With Diffusion Geometry,Workshop on Hyperspectral Image and Signal Processing,2022,2,"Hyperspectral images, which store a hundred or more spectral bands of reflectance, have become an important data source in natural and social sciences. Hyperspectral images are often generated in large quantities at a relatively coarse spatial resolution. As such, unsupervised machine learning algorithms incorporating known structure in hyperspectral imagery are needed to analyze these images automatically. This work introduces the Spatial-Spectral Image Reconstruction and Clustering with Diffusion Geometry (DSIRC) algorithm for partitioning highly mixed hyperspectral images. DSIRC reduces measurement noise through a shape-adaptive reconstruction procedure. In particular, for each pixel, DSIRC locates spectrally correlated pixels within a data-adaptive spatial neighborhood and reconstructs that pixel's spectral signature using those of its neighbors. DSIRC then locates high-density, high-purity pixels far in diffusion distance (a data-dependent distance metric) from other high-density, high-purity pixels and treats these as cluster exemplars, giving each a unique label. Non-modal pixels are assigned the label of their diffusion distance-nearest neighbor of higher density and purity that is already labeled. Strong numerical results indicate that incorporating spatial information through image reconstruction substantially improves the performance of pixel-wise clustering."
"Sam L. Polk, Aland H. Y. Chan, Kangning Cui, R. Plemmons, D. Coomes, James M. Murphy",01f75d42c6c5f4ed55890a7cc45cf8a6b7cd0195,Unsupervised Detection of ASH Dieback Disease (Hymenoscyphus Fraxineus) Using Diffusion-Based Hyperspectral Image Clustering,IEEE International Geoscience and Remote Sensing Symposium,2022,2,"Ash dieback (Hymenoscyphus fraxineus) is an introduced fungal disease that is causing the widespread death of ash trees across Europe. Remote sensing hyperspectral images encode rich structure that has been exploited for the detection of dieback disease in ash trees using supervised machine learning techniques. However, to understand the state of forest health at landscape-scale, accurate unsupervised approaches are needed. This article investigates the use of the unsupervised Diffusion and VCA-Assisted Image Segmentation (D-VIS) clustering algorithm for the detection of ash dieback disease in a forest site near Cambridge, United Kingdom. The unsupervised clustering presented in this work has high overlap with the supervised classification of previous work on this scene (overall accuracy = 71%). Thus, unsupervised learning may be used for the remote detection of ash dieback disease without the need for expert labeling."
"Wenbo Li, Xin Yu, Kun Zhou, Yibing Song, Zhe Lin, Jiaya Jia",38c13a1e10311f18fc8feec642e448aedfe926b9,SDM: Spatial Diffusion Model for Large Hole Image Inpainting,ArXiv,2022,1,"Generative adversarial networks (GANs) have made great success in image inpainting yet still have difﬁculties tackling large missing regions. In contrast, iterative algorithms, such as autoregressive and denoising diffusion models, have to be deployed with massive computing resources for decent effect. To overcome the respective limitations, we present a novel spatial diffusion model (SDM) that uses a few iterations to gradually deliver informative pixels to the entire image, largely enhancing the inference efﬁciency. Also, thanks to the proposed decoupled probabilistic modeling and spatial diffusion scheme, our method achieves high-quality large-hole completion. On multiple benchmarks, we achieve new state-of-the-art performance. Code is released at https://github.com/fenglinglwb/SDM ."
"K. Gong, Keith A. Johnson, G. Fakhri, Quanzheng Li, T. Pan",224ba3f27630871904610b17512e59ed1bd14b81,PET image denoising based on denoising diffusion probabilistic models,ArXiv,2022,1,"Due to various physical degradation factors and limited counts received, PET image quality needs further improvements. The denoising diffusion probabilistic models (DDPM) are distribution learning-based models, which try to transform a normal distribution into a specific data distribution based on iterative refinements. In this work, we proposed and evaluated different DDPM-based methods for PET image denoising. Under the DDPM framework, one way to perform PET image denoising is to provide the PET image and/or the prior image as the network input. Another way is to supply the prior image as the input with the PET image included in the refinement steps, which can fit for scenarios of different noise levels. 120 18F-FDG datasets and 140 18F-MK-6240 datasets were utilized to evaluate the proposed DDPM-based methods. Quantification show that the DDPM-based frameworks with PET information included can generate better results than the nonlocal mean and Unet-based denoising methods. Adding additional MR prior in the model can help achieve better performance and further reduce the uncertainty during image denoising. Solely relying on MR prior while ignoring the PET information can result in large bias. Regional and surface quantification shows that employing MR prior as the network input while embedding PET image as a data-consistency constraint during inference can achieve the best performance. In summary, DDPM-based PET image denoising is a flexible framework, which can efficiently utilize prior information and achieve better performance than the nonlocal mean and Unet-based denoising methods."
"Adham Elarabawy, Harish Kamath, Samuel Denton",a4be3489d7dba5d286cf00b698f267b65ebd7aaf,Direct Inversion: Optimization-Free Text-Driven Real Image Editing with Diffusion Models,ArXiv,2022,1,"With the rise of large, publicly-available text-to-image diffusion models, text-guided real image editing has garnered much research attention recently. Existing methods tend to either rely on some form of per-instance or per-task fine-tuning and optimization, require multiple novel views, or they inherently entangle preservation of real image identity, semantic coherence, and faithfulness to text guidance. In this paper, we propose an optimization-free and zero fine-tuning framework that applies complex and non-rigid edits to a single real image via a text prompt, avoiding all the pitfalls described above. Using widely-available generic pre-trained text-to-image diffusion models, we demonstrate the ability to modulate pose, scene, background, style, color, and even racial identity in an extremely flexible manner through a single target text detailing the desired edit. Furthermore, our method, which we name $\textit{Direct Inversion}$, proposes multiple intuitively configurable hyperparameters to allow for a wide range of types and extents of real image edits. We prove our method's efficacy in producing high-quality, diverse, semantically coherent, and faithful real image edits through applying it on a variety of inputs for a multitude of tasks. We also formalize our method in well-established theory, detail future experiments for further improvement, and compare against state-of-the-art attempts."
"Ye Zhu, Yuehua Wu, Kyle Olszewski, Jian Ren, S. Tulyakov, Yan Yan",f2ad100d01a586ef798633e3801eb85bd43f45cd,Discrete Contrastive Diffusion for Cross-Modal Music and Image Generation,,2022,1,"Diffusion probabilistic models (DPMs) have become a popular approach to conditional generation, due to their promising results and support for cross-modal synthesis. A key desideratum in conditional synthesis is to achieve high correspondence between the conditioning input and generated output. Most existing methods learn such relationships implicitly, by incorporating the prior into the variational lower bound. In this work, we take a different route -- we explicitly enhance input-output connections by maximizing their mutual information. To this end, we introduce a Conditional Discrete Contrastive Diffusion (CDCD) loss and design two contrastive diffusion mechanisms to effectively incorporate it into the denoising process, combining the diffusion training and contrastive learning for the first time by connecting it with the conventional variational objectives. We demonstrate the efficacy of our approach in evaluations with diverse multimodal conditional synthesis tasks: dance-to-music generation, text-to-image synthesis, as well as class-conditioned image synthesis. On each, we enhance the input-output correspondence and achieve higher or competitive general synthesis quality. Furthermore, the proposed approach improves the convergence of diffusion models, reducing the number of required diffusion steps by more than 35% on two benchmarks, significantly increasing the inference speed."
"Daichi Horita, Jiaolong Yang, Dong Chen, Yuki Koyama, K. Aizawa",52f488b7fa13a295506e71c204493120b8c5712a,A Structure-Guided Diffusion Model for Large-Hole Diverse Image Completion,ArXiv,2022,1,"Diverse image completion, a problem of generating various ways of ﬁlling incomplete regions ( i.e . holes) of an image, has made remarkable success. However, managing input images with large holes is still a challenging problem due to the corruption of semantically important structures. In this paper, we tackle this problem by incorporating explicit structural guidance. We propose a structure-guided diffusion model (SGDM) for the large-hole diverse completion problem. Our proposed SGDM consists of a structure generator and a texture generator, which are both diffusion probabilistic models (DMs). The structure generator generates an edge image representing a plausible structure within the holes, which is later used to guide the texture generation process. To jointly train these two generators, we design a strategy that combines optimal Bayesian denoising and a momentum framework. In addition to the quality improvement, auxiliary edge images generated by the structure generator can be manually edited to allow user-guided image editing. Our experiments using datasets of faces (CelebA-HQ) and natural scenes (Places) show that our method achieves a comparable or superior trade-off between visual quality and diversity compared to other state-of-the-art"
"Rui Li, Weihua Li, Yi Yang, Hanyu Wei, Jianhua Jiang, Quan Bai",3de95f33c2b4f61a9c0f335b4810a966e209a47a,Swinv2-Imagen: Hierarchical Vision Transformer Diffusion Models for Text-to-Image Generation,ArXiv,2022,1,"Recently, diffusion models have been proven to perform remarkably well in text-to-image synthesis tasks in a number of studies, immediately presenting new study opportunities for image generation. Google's Imagen follows this research trend and outperforms DALLE2 as the best model for text-to-image generation. However, Imagen merely uses a T5 language model for text processing, which cannot ensure learning the semantic information of the text. Furthermore, the Efficient UNet leveraged by Imagen is not the best choice in image processing. To address these issues, we propose the Swinv2-Imagen, a novel text-to-image diffusion model based on a Hierarchical Visual Transformer and a Scene Graph incorporating a semantic layout. In the proposed model, the feature vectors of entities and relationships are extracted and involved in the diffusion model, effectively improving the quality of generated images. On top of that, we also introduce a Swin-Transformer-based UNet architecture, called Swinv2-Unet, which can address the problems stemming from the CNN convolution operations. Extensive experiments are conducted to evaluate the performance of the proposed model by using three real-world datasets, i.e., MSCOCO, CUB and MM-CelebA-HQ. The experimental results show that the proposed Swinv2-Imagen model outperforms several popular state-of-the-art methods."
Princy Chahal,a96bd967eaad807a914bd26a94ab965069ba1c72,Exploring Transformer Backbones for Image Diffusion Models,ArXiv,2022,1,We present an end-to-end Transformer based Latent Diffusion model for image synthesis. On the ImageNet class conditioned generation task we show that a Transformer based Latent Diffusion model achieves a 14.1FID which is comparable to the 13.1FID score of a UNet based architecture. In addition to showing the application of Transformer models for Diffusion based image synthesis this simplification in architecture allows easy fusion and modeling of text and image data. The multi-head attention mechanism of Transformers enables simplified interaction between the image and text features which removes the requirement for crossattention mechanism in UNet based Diffusion models.
"Jee Seok Yoon, Chenghao Zhang, Heung-Il Suk, Jia Guo, Xiaoxia Li",5466a6fa708db56300e62c1a9e261f4948800a4d,SADM: Sequence-Aware Diffusion Model for Longitudinal Medical Image Generation,ArXiv,2022,1,"Human organs constantly undergo anatomical changes due to a complex mix of short-term (e.g., heartbeat) and long-term (e.g., aging) factors. Evidently, prior knowledge of these factors will be beneficial when modeling their future state, i.e., via image generation. However, most of the medical image generation tasks only rely on the input from a single image, thus ignoring the sequential dependency even when longitudinal data is available. Sequence-aware deep generative models, where model input is a sequence of ordered and timestamped images, are still underexplored in the medical imaging domain that is featured by several unique challenges: 1) Sequences with various lengths; 2) Missing data or frame, and 3) High dimensionality. To this end, we propose a sequence-aware diffusion model (SADM) for the generation of longitudinal medical images. Recently, diffusion models have shown promising results in high-fidelity image generation. Our method extends this new technique by introducing a sequence-aware transformer as the conditional module in a diffusion model. The novel design enables learning longitudinal dependency even with missing data during training and allows autoregressive generation of a sequence of images during inference. Our extensive experiments on 3D longitudinal medical images demonstrate the effectiveness of SADM compared with baselines and alternative methods. The code is available at https://github.com/ubc-tea/SADM-Longitudinal-Medical-Image-Generation."
"Shady Abu Hussein, Tom Tirer, R. Giryes",87bec8dfbd7ff6507ad292026fef58ab544cf161,ADIR: Adaptive Diffusion for Image Reconstruction,ArXiv,2022,1,"In recent years, denoising diffusion models have demonstrated outstanding image generation performance. The information on natural images captured by these models is useful for many image reconstruction applications, where the task is to restore a clean image from its degraded observations. In this work, we propose a conditional sampling scheme that exploits the prior learned by diffusion models while retaining agreement with the observations. We then combine it with a novel approach for adapting pretrained diffusion denoising networks to their input. We examine two adaption strategies: the first uses only the degraded image, while the second, which we advocate, is performed using images that are ``nearest neighbors'' of the degraded image, retrieved from a diverse dataset using an off-the-shelf visual-language model. To evaluate our method, we test it on two state-of-the-art publicly available diffusion models, Stable Diffusion and Guided Diffusion. We show that our proposed `adaptive diffusion for image reconstruction' (ADIR) approach achieves a significant improvement in the super-resolution, deblurring, and text-based editing tasks."
"Yufan Zhou, Bingchen Liu, Yizhe Zhu, Xiao Yang, Changyou Chen, Jinhui Xu",30c7d7bd208314ea1e925835eabddd98aca29f01,Shifted Diffusion for Text-to-image Generation,ArXiv,2022,1,"We present Corgi, a novel method for text-to-image generation. Corgi is based on our proposed shifted diffusion model, which achieves better image embedding generation from input text. Unlike the baseline diffusion model used in DALL-E 2, our method seamlessly encodes prior knowledge of the pre-trained CLIP model in its diffusion process by designing a new initialization distribution and a new transition step of the diffusion. Compared to the strong DALL-E 2 baseline, our method performs better in generating image embedding from the text in terms of both efficiency and effectiveness, resulting in better text-to-image generation. Extensive large-scale experiments are conducted and evaluated in terms of both quantitative measures and human evaluation, indicating a stronger generation ability of our method compared to existing ones. Furthermore, our model enables semi-supervised and language-free training for text-to-image generation, where only part or none of the images in the training dataset have an associated caption. Trained with only 1.7% of the images being captioned, our semi-supervised model obtains FID results comparable to DALL-E 2 on zero-shot text-to-image generation evaluated on MS-COCO. Corgi also achieves new state-of-the-art results across different datasets on downstream language-free text-to-image generation tasks, outperforming the previous method, Lafite, by a large margin."
"A. Bhunia, Salman Khan, Hisham Cholakkal, R. Anwer, J. Laaksonen, M. Shah, F. Khan",7ec5b25fbbbf7a83a2a04b3f6ae951d7e488badd,Person Image Synthesis via Denoising Diffusion Model,ArXiv,2022,1,"The pose-guided person image generation task requires synthesizing photorealistic images of humans in arbitrary poses. The existing approaches use generative adversarial networks that do not necessarily maintain realistic textures or need dense correspondences that struggle to handle complex deformations and severe occlusions. In this work, we show how denoising diffusion models can be applied for high-fidelity person image synthesis with strong sample diversity and enhanced mode coverage of the learnt data distribution. Our proposed Person Image Diffusion Model (PIDM) disintegrates the complex transfer problem into a series of simpler forward-backward denoising steps. This helps in learning plausible source-to-target transformation trajectories that result in faithful textures and undistorted appearance details. We introduce a 'texture diffusion module' based on cross-attention to accurately model the correspondences between appearance and pose information available in source and target images. Further, we propose 'disentangled classifier-free guidance' to ensure close resemblance between the conditional inputs and the synthesized output in terms of both pose and appearance information. Our extensive results on two large-scale benchmarks and a user study demonstrate the photorealism of our proposed approach under challenging scenarios. We also show how our generated images can help in downstream tasks. Our code and models will be publicly released."
"Cristian Sbrolli, Paolo Cudrano, Matteo Frosi, Matteo Matteucci",48a2468f168fb31bf6fdb63a762111248d23255b,IC3D: Image-Conditioned 3D Diffusion for Shape Generation,ArXiv,2022,1,"In the last years, Denoising Diffusion Probabilistic Models (DDPMs) obtained state-of-the-art results in many generative tasks, outperforming GANs and other classes of generative models. In particular, they reached impressive results in various image generation sub-tasks, among which conditional generation tasks such as text-guided image synthesis. Given the success of DDPMs in 2D generation, they have more recently been applied to 3D shape generation, outperforming previous approaches and reaching state-of-the-art results. However, these existing 3D DDPM works make little or no use of guidance, mainly being unconditional or class-conditional. In this work, we present IC3D, an Image-Conditioned 3D Diffusion model that generates 3D shapes by image guidance. To guide our DDPM, we introduce CISP (Contrastive Image-Shape Pre-training), a model jointly embedding images and shapes by contrastive pre-training, inspired by the literature on text-to-image DDPMs. Our generative diffusion model outperforms the state-of-the-art in 3D generation quality and diversity. Furthermore, despite IC3D generative nature, we show that its generated shapes are preferred by human evaluators to a SoTA single-view 3D reconstruction model in terms of quality and coherence to the query image by running a side-by-side human evaluation. Ablation studies show the importance of CISP for learning structural integrity properties, crucial for realistic generation. Such biases yield a regular embedding space and allow for interpolation and conditioning on out-of-distribution images, while also making IC3D capable of generating coherent but diverse completions of occluded views and enabling its adoption in controlled real-life applications."
"Chi Tai, N. Hodžić, Nicole Flanagan, Hayden Gunraj, A. Wong",1667af163d2ff22eb004b71df080782f0d6f81e3,Cancer-Net BCa: Breast Cancer Pathologic Complete Response Prediction using Volumetric Deep Radiomic Features from Synthetic Correlated Diffusion Imaging,ArXiv,2022,1,"Breast cancer is the second most common type of cancer in women in Canada and the United States, representing over 25% of all new female cancer cases. Neoadjuvant chemotherapy treatment has recently risen in usage as it may result in a patient having a pathologic complete response (pCR), and it can shrink inoperable breast cancer tumors prior to surgery so that the tumor becomes operable, but it is difﬁcult to predict a patient’s pathologic response to neoadjuvant chemotherapy. In this paper, we investigate the efﬁcacy of leveraging learnt volumetric deep features from a newly introduced magnetic resonance imaging (MRI) modality called synthetic correlated diffusion imaging (CDI s ) for the purpose of pCR prediction. More speciﬁcally, we leverage a volumetric convolutional neural network to learn volumetric deep radiomic features from a pre-treatment cohort and construct a predictor based on the learnt features using the post-treatment response. As the ﬁrst study to explore the utility of CDI s within a deep learning perspective for clinical decision support, we evaluated the proposed approach using the ACRIN-6698 study against those learnt using gold-standard imaging modalities, and found that the proposed approach can provide enhanced pCR prediction performance and thus may be a useful tool to aid oncologists in improving recommendation of treatment of patients. Subsequently, this approach to leverage volumetric deep radiomic features (which we name Cancer-Net BCa) can be further extended to other applications of CDI"
"Yueqin Yin, Lianghua Huang, Yu Liu, Kaiqiang Huang",06351baa279a9aa448b612354031c8fdf7a0e21d,DiffGAR: Model-Agnostic Restoration from Generative Artifacts Using Image-to-Image Diffusion Models,Proceedings of the 2022 6th International Conference on Computer Science and Artificial Intelligence,2022,1,"Recent generative models show impressive results in photo-realistic image generation. However, artifacts often inevitably appear in the generated results, leading to downgraded user experience and reduced performance in downstream tasks. This work aims to develop a plugin post-processing module for diverse generative models, which can faithfully restore images from diverse generative artifacts. This is challenging because: (1) Unlike traditional degradation patterns, generative artifacts are non-linear and the transformation function is highly complex. (2) There are no readily available artifact-image pairs. (3) Different from model-specific anti-artifact methods, a model-agnostic framework views the generator as a black-box machine and has no access to the architecture details. In this work, we first design a group of mechanisms to simulate generative artifacts of popular generators (i.e., GANs, autoregressive models, and diffusion models), given real images. Second, we implement the model-agnostic anti-artifact framework as an image-to-image diffusion model, due to its advantage in generation quality and capacity. Finally, we design a conditioning scheme for the diffusion model to enable both blind and non-blind image restoration. A guidance parameter is also introduced to allow for a trade-off between restoration accuracy and image quality. Extensive experiments show that our method significantly outperforms previous approaches on the proposed datasets and real-world artifact images."
"Hamza Kebiri, G. Girard, Y. Alemán‐Gómez, Thomas Yu, A. Jakab, Erick Jorge Canales-Rodríguez, M. Cuadra",1dd3069bb46aaba12f3ee8f5222ea7efd48089f2,Slice Estimation in Diffusion MRI of Neonatal and Fetal Brains in Image and Spherical Harmonics Domains Using Autoencoders,CDMRI@MICCAI,2022,1,
"E. Miller, G. Prigozhin, B. LaMarr, M. Bautz, R. Foster, C. Grant, C. Lage, C. Leitz, A. Malonis",8d474b42bb2302289d2c1276df6d8d430f55e1d9,Understanding the effects of charge diffusion in next-generation soft x-ray imagers,Astronomical Telescopes + Instrumentation,2022,1,"To take advantage of high-resolution optics sensitive to a broad energy range, future x-ray imaging instruments will require thick detectors with small pixels. This pixel aspect ratio affects spectral response in the soft x-ray band, vital for many science goals, as charge produced by the photon interaction near the entrance window diffuses across multiple pixels by the time it is collected, and is potentially lost below the imposed noise threshold. In an effort to understand these subtle but significant effects and inform the design and requirements of future detectors, we present simulations of charge diffusion using a variety of detector characteristics and operational settings, assessing spectral response at a range of x-ray energies. We validate the simulations by comparing the performance to that of real CCD detectors tested in the lab and deployed in space, spanning a range of thickness, pixel size, and other characteristics. The simulations show that while larger pixels, higher bias voltage, and optimal backside passivation improve performance, reducing the readout noise has a dominant effect in all cases. We finally show how high-pixel-aspect-ratio devices present challenges for measuring the backside passivation performance due to the magnitude of other processes that degrade spectral response, and present a method for utilizing the simulations to qualitatively assess this performance. Since compelling science requirements often compete technically with each other (high spatial resolution, soft x-ray response, hard x-ray response), these results can be used to find the proper balance for a future high-spatial-resolution x-ray instrument."
"F. Gadjimuradov, T. Benkert, M. Nickel, Tobit Fuhres, M. Saake, A. Maier",78b84c760996ca209a1b14912fa43e84e4186879,Deep learning-guided weighted averaging for signal dropout compensation in diffusion-weighted imaging of the liver,,2022,1,"Purpose: To develop an algorithm for the retrospective correction of signal dropout artifacts in abdominal diffusion-weighted imaging (DWI) resulting from cardiac motion. Methods: Given a set of image repetitions for a slice, a locally adaptive weighted averaging is proposed which aims to suppress the contribution of image regions affected by signal dropouts. Corresponding weight maps were estimated by a sliding-window algorithm which analyzed signal deviations from a patch-wise reference. In order to ensure the computation of a robust reference, repetitions were filtered by a classifier that was trained to detect images corrupted by signal dropouts. The proposed method, named Deep Learning-guided Adaptive Weighted Averaging (DLAWA), was evaluated in terms of dropout suppression capability, bias reduction in the Apparent Diffusion Coefficient (ADC) and noise characteristics. Results: In the case of uniform averaging, motion-related dropouts caused signal attenuation and ADC overestimation in parts of the liver with the left lobe being affected particularly. Both effects could be substantially mitigated by DLAWA while preventing global penalties with respect to signal-to-noise ratio (SNR) due to local signal suppression. Performing evaluations on patient data, the capability to recover lesions concealed by signal dropouts was demonstrated as well. Further, DLAWA allowed for transparent control of the trade-off between SNR and signal dropout suppression by means of a few hyperparameters. Conclusion: This work presents an effective and flexible method for the local compensation of signal dropouts resulting from motion and pulsation. Since DLAWA follows a retrospective approach, no changes to the acquisition are required."
"Ryota Ikeda, T. Morishita, Takafumi Tsukui, B. Vulcani, M. Trenti, B. Metha, A. Acebrón, P. Bergamini, C. Grillo, D. Iono, A. Mercurio, P. Rosati, E. Vanzella",264e476f1f4e619accacd0d8c834a0f32b76cab5,Near-infrared characterization of ultra-diffuse galaxies in Abell 2744 by JWST/NIRISS imaging,,2022,0,"We present a search and characterization of ultra-diﬀuse galaxies (UDGs) in the Frontier Fields cluster Abell 2744 at 𝑧 = 0 . 308. We use JWST/NIRISS F200W observations, acquired as part of the GLASS-JWST Early Release Science Program, aiming to characterize morphologies of cluster UDGs and their diﬀuse stellar components. A total number of 22 UDGs are identiﬁed by our selection criteria using morphological parameters, down to stellar mass of ∼ 10 7 𝑀 (cid:12) . The selected UDGs are systematically larger in eﬀective radius in F200W than in HST/ACS F814W images, which implies that some of them would not have been identiﬁed as UDGs when selected at rest-frame optical wavelengths. In fact, we ﬁnd that about one third of the UDGs were not previously identiﬁed based on the F814W data. We observe a ﬂat distribution of the UDGs in the stellar mass-size plane, similar to what is found for cluster quiescent galaxies at comparable mass. We also ﬁnd 10 potential candidates with disturbed morphologies, a previously overlooked but important population as a possible progenitor of the local UDGs. Our pilot study using the new JWST F200W ﬁlter showcases the eﬃciency of searching UDGs at cosmological distances, with 1/30 of the exposure time of the previous deep observing campaign with HST. Further studies with JWST focusing on spatially-resolved properties of individual sources will provide insight into their origin."
"Bin Huang, Liu Zhang, Shiyu Lu, Bo Lin, Weiwen Wu, Qiegen Liu",bad812bf0e1c069275a5fd9aa7e567db4df6c87f,One Sample Diffusion Model in Projection Domain for Low-Dose CT Imaging,ArXiv,2022,0,"— Low-dose computed tomography (CT) plays a significant role in reducing the radiation risk in clinical applications. However, lowering the radiation dose will significantly degrade the image quality. With the rapid development and wide application of deep learning, it has brought new directions for the development of low-dose CT imaging algorithms. Therefore, we propose a fully unsupervised one sample diffusion model (OSDM) in projection domain for low-dose CT reconstruction. To extract sufficient prior information from single sample, the Hankel matrix formulation is employed. Besides, the penalized weighted least-squares and total variation are introduced to achieve superior image quality. Specifically, we first train a score-based generative model on one sinogram by extracting a great number of tensors from the structural-Hankel matrix as the network input to capture prior distribution. Then, at the inference stage, the stochastic differential equation solver and data-consistency step are performed iteratively to obtain the sinogram data. Finally, the final image is obtained through the filtered back-projection algorithm. The reconstructed results are approaching to the normal-dose counterparts. The results prove that OSDM is practical and effective model for reducing the artifacts and preserving the image quality."
"Naoki Matsunaga, Masato Ishii, Akio Hayakawa, Kenji Suzuki, T. Narihira",7e673c7630fe9368f281a9fe02e55491f23b4437,Fine-grained Image Editing by Pixel-wise Guidance Using Diffusion Models,ArXiv,2022,0,"Generative models, particularly GANs, have been utilized for image editing. Although GAN-based methods perform well on generating reasonable contents aligned with the user's intentions, they struggle to strictly preserve the contents outside the editing region. To address this issue, we use diffusion models instead of GANs and propose a novel image-editing method, based on pixel-wise guidance. Specifically, we first train pixel-classifiers with few annotated data and then estimate the semantic segmentation map of a target image. Users then manipulate the map to instruct how the image is to be edited. The diffusion model generates an edited image via guidance by pixel-wise classifiers, such that the resultant image aligns with the manipulated map. As the guidance is conducted pixel-wise, the proposed method can create reasonable contents in the editing region while preserving the contents outside this region. The experimental results validate the advantages of the proposed method both quantitatively and qualitatively."
"Mengwei Ren, M. Delbracio, Hossein Talebi, G. Gerig, P. Milanfar",b40549f98b651985277d2067389e9b54f8dba132,Multiscale Structure Guided Diffusion for Image Deblurring,,2022,0,"Diffusion Probabilistic Models (DPMs) have recently been employed for image deblurring, formulated as an image-conditioned generation process that maps Gaussian noise to the high-quality image, conditioned on the blurry input. Image-conditioned DPMs (icDPMs) have shown more realistic results than regression-based methods when trained on pairwise in-domain data. However, their robustness in restoring images is unclear when presented with out-of-domain images as they do not impose specific degradation models or intermediate constraints. To this end, we introduce a simple yet effective multiscale structure guidance as an implicit bias that informs the icDPM about the coarse structure of the sharp image at the intermediate layers. This guided formulation leads to a significant improvement of the deblurring results, particularly on unseen domain. The guidance is extracted from the latent space of a regression network trained to predict the clean-sharp target at multiple lower resolutions, thus maintaining the most salient sharp structures. With both the blurry input and multiscale guidance, the icDPM model can better understand the blur and recover the clean image. We evaluate a single-dataset trained model on diverse datasets and demonstrate more robust deblurring results with fewer artifacts on unseen data. Our method outperforms existing baselines, achieving state-of-the-art perceptual quality while keeping competitive distortion metrics."
"Kyoungwan Woo, Achyuta Rajaram",8eca86243e161ff694bc58f26b13e080144f4262,FREDSR: Fourier Residual Efficient Diffusive GAN for Single Image Super Resolution,ArXiv,2022,0,"FREDSR is a GAN variant that aims to outperform traditional GAN models in specific tasks such as Single Image Super Resolution with extreme parameter efficiency at the cost of per-dataset generalizeability. FREDSR integrates fast Fourier transformation, residual prediction, diffusive discriminators, etc to achieve strong performance in comparisons to other models on the UHDSR4K dataset for Single Image 3x Super Resolution from 360p and 720p with only 37000 parameters. The model follows the characteristics of the given dataset, resulting in lower generalizeability but higher performance on tasks such as real time up-scaling."
"Gabriel Varela-Mattatall, Paul I. Dubovan, T. Santini, K. Gilbert, Ravi S. Menon, C. Baron",8129e11d5741f2b89fe6764e3581b017690333e9,High-resolution single-shot spiral diffusion-weighted imaging at 7T using expanded encoding with compressed sensing,,2022,0,"Purpose: The expanded encoding model incorporates spatially- and time-varying field perturbations for correction during reconstruction. So far, these reconstructions have used the conjugate gradient method with early stopping used as implicit regularization. However, this approach is likely suboptimal for low-SNR cases like diffusion or high-resolution MRI. Here, we investigate the extent that l1-wavelet regularization, or equivalently compressed sensing (CS), combined with expanded encoding improves trade-offs between spatial resolution, readout time and SNR for single-shot spiral diffusion-weighted imaging at 7T. The reconstructions were performed using our open-source GPU- enabled reconstruction toolbox, “MatMRI”, that allows inclusion of the different components of the expanded encoding model, with or without CS. Methods: In vivo accelerated single-shot spirals were acquired with five acceleration factors (2 6) and three in-plane spatial resolutions (1.5, 1.3, and 1.1 mm). From the in vivo reconstructions, we estimated diffusion tensors and computed fractional anisotropy maps. Then, simulations were used to quantitatively investigate and validate the impact of CS-based regularization on image quality when compared to a known ground truth. Results: In vivo reconstructions revealed improved image quality with retainment of small features when CS was used. Simulations showed that the joint use of the expanded encoding model and CS improves accuracy of image reconstructions (reduced mean-squared error) over the range of acceleration factors investigated. Conclusion: The expanded encoding model and CS regularization are complementary tools for single-shot spiral diffusion MRI, which enables both higher spatial resolutions and higher acceleration factors."
"Kai Zhang, Muyi Sun, Jianxin Sun, Binghao Zhao, Kunbo Zhang, Zhenan Sun, T. Tan",538bf28f2b1e6ed1a8dfb2b20ab02394abb4b121,HumanDiffusion: a Coarse-to-Fine Alignment Diffusion Framework for Controllable Text-Driven Person Image Generation,ArXiv,2022,0,"Text-driven person image generation is an emerging and challenging task in cross-modality image generation. Controllable person image generation promotes a wide range of applications such as digital human interaction and virtual try-on. However, previous methods mostly employ single-modality information as the prior condition (e.g. pose-guided person image generation), or utilize the preset words for text-driven human synthesis. Introducing a sentence composed of free words with an editable semantic pose map to describe person appearance is a more user-friendly way. In this paper, we propose HumanDiffusion, a coarse-to-fine alignment diffusion framework, for text-driven person image generation. Specifically, two collaborative modules are proposed, the Stylized Memory Retrieval (SMR) module for fine-grained feature distillation in data processing and the Multi-scale Cross-modality Alignment (MCA) module for coarse-to-fine feature alignment in diffusion. These two modules guarantee the alignment quality of the text and image, from image-level to feature-level, from low-resolution to high-resolution. As a result, HumanDiffusion realizes open-vocabulary person image generation with desired semantic poses. Extensive experiments conducted on DeepFashion demonstrate the superiority of our method compared with previous approaches. Moreover, better results could be obtained for complicated person images with various details and uncommon poses."
"M. Beltran, D. Paganin, M. Croughan, K. Morgan",bc262482b057e74e3f9a4d8abe06a73c18fc0cd0,"Fast implicit diffusive dark-field retrieval for single-exposure, single-mask x-ray imaging",,2022,0,"Complementary to conventional and phase X-ray radiography, dark-field imaging has become central in visualizing diffusive scattering signal due to the spatially-unresolved texture within an object. To date most diffusive-dark-field retrieval methods require either the acquisition of multiple images at the cost of higher radiation dose or significant amounts of computational memory and time. In this work, a simple method of X-ray diffusive dark-field retrieval is presented, applicable to any single-mask imaging setup, with only one exposure of the sample. The approach, which is based on a model of geometric and diffusive reverse-flow conservation, is implicit and non-iterative. This numerically fast methodology is applied to experimental X-ray images acquired using both a random mask and a grid mask, giving high quality reconstructions that are very stable in the presence of noise. The method should be useful for high-speed imaging and/or imaging with low-flux sources."
A. Stockl,13721a3adc8f0f365eeb8d540becbdb9c05cbf1c,Evaluating a Synthetic Image Dataset Generated with Stable Diffusion,,2022,0,"We generate synthetic images with the""Stable Diffusion""image generation model using the Wordnet taxonomy and the definitions of concepts it contains. This synthetic image database can be used as training data for data augmentation in machine learning applications, and it is used to investigate the capabilities of the Stable Diffusion model. Analyses show that Stable Diffusion can produce correct images for a large number of concepts, but also a large variety of different representations. The results show differences depending on the test concepts considered and problems with very specific concepts. These evaluations were performed using a vision transformer model for image classification."
"Zihao Tang, Xinyi Wang, Lihaowen Zhu, M. Cabezas, Dongnan Liu, Michael H Barnett, Weidong (Tom) Cai, Chengyu Wang",1a2371e673e00d18c7637a7b360b760d05dcc806,TW-BAG: Tensor-wise Brain-aware Gate Network for Inpainting Disrupted Diffusion Tensor Imaging,International Conference on Digital Image Computing: Techniques and Applications,2022,0,"Diffusion Weighted Imaging (DWI) is an advanced imaging technique commonly used in neuroscience and neurological clinical research through a Diffusion Tensor Imaging (DTI) model. Volumetric scalar metrics including fractional anisotropy, mean diffusivity, and axial diffusivity can be derived from the DTI model to summarise water diffusivity and other quantitative microstructural information for clinical studies. However, clinical practice constraints can lead to sub-optimal DWI acquisitions with missing slices (either due to a limited field of view or the acquisition of disrupted slices). To avoid discarding valuable subjects for group-wise studies, we propose a novel 3D Tensor-Wise Brain-Aware Gate network (TW-BAG) for inpainting disrupted DTIs. The proposed method is tailored to the problem with a dynamic gate mechanism and independent tensor-wise decoders. We evaluated the proposed method on the publicly available Human Connectome Project (HCP) dataset using common image similarity metrics derived from the predicted tensors and scalar DTI metrics. Our experimental results show that the proposed approach can reconstruct the original brain DTI volume and recover relevant clinical imaging information."
"Yuntian Deng, Noriyuki Kojima, Alexander M. Rush",b69391b7b4cbef5a9a749744d7f676942c214706,Markup-to-Image Diffusion Models with Scheduled Sampling,ArXiv,2022,0,"Building on recent advances in image generation, we present a fully data-driven approach to rendering markup into images. The approach is based on diffusion models, which parameterize the distribution of data using a sequence of denoising operations on top of a Gaussian noise distribution. We view the diffusion denoising process as a sequential decision making process, and show that it exhibits compounding errors similar to exposure bias issues in imitation learning problems. To mitigate these issues, we adapt the scheduled sampling algorithm to diffusion training. We conduct experiments on four markup datasets: mathematical formulas (LaTeX), table layouts (HTML), sheet music (LilyPond), and molecular images (SMILES). These experiments each verify the effectiveness of the diffusion process and the use of scheduled sampling to fix generation issues. These results also show that the markup-to-image task presents a useful controlled compositional setting for diagnosing and analyzing generative image models."
"K. Schilling, Francesco Grussu, A. Ianuş, B. Hansen, M. Aggarwal, S. Michielse, F. Nasrallah, Warda T. Syeda, Nian Wang, J. Veraart, A. Roebroeck, Andrew F Bagdaserian, C. Eichner, F. Sepehrband, Jan Zimmermann, B. Jeurissen, L. Frydman, Y. Looij, David Hike, J. Dunn, K. Miller, B. Landman, N. Shemesh, A. Anderson, Emilie T. McKinnon, S. Farquharson, F. D. Acqua, C. Pierpaoli, I. Drobnjak, A. Leemans, K. D. Harkins, M. Descoteaux, Duan Xu, M. Santin, S. Grant, A. Obenaus, Gene S Kim, Dan Wu, D. Bihan, S. Blackband, L. Ciobanu, E. Fieremans, Ruiliang Bai, T. Leergaard, Jiangyang Zhang, T. Dyrby, G. A. Johnson, J. Cohen-Adad, M. Budde, I. Jelescu",c57a8c945f5d3eed1cf7469614066768aee49171,Recommendations and guidelines from the ISMRM Diffusion Study Group for preclinical diffusion MRI: Part 2 -- Ex vivo imaging,,2022,0,"The value of preclinical diffusion MRI (dMRI) is substantial. While dMRI enables in vivo non-invasive characterization of tissue, ex vivo dMRI is increasingly being used to probe tissue microstructure and brain connectivity. Ex vivo dMRI has several experimental advantages including higher signal-to-noise ratio and spatial resolution compared to in vivo studies, and more advanced diffusion contrasts for improved microstructure and connectivity characterization. Another major advantage is direct comparison with histological data as a crucial methodological validation. However, there are a number of considerations that must be made when performing ex vivo experiments. The steps from tissue preparation, image acquisition and processing, and interpretation of results are complex, with many decisions that not only differ dramatically from in vivo imaging, but ultimately affect what questions can be answered using the data. This work represents 'Part 2' of a series of recommendations and considerations for preclinical dMRI, where we focus on best practices for dMRI of ex vivo tissue. We first describe the value that ex vivo imaging adds to the field of dMRI, followed by general considerations and foundational knowledge that must be considered when designing experiments. We then give guidelines for ex vivo protocols, including tissue preparation, imaging sequences and data processing including pre-processing, model-fitting, and tractography. Finally, we provide an online resource which lists publicly available ex vivo dMRI datasets and dedicated software packages. In each section, we attempt to provide guidelines and recommendations, but also highlight areas for which no guidelines exist, and where future work should lie. An overarching goal herein is to enhance the rigor and reproducibility of ex vivo dMRI acquisitions and analyses, and thereby advance biomedical knowledge."
Robin Zbinden,1ca78b7067e27421452c894b6c72586122f30797,Implementing and Experimenting with Diffusion Models for Text-to-Image Generation,ArXiv,2022,0,"Taking advantage of the many recent advances in deep learning, text-to-image generative models currently have the merit of attracting the general public attention. Two of these models, DALL-E 2 and Imagen, have demonstrated that highly photorealistic images could be generated from a simple textual description of an image. Based on a novel approach for image generation called diffusion models, text-to-image models enable the production of many different types of high resolution images, where human imagination is the only limit. However, these models require exceptionally large amounts of computational resources to train, as well as handling huge datasets collected from the internet. In addition, neither the codebase nor the models have been released. It consequently prevents the AI community from experimenting with these cutting-edge models, making the reproduction of their results complicated, if not impossible. In this thesis, we aim to contribute by firstly reviewing the different approaches and techniques used by these models, and then by proposing our own implementation of a text-to-image model. Highly based on DALL-E 2, we introduce several slight modifications to tackle the high computational cost induced. We thus have the opportunity to experiment in order to understand what these models are capable of, especially in a low resource regime. In particular, we provide additional and analyses deeper than the ones performed by the authors of DALL-E 2, including ablation studies. Besides, diffusion models use so-called guidance methods to help the generating process. We introduce a new guidance method which can be used in conjunction with other guidance methods to improve image quality. Finally, the images generated by our model are of reasonably good quality, without having to sustain the significant training costs of state-of-the-art text-toimage models."
"Mojtaba Lashgari, N. Ravikumar, I. Teh, Jing-Rebecca Li, D. Buckley, J. Schneider, Alejandro F. Frangi",8c5fc51dceabede446513af58bdeb70d45012203,Three-dimensional micro-structurally informed in silico myocardium - towards virtual imaging trials in cardiac diffusion weighted MRI,Medical Image Anal.,2022,0,"In silico tissue models (viz. numerical phantoms) provide a mechanism for evaluating quantitative models of magnetic resonance imaging. This includes the validation and sensitivity analysis of imaging biomarkers and tissue microstructure parameters. This study proposes a novel method to generate a realistic numerical phantom of myocardial microstructure. The proposed method extends previous studies by accounting for the variability of the cardiomyocyte shape, water exchange between the cardiomyocytes (intercalated discs), disorder class of myocardial microstructure, and four sheetlet orientations. In the first stage of the method, cardiomyocytes and sheetlets are generated by considering the shape variability and intercalated discs in cardiomyocyte-cardiomyocyte connections. Sheetlets are then aggregated and oriented in the directions of interest. The morphometric study demonstrates no significant difference (p>0.01) between the distribution of volume, length, and primary and secondary axes of the numerical and real (literature) cardiomyocyte data. Moreover, structural correlation analysis validates that the in-silico tissue is in the same class of disorderliness as the real tissue. Additionally, the absolute angle differences between the simulated helical angle (HA) and input HA (reference value) of the cardiomyocytes (4.3°±3.1°) demonstrate a good agreement with the absolute angle difference between the measured HA using experimental cardiac diffusion tensor imaging (cDTI) and histology (reference value) reported by (Holmes et al., 2000) (3.7°±6.4°) and (Scollan et al. 1998) (4.9°±14.6°). Furthermore, the angular distance between eigenvectors and sheetlet angles of the input and simulated cDTI is much smaller than those between measured angles using structural tensor imaging (as a gold standard) and experimental cDTI. Combined with the qualitative results, these results confirm that the proposed method can generate richer numerical phantoms for the myocardium than previous studies."
"Yilin Luo, Bijie Bai, Yuhang Li, Ege Cetintas, Aydogan Ozcan",44b0e870cc19b77b3af6950a66c37fd57acc0558,All-optical image classification through unknown random diffusers using a single-pixel diffractive network,Light: Science & Applications,2022,0,
"Stephan Gärttner, F. Frank, Fabian Woller, Andreas Meier, N. Ray",0774e0f7fbd627e012257ece7535add02d4eb60b,Estimating relative diffusion from 3D micro-CT images using CNNs,ArXiv,2022,0,"In the past several years, convolutional neural networks (CNNs) have proven their capability to predict characteristic quantities in porous media research directly from pore-space geometries. Due to the frequently observed signiﬁcant reduction in computation time in comparison to classical computational methods, bulk parameter prediction via CNNs is especially compelling, e. g. for eﬀective diﬀusion. While the current literature is mainly focused on fully saturated porous media, the partially saturated case is also of high interest. Due to the qualitatively diﬀerent and more complex geometries of the domain available for dif-fusive transport present in this case, standard CNNs tend to lose robustness and accuracy with lower saturation rates. In this paper, we demonstrate the ability of CNNs to perform predictions of relative diﬀusion directly from full pore-space geometries. As such, our CNN conveniently fuses diﬀusion prediction and a well-established morphological model which describes phase distributions in partially saturated porous media. a certain saturation level on the resulting geometry To do so, a was trained to the relative diﬀusion related to a speciﬁc saturation level directly from the complete pore Our results demonstrate that CNNs are capable of performing this task as equally accurate and robust as standard diﬀusion prediction on fully saturated pore spaces. As such, workﬂows for the simulation of transport processes within partially saturated porous media can be simpliﬁed by encompassing multiple complex such as algorithms and into a single monolithic data-driven approach. The resulting speed-up setups that involve changes in phase distribution and geometry evolution, over time."
"Zhou Lan, Arkaprava Roy",07d5f3c0ed17e9e8209471185c4e4d202962eeb0,Spatial Autoregressive von-Mises Fisher Regression for Diffusion Tensor Imaging,,2022,0,"The principal diﬀusion directions, representing the tissue ﬁber orientations, are one of the most important markers derived from diﬀusion tensor imaging (DTI). They are frequently analyzed in several medical studies. However, only a few approaches are available for covariate-dependent statistical analysis for the principal diﬀusion direction data. To address this gap, we propose a novel generalized linear model to analyze such that using a von Mises Fisher (vMF) distributed error structure. Using a novel link function that relies on the transformation between Cartesian and spherical coordinates, we regress the vMF distributed principal diﬀusion directions on the subject’s covariates. This regression model allows us to measure the importance of the clinical factors on ﬁber orientations. Furthermore, we impose the spatial dependence to be supported along a given ﬁber using an autoregressive model. This novel speciﬁcation renders computational eﬃciency and ﬂexibility. For Bayesian inference of the directional data, a comprehensive toolbox is thoroughly developed with applications to neuroimaging analysis. We ﬁrst show the method’s empirical eﬃcacy through simulation experiments. Subsequently, applying our regression model to the Alzheimer’s Disease Neuroimaging Initiative (ADNI) data, we acquire new insights related to the progression of cognitive impairment."
"N. Shusharina, Xiaofeng Liu, Jaume Coll-Font, Anna N. Foster, G. El Fakhri, Jonghye Woo, T. Bortfeld, C. Nguyen",6190b1c4072cc5975fc25f2178470fdd7b9e3bf1,Feasibility study of clinical target volume definition for soft-tissue sarcoma using muscle fiber orientations derived from diffusion tensor imaging,Physics in Medicine and Biology,2022,0,"Objective. Soft-tissue sarcoma spreads preferentially along muscle fibers. We explore the utility of deriving muscle fiber orientations from diffusion tensor MRI (DT-MRI) for defining the boundary of the clinical target volume (CTV) in muscle tissue. Approach. We recruited eight healthy volunteers to acquire MR images of the left and right thigh. The imaging session consisted of (a) two MRI spin-echo-based scans, T1- and T2-weighted; (b) a diffusion weighted (DW) spin-echo-based scan using an echo planar acquisition with fat suppression. The thigh muscles were auto-segmented using the convolutional neural network. DT-MRI data were used as a geometry encoding input to solve the anisotropic Eikonal equation with the Hamiltonian Fast-Marching method. The isosurfaces of the solution modeled the CTV boundary. Main results. The auto-segmented muscles of the thigh agreed with manually delineated with the Dice score ranging from 0.8 to 0.94 for different muscles. To validate our method of deriving muscle fiber orientations, we compared anisotropy of the isosurfaces across muscles with different anatomical orientations within a thigh, between muscles in the left and right thighs of each subject, and between different subjects. The fiber orientations were identified reproducibly across all comparisons. We identified two controlling parameters, the distance from the gross tumor volume to the isosurface and the eigenvalues ratio, to tailor the proposed CTV to the satisfaction of the clinician. Significance. Our feasibility study with healthy volunteers shows the promise of using muscle fiber orientations derived from DW MRI data for automated generation of anisotropic CTV boundary in soft tissue sarcoma. Our contribution is significant as it serves as a proof of principle for combining DT-MRI information with tumor spread modeling, in contrast to using moderately informative 2D CT planes for the CTV delineation. Such improvements will positively impact the cancer centers with a small volume of sarcoma patients."
"Jakub Jurek, A. Materka, Kamil Ludwisiak, A. Majos, K. Gorczewski, K. Cepuch, A. Zawadzka",3834b7427c7d43574320c77914589d31a4274760,Supervised Denoising of Diffusion-Weighted Magnetic Resonance Images Using a Convolutional Neural Network and Transfer Learning,Biocybernetics and Biomedical Engineering,2022,0,"In this paper, we propose a method for denoising diffusion-weighted images (DWI) of the brain using a convolutional neural network trained on realistic, synthetic MR data. We compare our results to averaging of repeated scans, a widespread method used in clinics to improve signal-to-noise ratio of MR images. To obtain training data for transfer learning, we model, in a data-driven fashion, the effects of echo-planar imaging (EPI): Nyquist ghosting and ramp sampling. We introduce these effects to the digital phantom of brain anatomy (BrainWeb). Instead of simulating pseudo-random noise with a defined probability distribution, we perform noise scans with a brain-DWI-designed protocol to obtain realistic noise maps. We combine them with the simulated, noise-free EPI images. We also measure the Point Spread Function in a DW image of an AJR-approved geometrical phantom and inter-scan movement in a brain scan of a healthy volunteer. Their influence on image denoising and averaging of repeated images is investigated at different signal-to-noise ratio levels. Denoising performance is evaluated quantitatively using the simulated EPI images and qualitatively in real EPI DWI of the brain. We show that the application of our method allows for a significant reduction in scan time by lowering the number of repeated scans. Visual comparisons made in the acquired brain images indicate that the denoised single-repetition images are less noisy than multi-repetition averaged images. We also analyse the convolutional neural network denoiser and point out the challenges accompanying this denoising method."
"Bo Li, Kaitao Xue, Bin Liu, Yunyu Lai",5126f69957f4b69ddaa85c0f555916ca1b8f26b1,BBDM: Image-to-image Translation with Brownian Bridge Diffusion Models,,2022,0,"Image-to-image translation is an important and challenging problem in computer vision and image processing. Diffusion models (DM) have shown great potentials for high-quality image synthesis, and have gained competitive performance on the task of image-to-image translation. However, most of the existing diffusion models treat image-to-image translation as conditional generation processes, and suffer heavily from the gap between distinct domains. In this paper, a novel image-to-image translation method based on the Brownian Bridge Diffusion Model (BBDM) is proposed, which models image-to-image translation as a stochastic Brownian bridge process, and learns the translation between two domains directly through the bidirectional diffusion process rather than a conditional generation process. To the best of our knowledge, it is the first work that proposes Brownian Bridge diffusion process for image-to-image translation. Experimental results on various benchmarks demonstrate that the proposed BBDM model achieves competitive performance through both visual inspection and measurable metrics."
"L. Fatone, D. Funaro",a65baf859c79b97c203d7fb19d7368fe6a7944d7,High-order discretization of backward anisotropic diffusion and application to image processing,Annali dell?Università di Ferrara,2022,0,
"R. V. Gorkum, Jonathan L. Weine, W. Segars, C. Stoeck, S. Kozerke",3fd22a3d510582a6652e5507e7d69030aab86251,MRXCAT-CDTI: A Numerical Cardiac Diffusion Tensor Imaging Phantom,ArXiv,2022,0,"Magnetic Resonance cardiac diffusion tensor imaging (cDTI) and cardiac intravoxel incoherent motion imaging enables probing of in vivo myofiber architecture and myocardial perfusion surrogates. To study the impact of experimental parameters such as resolution, off-resonances and heart-rate variations, we propose a numerical open-source framework called MRXCAT-CDTI. It allows simulating diffusion and perfusion contrast for spin-echo (SE) and stimulated echo acquisition mode (STEAM) cDTI sequences. The Fourier encoder supports in-plane and/or through-slice off-resonance effects, as well as T2* effects during single-shot image encoding. Optional lesions are included to mimic ischemic and infarcted myocardial regions. MRXCAT-CDTI allows assessing realistic influences on data acquisition, and how these affect the data encoding process and subsequent data processing. As an example, heart-rate variations lead to differences in partial saturation and relaxation of magnetization that end up in errors of 9 to 30% for cDTI angle metrics if not accounted for. For SE echo-planar cDTI, in-plane off-resonance effects more adversely affect cDTI metrics compared to through-slice off-resonances. With this work we propose an open-source MRXCAT-CDTI numerical simulation framework that offers realistic image encoding effects found in cardiac diffusion and perfusion data to systematically study influences of data encoding, reconstruction, and post-processing to promote reproducible research."
"E. McShane, H. K. Chandrasekharan, A. Kufcs'ak, N. Finlayson, A. Erdogan, R. Henderson, Kimran Dhaliwal, R. Thomson, M. Tanner",d7cbc849fca315a9e98ddee96ab8b7b3fb753018,High resolution TCSPC imaging of diffuse light with a one-dimensional SPAD array scanning system.,Optics Express,2022,0,"We report a time-correlated single-photon counting (TCSPC) imaging system based on a line-scanning architecture. The system benefits from the high fill-factor, active area, and large dimension of an advanced CMOS single-photon avalanche diode (SPAD) array line-sensor. A two-dimensional image is constructed using a moving mirror to scan the line-sensor field-of-view (FOV) across the target, to enable the efficient acquisition of a two-dimensional 0.26 Mpixel TCSPC image. We demonstrate the capabilities of the system for TCSPC imaging and locating objects obscured in scattering media - specifically to locate a series of discrete point sources of light along an optical fibre submerged in a highly scattering solution. We demonstrate that by selectively imaging using early arriving photons which have undergone less scattering than later arriving photons, our TCSPC imaging system is able to locate the position of discrete point sources of light than a non-time-resolved imaging system."
"Chen Qian, Z. Wang, Xinlin Zhang, Boxuan Shi, B. Jiang, Ran Tao, D. Guo, X. Qu",bf08ff185b3ae3f8695439a3552899628fc829b2,A Paired Phase and Magnitude Reconstruction for Advanced Diffusion-Weighted Imaging,,2022,0,"— Objective : Multi-shot interleaved echo planer imaging can obtain diffusion-weighted images (DWI) with high spatial resolution and low distortion, but suffers from ghost artifacts introduced by phase variations between shots. In this work, we aim at solving the challenging reconstructions under inter-shot motions between shots and a low signal-to-noise ratio. Methods : An explicit phase model with paired phase and magnitude priors is proposed to regularize the reconstruction (PAIR). The former prior is derived from the smoothness of the shot phase and enforced with low-rankness in the k-space domain. The latter explores similar edges among multi-b-value and multi-direction DWI with weighted total variation in the image domain. Results : Extensive simulation and in vivo results show that PAIR can remove ghost artifacts very well under a high number of shots (8 shots) and significantly suppress the noise under the ultra-high b-value (4000 s/mm 2 ). Conclusion : The explicit phase model PAIR with complementary priors has a good performance on challenging reconstructions under inter-shot motions between shots and a low signal-to-noise ratio. Significance : PAIR has great potential in advanced clinical DWI applications and brain function research."
"Sam L. Polk, Kangning Cui, Aland H. Y. Chan, D. Coomes, R. Plemmons, James M. Murphy",9f70200a6eeb0088a5fa8ff39163fab97e72fa18,Unsupervised Diffusion and Volume Maximization-Based Clustering of Hyperspectral Images,Remote Sensing,2022,0,"Hyperspectral images taken from aircraft or satellites contain information from hundreds of spectral bands, within which lie latent lower-dimensional structures that can be exploited for classifying vegetation and other materials. A disadvantage of working with hyperspectral images is that, due to an inherent trade-off between spectral and spatial resolution, they have a relatively coarse spatial scale, meaning that single pixels may correspond to spatial regions containing multiple materials. This article introduces the Diffusion and Volume maximization-based Image Clustering (D-VIC) algorithm for unsupervised material clustering to address this problem. By directly incorporating pixel purity into its labeling procedure, D-VIC gives greater weight to pixels corresponding to a spatial region containing just a single material. D-VIC is shown to outperform comparable state-of-the-art methods in extensive experiments on a range of hyperspectral images, including land-use maps and highly mixed forest health surveys (in the context of ash dieback disease), implying that it is well-equipped for unsupervised material clustering of spectrally-mixed hyperspectral datasets."
"I. Ulrich, C. Boehm, A. Zunino, Cyrill Bosch, A. Fichtner",0f0e9b2d16669a729b45c9632d61bbcd44e3e93b,Diffuse ultrasound computed tomography for medical imaging,,2022,0,"An alternative approach to ultrasound computed tomography (USCT) for medical imaging is proposed, with the intent to (i) shorten acquisition time for devices with a large number of emitters, (ii) eliminate the calibration step, and (iii) suppress instrument noise. Inspired by seismic ambient field interferometry, the method rests on the active excitation of diffuse ultrasonic wavefields and the extraction of deterministic travel time information by inter-station correlation. To reduce stochastic errors and accelerate convergence, ensemble interferograms are obtained by phase-weighted stacking of observed and computed correlograms, generated with identical realizations of random sources. Mimicking a breast imaging setup, the accuracy of the travel time measurements as a function of the number of emitters and random realizations can be assessed both analytically and with spectralelement simulations for realistic breast phantoms. The results warrant tomographic reconstructions with straightor bent-ray approaches, where the effect of inherent stochastic fluctuations can be made significantly smaller than the effect of subjective choices on regularisation. This work constitutes a first conceptual study and a necessary prelude to future implementations. The following article has been submitted to Journal of the Acoustical society of America. After it is published, it will be found at http://asa.scitation.org/journal/jas."
"Prafulla Dhariwal, Alex Nichol",64ea8f180d0682e6c18d1eb688afdb2027c02794,Diffusion Models Beat GANs on Image Synthesis,Neural Information Processing Systems,2021,1007,"We show that diffusion models can achieve image sample quality superior to the current state-of-the-art generative models. We achieve this on unconditional image synthesis by finding a better architecture through a series of ablations. For conditional image synthesis, we further improve sample quality with classifier guidance: a simple, compute-efficient method for trading off diversity for fidelity using gradients from a classifier. We achieve an FID of 2.97 on ImageNet 128$\times$128, 4.59 on ImageNet 256$\times$256, and 7.72 on ImageNet 512$\times$512, and we match BigGAN-deep even with as few as 25 forward passes per sample, all while maintaining better coverage of the distribution. Finally, we find that classifier guidance combines well with upsampling diffusion models, further improving FID to 3.94 on ImageNet 256$\times$256 and 3.85 on ImageNet 512$\times$512. We release our code at https://github.com/openai/guided-diffusion"
"Robin Rombach, A. Blattmann, Dominik Lorenz, Patrick Esser, B. Ommer",c10075b3746a9f3dd5811970e93c8ca3ad39b39d,High-Resolution Image Synthesis with Latent Diffusion Models,Computer Vision and Pattern Recognition,2021,1002,"By decomposing the image formation process into a sequential application of denoising autoencoders, diffusion models (DMs) achieve state-of-the-art synthesis results on image data and beyond. Additionally, their formulation allows for a guiding mechanism to control the image generation process without retraining. However, since these models typically operate directly in pixel space, optimization of powerful DMs often consumes hundreds of GPU days and inference is expensive due to sequential evaluations. To enable DM training on limited computational resources while retaining their quality and flexibility, we apply them in the latent space of powerful pretrained autoencoders. In contrast to previous work, training diffusion models on such a representation allows for the first time to reach a near-optimal point between complexity reduction and detail preservation, greatly boosting visual fidelity. By introducing cross-attention layers into the model architecture, we turn diffusion models into powerful and flexible generators for general conditioning inputs such as text or bounding boxes and high-resolution synthesis becomes possible in a convolutional manner. Our latent diffusion models (LDMs) achieve new state of the art scores for image inpainting and class-conditional image synthesis and highly competitive performance on various tasks, including unconditional image generation, text-to-image synthesis, and super-resolution, while significantly reducing computational requirements compared to pixel-based DMs."
"Alex Nichol, Prafulla Dhariwal, A. Ramesh, Pranav Shyam, Pamela Mishkin, Bob McGrew, Ilya Sutskever, Mark Chen",7002ae048e4b8c9133a55428441e8066070995cb,GLIDE: Towards Photorealistic Image Generation and Editing with Text-Guided Diffusion Models,International Conference on Machine Learning,2021,559,"Diffusion models have recently been shown to generate high-quality synthetic images, especially when paired with a guidance technique to trade off diversity for fidelity. We explore diffusion models for the problem of text-conditional image synthesis and compare two different guidance strategies: CLIP guidance and classifier-free guidance. We find that the latter is preferred by human evaluators for both photorealism and caption similarity, and often produces photorealistic samples. Samples from a 3.5 billion parameter text-conditional diffusion model using classifier-free guidance are favored by human evaluators to those from DALL-E, even when the latter uses expensive CLIP reranking. Additionally, we find that our models can be fine-tuned to perform image inpainting, enabling powerful text-driven image editing. We train a smaller model on a filtered dataset and release the code and weights at https://github.com/openai/glide-text2im."
"Chitwan Saharia, William Chan, Huiwen Chang, Chris A. Lee, Jonathan Ho, Tim Salimans, David J. Fleet, Mohammad Norouzi",37c9c4e7648f639c0b36f150fc6c6c90b3682f4a,Palette: Image-to-Image Diffusion Models,International Conference on Computer Graphics and Interactive Techniques,2021,251,"This paper develops a unified framework for image-to-image translation based on conditional diffusion models and evaluates this framework on four challenging image-to-image translation tasks, namely colorization, inpainting, uncropping, and JPEG restoration. Our simple implementation of image-to-image diffusion models outperforms strong GAN and regression baselines on all tasks, without task-specific hyper-parameter tuning, architecture customization, or any auxiliary loss or sophisticated new techniques needed. We uncover the impact of an L2 vs. L1 loss in the denoising diffusion objective on sample diversity, and demonstrate the importance of self-attention in the neural architecture through empirical studies. Importantly, we advocate a unified evaluation protocol based on ImageNet, with human evaluation and sample quality scores (FID, Inception Score, Classification Accuracy of a pre-trained ResNet-50, and Perceptual Distance against original images). We expect this standardized evaluation protocol to play a role in advancing image-to-image translation research. Finally, we show that a generalist, multi-task diffusion model performs as well or better than task-specific specialist counterparts. Check out https://diffusion-palette.github.io/ for an overview of the results and code."
"Jonathan Ho, Chitwan Saharia, William Chan, David J. Fleet, Mohammad Norouzi, Tim Salimans",0f183bcfe65781c06b1a48a6f56e0f3c63e8e4a4,Cascaded Diffusion Models for High Fidelity Image Generation,Journal of machine learning research,2021,242,"We show that cascaded diffusion models are capable of generating high fidelity images on the class-conditional ImageNet generation benchmark, without any assistance from auxiliary image classifiers to boost sample quality. A cascaded diffusion model comprises a pipeline of multiple diffusion models that generate images of increasing resolution, beginning with a standard diffusion model at the lowest resolution, followed by one or more super-resolution diffusion models that successively upsample the image and add higher resolution details. We find that the sample quality of a cascading pipeline relies crucially on conditioning augmentation, our proposed method of data augmentation of the lower resolution conditioning inputs to the super-resolution models. Our experiments show that conditioning augmentation prevents compounding error during sampling in a cascaded model, helping us to train cascading pipelines achieving FID scores of 1.48 at 64x64, 3.52 at 128x128 and 4.88 at 256x256 resolutions, outperforming BigGAN-deep, and classification accuracy scores of 63.02% (top-1) and 84.06% (top-5) at 256x256, outperforming VQ-VAE-2."
"Shuyang Gu, Dong Chen, Jianmin Bao, Fang Wen, Bo Zhang, Dongdong Chen, Lu Yuan, B. Guo",194ea47df737ee5cc4240273b34a6c673a081515,Vector Quantized Diffusion Model for Text-to-Image Synthesis,Computer Vision and Pattern Recognition,2021,149,"We present the vector quantized diffusion (VQ-Diffusion) model for text-to-image generation. This method is based on a vector quantized variational autoencoder (VQ-VAE) whose latent space is modeled by a conditional variant of the recently developed Denoising Diffusion Probabilistic Model (DDPM). We find that this latent-space method is well-suited for text-to-image generation tasks because it not only eliminates the unidirectional bias with existing methods but also allows us to incorporate a mask-and-replace diffusion strategy to avoid the accumulation of errors, which is a serious problem with existing methods. Our experiments show that the VQ-Diffusion produces significantly better text-to-image generation results when compared with conventional autoregressive (AR) models with similar numbers of parameters. Compared with previous GAN-based text-to-image methods, our VQ-Diffusion can handle more complex scenes and improve the synthesized image quality by a large margin. Finally, we show that the image generation computation in our method can be made highly efficient by reparameterization. With traditional AR methods, the text-to-image generation time increases linearly with the output image resolution and hence is quite time consuming even for normal size images. The VQ-Diffusion allows us to achieve a better trade-off between quality and speed. Our experiments indicate that the VQ-Diffusion model with the reparameterization is fifteen times faster than traditional AR methods while achieving a better image quality. The code and models are available at https://github.com/cientgu/VQ-Diffusion."
"Omri Avrahami, D. Lischinski, Ohad Fried",88e8801e4daf404d3d40f1648ef29faeb8e6d58a,Blended Diffusion for Text-driven Editing of Natural Images,Computer Vision and Pattern Recognition,2021,135,"Natural language offers a highly intuitive interface for image editing. In this paper, we introduce the first solution for performing local (region-based) edits in generic natural images, based on a natural language description along with an ROI mask. We achieve our goal by leveraging and combining a pretrained language-image model (CLIP), to steer the edit towards a user-provided text prompt, with a denoising diffusion probabilistic model (DDPM) to generate natural-looking results. To seamlessly fuse the edited region with the unchanged parts of the image, we spatially blend noised versions of the input image with the local text-guided diffusion latent at a progression of noise levels. In addition, we show that adding augmentations to the diffusion process mitigates adversarial results. We compare against several baselines and related methods, both qualitatively and quantitatively, and show that our method outperforms these solutions in terms of overall realism, ability to preserve the background and matching the text. Finally, we show several text-driven editing applications, including adding a new object to an image, removing/replacing/altering existing objects, background replacement, and image extrapolation."
"Gwanghyun Kim, Taesung Kwon, Jong-Chul Ye",8f8dedb511c0324d1cb7f9750560109ca9290b5f,DiffusionCLIP: Text-Guided Diffusion Models for Robust Image Manipulation,Computer Vision and Pattern Recognition,2021,89,"Recently, GAN inversion methods combined with Contrastive Language-Image Pretraining (CLIP) enables zeroshot image manipulation guided by text prompts. However, their applications to diverse real images are still difficult due to the limited GAN inversion capability. Specifically, these approaches often have difficulties in reconstructing images with novel poses, views, and highly variable contents compared to the training data, altering object identity, or producing unwanted image artifacts. To mitigate these problems and enable faithful manipulation of real images, we propose a novel method, dubbed DiffusionCLIP, that performs textdriven image manipulation using diffusion models. Based on full inversion capability and high-quality image generation power of recent diffusion models, our method performs zeroshot image manipulation successfully even between unseen domains and takes another step towards general application by manipulating images from a widely varying ImageNet dataset. Furthermore, we propose a novel noise combination method that allows straightforward multi-attribute manipulation. Extensive experiments and human evaluation confirmed robust and superior manipulation performance of our methods compared to the existing baselines. Code is available at https://github.com/gwang-kim/DiffusionCLIP.git"
"Haoying Li, Yifan Yang, Meng Chang, H. Feng, Zhi-hai Xu, Qi Li, Yue-ting Chen",d0cefc4621a55540c77e8ade9b8ae1bfeb530f42,SRDiff: Single Image Super-Resolution with Diffusion Probabilistic Models,Neurocomputing,2021,83,
"Xihui Liu, Dong Huk Park, S. Azadi, Gong Zhang, Arman Chopikyan, Yuxiao Hu, Humphrey Shi, Anna Rohrbach, Trevor Darrell",9c5d70eb1ba888aed7e8b9f17ebd0b1d259f5b55,More Control for Free! Image Synthesis with Semantic Diffusion Guidance,IEEE Workshop/Winter Conference on Applications of Computer Vision,2021,65,"Controllable image synthesis models allow creation of diverse images based on text instructions or guidance from a reference image. Recently, denoising diffusion probabilistic models have been shown to generate more realistic imagery than prior methods, and have been successfully demonstrated in unconditional and class-conditional settings. We investigate fine-grained, continuous control of this model class, and introduce a novel unified framework for semantic diffusion guidance, which allows either language or image guidance, or both. Guidance is injected into a pretrained unconditional diffusion model using the gradient of image-text or image matching scores, without re-training the diffusion model. We explore CLIP-based language guidance as well as both content and style-based image guidance in a unified framework. Our text-guided synthesis approach can be applied to datasets without associated text annotations. We conduct experiments on FFHQ and LSUN datasets, and show results on fine-grained text-guided image synthesis, synthesis of images related to a style or content reference image, and examples with both textual and image guidance.1"
"Patrick Esser, Robin Rombach, A. Blattmann, B. Ommer",426c9d639c11514df7ba6e96d2343695561ba0eb,ImageBART: Bidirectional Context with Multinomial Diffusion for Autoregressive Image Synthesis,Neural Information Processing Systems,2021,60,"Autoregressive models and their sequential factorization of the data likelihood have recently demonstrated great potential for image representation and synthesis. Nevertheless, they incorporate image context in a linear 1D order by attending only to previously synthesized image patches above or to the left. Not only is this unidirectional, sequential bias of attention unnatural for images as it disregards large parts of a scene until synthesis is almost complete. It also processes the entire image on a single scale, thus ignoring more global contextual information up to the gist of the entire scene. As a remedy we incorporate a coarse-to-fine hierarchy of context by combining the autoregressive formulation with a multinomial diffusion process: Whereas a multistage diffusion process successively removes information to coarsen an image, we train a (short) Markov chain to invert this process. In each stage, the resulting autoregressive ImageBART model progressively incorporates context from previous stages in a coarse-to-fine manner. Experiments show greatly improved image modification capabilities over autoregressive models while also providing high-fidelity image generation, both of which are enabled through efficient training in a compressed latent space. Specifically, our approach can take unrestricted, user-provided masks into account to perform local image editing. Thus, in contrast to pure autoregressive models, it can solve free-form image inpainting and, in the case of conditional models, local, text-guided image modification without requiring mask-specific training."
"Gwanghyun Kim, Jong-Chul Ye",78a168d41b0147a00347242b97522900631ddfe4,DiffusionCLIP: Text-guided Image Manipulation Using Diffusion Models,ArXiv,2021,60,"Diffusion models are recent generative models that have shown great success in image generation with the state-of-the-art performance. However, only a few researches have been conducted for image manipulation with diffusion models. Here, we present a novel DiffusionCLIP which performs text-driven image manipulation with diffusion models using Contrastive Language–Image Pre-training (CLIP) loss. Our method has a performance comparable to that of the modern GAN-based image processing methods for in and out-of-domain image processing tasks, with the advantage of almost perfect inversion even without additional encoders or optimization. Furthermore, our method can be easily used for various novel applications, enabling image translation from an unseen domain to another unseen domain or stroke-conditioned image generation in an unseen domain, etc. Finally, we present a novel multiple attribute control with DiffusionCLIP by combining multiple ﬁne-tuned diffusion models."
"Hiroshi Sasaki, Chris G. Willcocks, T. Breckon",bc5b3be970609bf44d8fd51db199406e1aa69473,UNIT-DDPM: UNpaired Image Translation with Denoising Diffusion Probabilistic Models,ArXiv,2021,52,"We propose a novel unpaired image-to-image translation method that uses denoising diffusion probabilistic models without requiring adversarial training. Our method, UNpaired Image Translation with Denoising Diffusion Probabilistic Models (UNIT-DDPM), trains a generative model to infer the joint distribution of images over both domains as a Markov chain by minimising a denoising score matching objective conditioned on the other domain. In particular, we update both domain translation models simultaneously, and we generate target domain images by a denoising Markov Chain Monte Carlo approach that is conditioned on the input source domain images, based on Langevin dynamics. Our approach provides stable model training for image-to-image translation and generates high-quality image outputs. This enables state-of-the-art Fr\'echet Inception Distance (FID) performance on several public datasets, including both colour and multispectral imagery, significantly outperforming the contemporary adversarial image-to-image translation methods."
"Yilin Luo, Yifan Zhao, Jingxi Li, Ege Cetintas, Y. Rivenson, M. Jarrahi, Aydogan Ozcan",c2eb05d8245715cc933b8424694ba1f2f45ca91c,Computational imaging without a computer: seeing through random diffusers at the speed of light,eLight,2021,44,
"Tomer Amit, Eliya Nachmani, Tal Shaharbany, Lior Wolf",1c1cc65908dd5ca3d0103d650de896e053e0e7d7,SegDiff: Image Segmentation with Diffusion Probabilistic Models,ArXiv,2021,40,"Diffusion Probabilistic Methods are employed for state-of-the-art image generation. In this work, we present a method for extending such models for performing image segmentation. The method learns end-to-end, without relying on a pre-trained backbone. The information in the input image and in the current estimation of the segmentation map is merged by summing the output of two encoders. Additional encoding layers and a decoder are then used to iteratively refine the segmentation map, using a diffusion model. Since the diffusion model is probabilistic, it is applied multiple times, and the results are merged into a final segmentation map. The new method produces state-of-the-art results on the Cityscapes validation set, the Vaihingen building segmentation benchmark, and the MoNuSeg dataset."
"Julia Wolleb, Robin Sandkühler, Florentin Bieder, Philippe Valmaggia, P. Cattin",03a718819cdd3fcc102db640330037ff46431d67,Diffusion Models for Implicit Image Segmentation Ensembles,International Conference on Medical Imaging with Deep Learning,2021,29,"Diffusion models have shown impressive performance for generative modelling of images. In this paper, we present a novel semantic segmentation method based on diffusion models. By modifying the training and sampling scheme, we show that diffusion models can perform lesion segmentation of medical images. To generate an image specific segmentation, we train the model on the ground truth segmentation, and use the image as a prior during training and in every step during the sampling process. With the given stochastic sampling process, we can generate a distribution of segmentation masks. This property allows us to compute pixel-wise uncertainty maps of the segmentation, and allows an implicit ensemble of segmentations that increases the segmentation performance. We evaluate our method on the BRATS2020 dataset for brain tumor segmentation. Compared to state-of-the-art segmentation models, our approach yields good segmentation results and, additionally, detailed uncertainty maps."
"Georgios Batzolis, Jan Stanczuk, C. Schonlieb, C. Etmann",35356feaaf1a739a7db2b76f32e3e5a71ec74eb5,Conditional Image Generation with Score-Based Diffusion Models,,2021,29,"Score-based diffusion models have emerged as one of the most promising frameworks for deep generative modelling. In this work we conduct a systematic comparison and theoretical analysis of different approaches to learning conditional probability distributions with score-based diffusion models. In particular, we prove results which provide a theoretical justification for one of the most successful estimators of the conditional score. Moreover, we introduce a multi-speed diffusion framework, which leads to a new estimator for the conditional score, performing on par with previous state-of-the-art approaches. Our theoretical and experimental findings are accompanied by an open source library MSDiff which allows for application and further research of multi-speed diffusion models."
"I. Jelescu, Alexandre de Skowronski, F. Geffroy, M. Palombo, D. Novikov",151bc98d689bae082cfbb226efc35969d59d56ca,Neurite Exchange Imaging (NEXI): A minimal model of diffusion in gray matter with inter-compartment water exchange,NeuroImage,2021,21,
"Sam Bond-Taylor, Peter Hessey, Hiroshi Sasaki, T. Breckon, Chris G. Willcocks",80035bfa3f822364fbc62de6df2d5df13a0c47ff,Unleashing Transformers: Parallel Token Prediction with Discrete Absorbing Diffusion for Fast High-Resolution Image Generation from Vector-Quantized Codes,European Conference on Computer Vision,2021,18,
"Minghui Hu, Yujie Wang, Tat-Jen Cham, Jianfei Yang, P.N.Suganthan",64ac9c65c8f1e0a96a6d79facf548214103d0cbc,Global Context with Discrete Diffusion in Vector Quantised Modelling for Image Generation,Computer Vision and Pattern Recognition,2021,12,"The integration of Vector Quantised Variational AutoEncoder (VQ-VAE) with autoregressive models as generation part has yielded high-quality results on image generation. However, the autoregressive models will strictly follow the progressive scanning order during the sampling phase. This leads the existing VQ series models to hardly escape the trap of lacking global information. Denoising Diffusion Probabilistic Models (DDPM) in the continuous domain have shown a capability to capture the global context, while generating high-quality images. In the discrete state space, some works have demonstrated the potential to perform text generation and low resolution image generation. We show that with the help of a content-rich discrete visual codebook from VQ-VAE, the discrete diffusion model can also generate high fidelity images with global context, which compensates for the deficiency of the classical autoregressive model along pixel space. Meanwhile, the integration of the discrete VAE with the diffusion model resolves the drawback of conventional autoregressive models being oversized, and the diffusion model which demands excessive time in the sampling process when generating images. It is found that the quality of the generated images is heavily dependent on the discrete visual codebook. Extensive experiments demonstrate that the proposed Vector Quantised Discrete Diffusion Model (VQ-DDM) is able to achieve comparable performance to top-tier methods with low complexity. It also demonstrates outstanding advantages over other vectors quantised with autoregressive models in terms of image inpainting tasks without additional training."
"F. Kanavati, M. Tsuneki",7d78f9f6cfdd50907b28e9d53b2570a3d335e8e6,A deep learning model for gastric diffuse-type adenocarcinoma classification in whole slide images,Scientific Reports,2021,12,
"Yongyi Zhao, Ankit Raghuram, H. K. Kim, A. Hielscher, Jacob T. Robinson, A. Veeraraghavan",2afaa089a8fe3ca7676da56f2ed174880b2e8c67,"High Resolution, Deep Imaging Using Confocal Time-of-Flight Diffuse Optical Tomography",IEEE Transactions on Pattern Analysis and Machine Intelligence,2021,12,"Light scattering by tissue severely limits how deep beneath the surface one can image, and the spatial resolution one can obtain from these images. Diffuse optical tomography (DOT) is one of the most powerful techniques for imaging deep within tissue – well beyond the conventional <inline-formula><tex-math notation=""LaTeX"">$\sim$</tex-math><alternatives> <mml:math> <mml:mo>∼</mml:mo> </mml:math> <inline-graphic xlink:href=""zhao-ieq1-3075366.gif""/></alternatives></inline-formula>10-15 mean scattering lengths tolerated by ballistic imaging techniques such as confocal and two-photon microscopy. Unfortunately, existing DOT systems are limited, achieving only centimeter-scale resolution. Furthermore, they suffer from slow acquisition times and slow reconstruction speeds making real-time imaging infeasible. We show that time-of-flight diffuse optical tomography (ToF-DOT) and its confocal variant (CToF-DOT), by exploiting the photon travel time information, allow us to achieve millimeter spatial resolution in the highly scattered diffusion regime (<inline-formula><tex-math notation=""LaTeX"">$> \!\!50$</tex-math><alternatives> <mml:math> <mml:mrow> <mml:mo>></mml:mo> <mml:mspace width=""-0.166667em""/> <mml:mspace width=""-0.166667em""/> <mml:mn>50</mml:mn> </mml:mrow> </mml:math> <inline-graphic xlink:href=""zhao-ieq2-3075366.gif""/></alternatives></inline-formula> mean free paths). In addition, we demonstrate two additional innovations: focusing on confocal measurements, and multiplexing the illumination sources allow us to significantly reduce the measurement acquisition time. Finally, we rely on a novel convolutional approximation that allows us to develop a fast reconstruction algorithm, achieving a 100× speedup in reconstruction time compared to traditional DOT reconstruction techniques. Together, we believe that these technical advances serve as the first step towards real-time, millimeter resolution, deep tissue imaging using DOT."
"Boah Kim, Inhwa Han, Jong-Chul Ye",059fb28b8a61093c696fa63fea848a562baf9b23,DiffuseMorph: Unsupervised Deformable Image Registration Along Continuous Trajectory Using Diffusion Models,ArXiv,2021,11,"Deformable image registration is one of the fundamental tasks for medical imaging and computer vision. Classical registration algorithms usually rely on iterative optimization approaches to provide accurate deformation, which requires high computational cost. Although many deep-learning-based methods have been developed to carry out fast image registration, it is still challenging to estimate the deformation ﬁeld with less topological folding problem. Furthermore, these approaches only enable registration to a single ﬁxed image, and it is not possible to obtain contin-uously varying registration results between the moving and ﬁxed images. To address this, here we present a novel approach of diffusion model-based probabilistic image registration, called DiffuseMorph. Speciﬁcally, our model learns the score function of the deformation between moving and ﬁxed images. Similar to the existing diffusion models, DiffuseMorph not only provides synthetic deformed images through a reverse diffusion process, but also enables various levels of deformation of the moving image along with the latent space. Experimental results on 2D face expression image and 3D brain image registration tasks demonstrate that our method can provide ﬂexible and accurate deformation with a capability of topology preservation."
"Sam L. Polk, James M. Murphy",77ed7ce6a012a0c23e37a7d9c8a8c29ac66c5e92,Multiscale Clustering of Hyperspectral Images Through Spectral-Spatial Diffusion Geometry,2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS,2021,8,"Clustering algorithms partition a dataset into groups of similar points. The primary contribution of this article is the Multiscale Spatially-Regularized Diffusion Learning (M-SRDL) clustering algorithm, which uses spatially-regularized diffusion distances to efficiently and accurately learn multiple scales of latent structure in hyperspectral images (HSI). The M-SRDL clustering algorithm extracts clusterings at many scales from an HSI and outputs these clusterings' variation of information-barycenter as an exemplar for all underlying cluster structure. We show that incorporating spatial regularization into a multiscale clustering framework corresponds to smoother and more coherent clusters when applied to HSI data and leads to more accurate clustering labels."
"Lexi Gault, L. Leisman, E. Adams, Pavel E. Mancera Piña, K. Reiter, N. Smith, M. Battipaglia, J. Cannon, F. Fraternali, M. Haynes, Elizabeth McAllan, Hannah J. Pagel, K. Rhode, J. Salzer, Quinton Singer",c804cb52b22ec7e047224b0f654d9c5bb042a22b,VLA Imaging of H i-bearing Ultra-diffuse Galaxies from the ALFALFA Survey,Astrophysical Journal,2021,7,"Ultra-diffuse galaxies have generated significant interest due to their large optical extents and low optical surface brightnesses, which challenge galaxy formation models. Here we present resolved synthesis observations of 12 H i-bearing ultra-diffuse galaxies (HUDs) from the Karl G. Jansky Very Large Array, as well as deep optical imaging from the WIYN 3.5 m telescope at Kitt Peak National Observatory. We present the data processing and images, including total intensity H i maps and H i velocity fields. The HUDs show ordered gas distributions and evidence of rotation, important prerequisites for the detailed kinematic models of Mancera Piña et al. We compare the H i and stellar alignment and extent, and find that H i extends beyond the already extended stellar component and the H i disk is often misaligned with respect to the stellar one, emphasizing the importance of caution when approaching inclination measurements for these extreme sources. We explore the H i mass–diameter scaling relation, and find that, although the HUDs have diffuse stellar populations, they fall along the relation with typical global H i surface densities. This resolved sample forms an important basis for more detailed study of the H i distribution in this extreme extragalactic population."
"Boah Kim, Inhwa Han, Jong-Chul Ye",763613a26a9fefb9de7d3fea62d7c716772749de,DiffuseMorph: Unsupervised Deformable Image Registration Using Diffusion Model,European Conference on Computer Vision,2021,5,
"Abiy Tasissa, D. Nguyen, James M. Murphy",a330dd324b50eac0f4d8a8bdba9a886fcc7e12d3,Deep Diffusion Processes for Active Learning of Hyperspectral Images,2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS,2021,5,"A method for active learning of hyperspectral images (HSI) is proposed, which combines deep learning with diffusion processes on graphs. A deep variational autoencoder extracts smoothed, denoised features from a high-dimensional HSI, which are then used to make labeling queries based on graph diffusion processes. The proposed method combines the robust representations of deep learning with the mathematical tractability of diffusion geometry, and leads to strong performance on real HSI."
"Tobias Alt, Pascal Peter, J. Weickert",08c623dfef362f2e194abc0c995c520c7013a011,Learning Sparse Masks for Diffusion-based Image Inpainting,Iberian Conference on Pattern Recognition and Image Analysis,2021,5,
"A. Wong, Hayden Gunraj, Vignesh Sivan, M. Haider",bfbb8331f96504e162b5f72ab1c0e7758015ceaf,Synthetic correlated diffusion imaging hyperintensity delineates clinically significant prostate cancer,Scientific Reports,2021,4,
"Xuejian Ma, Fei Zhang, Zhaodong Chu, Ji Hao, Xihan Chen, Jiamin Quan, Zhiyuan Huang, Xiaoming Wang, Xiaoqin Li, Yanfa Yan, K. Zhu, K. Lai",da8402a05a4b922404a54099b1081ee0ad37e0c1,Superior photo-carrier diffusion dynamics in organic-inorganic hybrid perovskites revealed by spatiotemporal conductivity imaging,Nature Communications,2021,4,
"F. Gadjimuradov, T. Benkert, M. Nickel, A. Maier",009c03ba5957aebc1d5af33acf3706aeeec1924a,Robust partial Fourier reconstruction for diffusion‐weighted imaging using a recurrent convolutional neural network,Magnetic Resonance in Medicine,2021,4,To develop an algorithm for robust partial Fourier (PF) reconstruction applicable to diffusion‐weighted (DW) images with non‐smooth phase variations.
"Yanglan Ou, Ye Yuan, Xiaolei Huang, Kelvin K. Wong, John Volpi, J. Z. Wang, Stephen T. C. Wong",a8bcf38572b950d948b2ae2cbd1024285361b1af,LambdaUNet: 2.5D Stroke Lesion Segmentation of Diffusion-weighted MR Images,International Conference on Medical Image Computing and Computer-Assisted Intervention,2021,4,
"Haneul Kang, S. Ryu",463f945257f106b11630a14c51dd88e98bd1f955,Optical Imaging of Chemically and Geometrically Controlled Interfacial Diffusion and Redox in 2D van der Waals Space,Journal of Physical Chemistry C,2021,4,"Molecular motions and chemical reactions occurring in constrained space play key roles in many catalysis and energy storage applications. However, its understanding has been impeded by difficulty in detection and lack of reliable model systems. In this work, we report geometric and chemical manipulation of O2 diffusion and ensuing O2-mediated charge transfer (CT) that occur in the 2D space between single-layer transition metal dichalcogenides (TMDs) and dielectric substrates. As a sensitive real-time wide-field imaging signal, charge-density-dependent photoluminescence (PL) from TMDs was used. The two sequential processes inducing spatiotemporal PL change could be drastically accelerated by increasing the interfacial gap size or introducing artificial defects serving as CT reaction centers. We also show that widely varying CT kinetics of four TMDs are rate-determined by the degree of hydration required for the reactions. The reported findings will be instrumental in designing novel functional nanostructures and devices."
"N. Ram'irez-Olivencia, E. Varenius, M. P'erez-Torres, A. Alberdi, J. Conway, A. Alonso-Herrero, M. Pereira-Santaella, R. Herrero-Illana",0adbcfc7eff1e6c3398715a8ec4e1ced4c72f6f7,Subarcsecond LOFAR imaging of Arp299 at 150 MHz. Tracing the nuclear and diffuse extended emission of a bright LIRG,Astronomy & Astrophysics,2021,3,"Context. Arp 299 is the brightest luminous infrared galaxy (LIRG) within 50 Mpc, with IR luminosity log(LIR/L ) = 11.9. It provides a unique laboratory for testing physical processes in merging galaxies. Aims. We study for the first time the low-frequency (∼150 MHz) radio brightness distribution of Arp 299 at subarcsecond resolution, tracing in both compact and extended emission regions the local spectral energy distribution (SED) in order to characterize the dominant emission and absorption processes. Methods. We analysed the spatially resolved emission of Arp 299 revealed by 150 MHz international baseline Low-Frequency Array (LOFAR) and 1.4, 5.0, and 8.4 GHz Very Large Array (VLA) observations. Results. We present the first subarcsecond (0.4′′ ∼ 100 pc) image of the whole Arp 299 system at 150 MHz. The high surface brightness sensitivity of our LOFAR observations (∼100 μJy beam−1) allowed us to detect all of the nuclear components detected at higher frequencies, as well as the extended steep-spectrum emission surrounding the nuclei. We obtained spatially resolved, two-point spectral index maps for the whole galaxy: the compact nuclei show relatively flat spectra, while the extended, diffuse component shows a steep spectrum. We fitted the radio SED of the nuclear regions using two different models: a continuous free-free medium model and a clumpy model. The continuous model can explain the SED of the nuclei assuming a population of relativistic electrons subjected to synchrotron, bremsstrahlung, and ionization losses. The clumpy model fits assuming relativistic electrons with negligible energy losses, and thermal fractions that are more typical of star-forming galaxies than those required for the continuous model. Conclusions. Our results confirm the usefulness of combining spatially resolved radio imaging at both MHz and GHz frequencies to characterize in detail the radio emission properties of LIRGs from the central 100 pc out to the kiloparsec galaxy-wide scales."
"Ru-Yu Lai, Kui Ren, Ting Zhou",946c35496060b4b14a1c57d09c224003f1e1d5f2,Inverse Transport and Diffusion Problems in Photoacoustic Imaging with Nonlinear Absorption,SIAM Journal on Applied Mathematics,2021,3,"Motivated by applications in imaging nonlinear optical absorption by photoacoustic tomography (PAT), we study in this work inverse coefficient problems for a semilinear radiative transport equation and its diffusion approximation with internal data that are functionals of the coefficients and the solutions to the equations. Based on the techniques of firstand secondorder linearization, we derive uniqueness and stability results for the inverse problems. For uncertainty quantification purpose, we also establish the stability of the reconstruction of the absorption coefficients with respect to the change in the scattering coefficient."
"Mengwei Ren, Heejong Kim, Neel Dey, G. Gerig",10744f746726227cdf69489e10707f277b4944e1,Q-space Conditioned Translation Networks for Directional Synthesis of Diffusion Weighted Images from Multi-modal Structural MRI,International Conference on Medical Image Computing and Computer-Assisted Intervention,2021,3,
"E. Fischi-Gomez, Jonathan Rafael-Patino, M. Pizzolato, G. Piredda, T. Hilbert, T. Kober, E. Canales-Rodríguez, J. Thiran",870157bbd46bc8b08d157f5c454fabf09d50d435,"Multi-Compartment Diffusion Mri, T2 Relaxometry And Myelin Water Imaging As Neuroimaging Descriptors For Anomalous Tissue Detection",IEEE International Symposium on Biomedical Imaging,2021,3,"Multiple sclerosis (MS) is an inflammatory and neurodegenerative disease characterized by diffuse and focal areas of tissue loss. Conventional MRI techniques such as T1-weighted and T2-weighted scans are generally used in the diagnosis and prognosis of the disease. Yet, these methods are limited by the lack of specificity between lesions, its perilesional area and non-lesional tissue. Alternative MRI techniques exhibit a higher level of sensitivity to focal and diffuse MS pathology than conventional MRI acquisitions. However, they still suffer from limited specificity when considered alone. In this work, we have combined tissue microstructure information derived from multicompartment diffusion MRI and T2 relaxometry models to explore the voxel-based prediction power of a machine learning model in a cohort of MS patients and healthy controls. Our results show that the combination of multi-modal features, together with a boosting enhanced decision-tree based classifier, which combines a set of weak classifiers to form a strong classifier via a voting mechanism, is able to utilise the complementary information for the classification of abnormal tissue."
"Adnan Ahmad, D. Parker, Z. R. Samani, R. Verma",01b8bb90598b7f4feb242f465b2fc3c39dd06f45,3D-QCNet - A Pipeline for Automated Artifact Detection in Diffusion MRI images,Comput. Medical Imaging Graph.,2021,3,
"Maoyuan Xu, Xiaoping Xie",a949070ef347653f9064f3fc89c4760e3fe16d21,An efficient feature-preserving PDE algorithm for image denoising based on a spatial-fractional anisotropic diffusion equation,ArXiv,2021,3,"How to effectively remove the noise while preserving the image structure features is a challenging issue in the field of image denoising. In recent years, fractional PDE based methods have attracted more and more research efforts due to the ability to balance the noise removal and the preservation of image edges and textures. Among the existing fractional PDE algorithms, there are only a few using spatial fractional order derivatives, and all the fractional derivatives involved are one-sided derivatives. In this paper, an efficient feature-preserving fractional PDE algorithm is proposed for image denoising based on a nonlinear spatial-fractional anisotropic diffusion equation. Two-sided Grümwald-Letnikov fractional derivatives were used in the PDE model which are suitable to depict the local self-similarity of images. The Short Memory Principle is employed to simplify the approximation scheme. Experimental results show that the proposed method is of a satisfactory performance, i.e. it keeps a remarkable balance between noise removal and feature preserving, and has an extremely high structural retention property."
"J. Gholam, F. Szczepankiewicz, C. Tax, Lars Mueller, E. Kopanoglu, M. Nilsson, S. Aja‐Fernández, Matt Griffin, Derek K. Jones, L. Beltrachini",195b1581533a34b4df066a8ceff9fa28a1427ac5,aDWI-BIDS: an extension to the brain imaging data structure for advanced diffusion weighted imaging,,2021,2,"1School of Physics and Astronomy, Cardiff University, Cardiff, United Kingdom 2Cardiff Univeristy Brain Research Imaging Centre (CUBRIC), Cardiff, United Kingdom 3Department of Diagnostic Radiology, Lund University, Lund, Sweden 4Image Sciences Institute, University Medical Center Utrecht, Utrecht, Netherlands 5School of Psychology, Cardiff University, Cardiff, United Kingdom 6Universidad de Valladolid, Valladolid, Spain"
"Y. Liang, Chuang Niu, Chen Wei, Shenghan Ren, W. Cong, Ge Wang",cfb1997aeb113235d6173b2321331a0d0f819d1e,Phase function estimation from a diffuse optical image via deep learning,Physics in Medicine and Biology,2021,1,"Objective. The phase function is a key element of a light propagation model for Monte Carlo (MC) simulation, which is usually fitted with an analytic function with associated parameters. In recent years, machine learning methods were reported to estimate the parameters of the phase function of a particular form such as the Henyey–Greenstein phase function but, to our knowledge, no studies have been performed to determine the form of the phase function. Approach. Here we design a convolutional neural network (CNN) to estimate the phase function from a diffuse optical image without any explicit assumption on the form of the phase function. Specifically, we use a Gaussian mixture model (GMM) as an example to represent the phase function generally and learn the model parameters accurately. The GMM is selected because it provides the analytic expression of phase function to facilitate deflection angle sampling in MC simulation, and does not significantly increase the number of free parameters. Main Results. Our proposed method is validated on MC-simulated reflectance images of typical biological tissues using the Henyey–Greenstein phase function with different anisotropy factors. The mean squared error of the phase function is 0.01 and the relative error of the anisotropy factor is 3.28%. Significance. We propose the first data-driven CNN-based inverse MC model to estimate the form of scattering phase function. The effects of field of view and spatial resolution are analyzed and the findings provide guidelines for optimizing the experimental protocol in practical applications."
"Numair Khan, Min H. Kim, J. Tompkin",df1a4b5cb1cec9a321f8c2accf72c4dd7ef866f9,Differentiable Diffusion for Dense Depth Estimation from Multi-view Images,Computer Vision and Pattern Recognition,2021,1,"We present a method to estimate dense depth by optimizing a sparse set of points such that their diffusion into a depth map minimizes a multi-view reprojection error from RGB supervision. We optimize point positions, depths, and weights with respect to the loss by differential splatting that models points as Gaussians with analytic transmittance. Further, we develop an efficient optimization routine that can simultaneously optimize the 50k+ points required for complex scene reconstruction. We validate our routine using ground truth data and show high reconstruction quality. Then, we apply this to light field and wider baseline images via self supervision, and show improvements in both average and outlier error for depth maps diffused from inaccurate sparse points. Finally, we compare qualitative and quantitative results to image processing and deep learning methods."
"J. Ding, Chi-Hsiang Chu, Mong-Na Lo Huang, Chien-Ching Hsu",3d6c4fb25b21fd8684c0298f0068779d4798757e,Dopamine Transporter SPECT Image Classification for Neurodegenerative Parkinsonism via Diffusion Maps and Machine Learning Classifiers,Annual Conference on Medical Image Understanding and Analysis,2021,1,
U. Nnolim,b325c6b26a2e65f2854d9d9828c5fcb725fdef38,Analysis of Multiscale Wavelet-based Fractional Gradient-Anisotropic Diffusion Fusion for single hazy and underwater image enhancement,ArXiv,2021,0,This report presents the results of a multi-scale wavelet based scheme for single image dehazing and underwater image enhancement. The scheme is fast and highly localized in addition to global enhancement of hazy images. A PDE-based formulation enables additional versatility as the iterative nature allows more flexibility for various types of images. Visual and objective results from experiments indicate that the proposed approach competes favourably or surpasses most of the state-of-the-art approaches.
"D. Ludwig, F. Laun, K. Klika, J. Rauch, M. Ladd, P. Bachert, T. Kuder",41d3dcb550b721d2b7e9e706339e9d3eb4a46819,Diffusion pore imaging in the presence of extraporal water.,"Journal of magnetic resonance (San Diego, Calif. 1997 : Print)",2021,0,
"Volker Grimm, Kevin J Liang",304fead298c2cd2a798003c22b173c157354ee7d,An extended Krylov subspace method for decoding edge-based compressed images by homogeneous diffusion,ArXiv,2021,0,The heat equation is often used in order to inpaint dropped data in inpainting-based lossy compression schemes. We propose an alternative way to numerically solve the heat equation by an extended Krylov subspace method. The method is very efficient with respect to the direct computation of the solution of the heat equation at large times. And this is exactly what is needed for decoding edge-compressed pictures by homogeneous diffusion.
"O. Ruesch, C. Woehler",4e13f78b2805170e9c2696640cef35a549a76de1,"The fillet of a rock on the Moon: Cohesion and size dependent abrasion rates from topographic diffusion, LRO/NAC and Apollo images",,2021,0,"The efficiency of regolith production is key in understanding the properties of airless surfaces. Debris aprons, of fillets, around rocks are an ubiquitous morphology on many surfaces without atmosphere, which origin and evolution are largely unknown. Here we show that fillet originates from the juxtaposed rock under abrasion and that rocks of different cohesion have fillets with distinct morphological evolution. Thus, a fillet around a rock allows to disentangle rock cohesion from its surface exposure age. By combing topographic diffusion modeling with images of blocks of known age on the Moon we find abrasion rates for cm-sized boulders similar to regional rates (0.2 mm/Myr), whereas for 10-m sized blocks the rate is two order of magnitude higher (20 mm/Myr). Rates for instances of rocks of higher strength are reduced by ~50%. Fillets around lunar rocks are consistent with abrasion by isotropic micrometeoroid bombardment."
"Benoit Anctil-Robitaille, Antoine Th'eberge, Pierre-Marc Jodoin, M. Descoteaux, Christian Desrosiers, H. Lombaert",f6309fb0b5739dfbd0e94949cbea951a102823e9,Manifold-aware synthesis of high-resolution diffusion from structural imaging,Frontiers in Neuroimaging,2021,0,"The physical and clinical constraints surrounding diffusion-weighted imaging (DWI) often limit the spatial resolution of the produced images to voxels up to eight times larger than those of T1w images. The detailed information contained in accessible high-resolution T1w images could help in the synthesis of diffusion images with a greater level of detail. However, the non-Euclidean nature of diffusion imaging hinders current deep generative models from synthesizing physically plausible images. In this work, we propose the first Riemannian network architecture for the direct generation of diffusion tensors (DT) and diffusion orientation distribution functions (dODFs) from high-resolution T1w images. Our integration of the log-Euclidean Metric into a learning objective guarantees, unlike standard Euclidean networks, the mathematically-valid synthesis of diffusion. Furthermore, our approach improves the fractional anisotropy mean squared error (FA MSE) between the synthesized diffusion and the ground-truth by more than 23% and the cosine similarity between principal directions by almost 5% when compared to our baselines. We validate our generated diffusion by comparing the resulting tractograms to our expected real data. We observe similar fiber bundles with streamlines having <3% difference in length, <1% difference in volume, and a visually close shape. While our method is able to generate diffusion images from structural inputs in a high-resolution space within 15 s, we acknowledge and discuss the limits of diffusion inference solely relying on T1w images. Our results nonetheless suggest a relationship between the high-level geometry of the brain and its overall white matter architecture that remains to be explored."
"S. O'Sullivan, Ruizhe Kang, Jules A. Gardener, A. Akey, C. Matt, J. Hoffman",18c0765fa0d7d341c92c32467dc20ddc1bfd2938,Imaging Se diffusion across the FeSe/SrTiO$_3$ interface,,2021,0,"Monolayer FeSe on SrTiO 3 superconducts with reported T c as high as 100 K, but the dramatic interfacial T c enhancement remains poorly understood. Oxygen vacancies in SrTiO 3 are known to enhance the interfacial electron doping, electron-phonon coupling, and superconducting gap, but the detailed mechanism is unclear. Here we apply scanning transmission electron microscopy (STEM) and electron energy loss spectroscopy (EELS) to FeSe/SrTiO 3 to image the diﬀusion of selenium into SrTiO 3 to an unexpected depth of several unit cells, consistent with the simultaneously observed depth proﬁle of oxygen vacancies. Our density functional theory (DFT) calculations support the crucial role of oxygen vacancies in facilitating the thermally driven Se diﬀusion. In contrast to excess Se in the FeSe monolayer or FeSe/SrTiO 3 interface that is typically removed during post-growth annealing, the diﬀused Se remains in the top few unit cells of the SrTiO 3 bulk after the extended post-growth annealing that is necessary to achieve superconductivity. Thus, the unexpected Se in SrTiO 3 may contribute to the interfacial electron doping and electron-phonon coupling that enhance T c , suggesting another important role for oxygen vacancies as facilitators of Se diﬀusion."
"Andrew C. Chiang, Po-Nan Li, S. Wakatsuki",5b3e90730f2ab435b7ca77b27b06685baf213bb5,An image-incorporated immersed boundary method for diffusion equations,ArXiv,2021,0,"A novel sharp interface ghost-cell based immersed boundary method has been proposed and its parameters have been optimized against an analytical model in diffusion applications. The proposed embedded constrained moving least-squares (ECMLS) algorithm minimizes the error of the interpolated concentration at the image point of the ghost point by applying a moving least-squares method on all internal nodes, near the ghost image point, and the associated mirrored image points of these internal nodes through the corresponding boundary conditions. Using an analytical model as a reference, the ECMLS algorithm is compared to the constrained moving least-squares (CMLS) algorithm and the staircase model using various grid sizes, interpolation basis functions, weight functions, and the penalty parameter of the constraint. It is found that using ECMLS algorithm in the investigated diffusion application, the incomplete quartic basis function yields the best performance while the quadratic, cubic, and bicubic basis functions also produce results better than the staircase model. It is also found that the linear and bilinear basis functions cannot produce results better than the staircase model in diffusion applications. It is shown that the optimal radius of the region of internal nodes used for interpolation scales with the logarithm of the boundary radius of curvature. It is shown that for the diffusion application, the proposed ECMLS algorithm produces lower errors at the boundary with better numerical stability over a wider range of basis functions, weight functions, boundary radius of curvature, and the penalty parameter than the CMLS algorithm."
Zhou Lan,0c4a7cf232a02db89fa12ffdf4b23a09d64417e0,Statistical Inference of Auto-correlated Eigenvalues with Applications to Diffusion Tensor Imaging,,2021,0,"Diffusion tensor imaging (DTI) is a prevalent neuroimaging tool in analyzing the anatomical structure. The distinguishing feature of DTI is that the voxel-wise variable is a 3× 3 positive definite matrix other than a scalar, describing the diffusion process at the voxel. Recently, several statistical methods have been proposed to analyze the DTI data. This paper focuses on the statistical inference of eigenvalues of DTI because it provides more transparent clinical interpretations. However, the statistical inference of eigenvalues is statistically challenging because few treat these responses as random eigenvalues. In our paper, we rely on the distribution of the Wishart matrix’s eigenvalues to model the random eigenvalues. A hierarchical model which captures the eigenvalues’ randomness and spatial auto-correlation is proposed to infer the local covariate effects. The Monte-Carlo Expectation-Maximization algorithm is implemented for parameter estimation. Both simulation studies and application to IXI data-set are used to demonstrate our proposal. The results show that our proposal is more proper in analyzing auto-correlated random eigenvalues compared to alternatives."
"W. Consagra, A. Venkataraman, Zhengwu Zhang",563a0350713914d4e7ee1d9a40244834b298763d,Optimized Diffusion Imaging for Brain Structural Connectome Analysis,IEEE Transactions on Medical Imaging,2021,0,"High angular resolution diffusion imaging (HARDI) is a type of diffusion magnetic resonance imaging (dMRI) that measures diffusion signals on a sphere in q-space. It has been widely used in data acquisition for human brain structural connectome analysis. To more accurately estimate the structural connectome, dense samples in q-space are often acquired, potentially resulting in long scanning times and logistical challenges. This paper proposes a statistical method to select q-space directions optimally and estimate the local diffusion function from sparse observations. The proposed approach leverages relevant historical dMRI data to calculate a prior distribution to characterize local diffusion variability in each voxel in a template space. For a new subject to be scanned, the priors are mapped into the subject-specific coordinate and used to help select the best q-space samples. Simulation studies demonstrate big advantages over the existing HARDI sampling and analysis framework. We also applied the proposed method to the Human Connectome Project data and a dataset of aging adults with mild cognitive impairment. The results indicate that with very few q-space samples (e.g., 15 or 20), we can recover structural brain networks comparable to the ones estimated from 60 or more diffusion directions with the existing methods."
"Ryutaro Tanno, Daniel E. Worrall, Enrico Kaden, D. Alexander",29f8bae5a9a68d8fdc885d2e026a8166bd1eed30,Uncertainty modelling in deep learning for safer neuroimage enhancement: Demonstration in diffusion MRI,NeuroImage,2020,44,
"S. Mohammadi, M. Callaghan",6e53ae16611e27ab6c5d8a93925483332c43bdb0,Towards in vivo g-ratio mapping using MRI: Unifying myelin and diffusion imaging,Journal of Neuroscience Methods,2020,32,
"R. Henriques, M. Palombo, S. Jespersen, N. Shemesh, H. Lundell, A. Ianuş",5cef5808f400db02e2e72fb5f3d8dc6799dab957,Double diffusion encoding and applications for biomedical imaging,Journal of Neuroscience Methods,2020,22,
"Bo Li, M. Groot, R. Steketee, R. Meijboom, M. Smits, M. Vernooij, M. Ikram, Jiren Liu, W. Niessen, E. Bron",f7d7f39ee26107caa001fb3048812f0657afbe8e,Neuro4Neuro: A neural network approach for neural tract segmentation using large-scale population-based diffusion imaging,NeuroImage,2020,21,
"M. Khalid Hossain, K. Hashizume, Y. Hatano",6f7fd690c07b39b0690e9b7a6739e1f48a03143d,Evaluation of the hydrogen solubility and diffusivity in proton-conducting oxides by converting the PSL values of a tritium imaging plate,Nuclear Materials and Energy,2020,18,
"Hongyu Li, Zifei Liang, C. Zhang, Ruiying Liu, Jing Li, Weihong Zhang, D. Liang, B. Shen, Xiaoliang Zhang, Y. Ge, Jiangyang Zhang, L. Ying",0c1293f451f3f2be18e0f8a5b3c1de020229e1c8,SuperDTI: Ultrafast DTI and fiber tractography with deep learning,Magnetic Resonance in Medicine,2020,17,To develop a deep learning–based reconstruction framework for ultrafast and robust diffusion tensor imaging and fiber tractography.
"M. Pizzolato, G. Gilbert, J. Thiran, M. Descoteaux, R. Deriche",b7ddf7fdf49b74558eda3ce337ef054df23e9e3c,Adaptive phase correction of diffusion-weighted images,NeuroImage,2020,14,
"Hong-Hsi Lee, E. Fieremans, D. Novikov",cf5ef055678af3c7e371b983a6fabd27b389e3cf,Realistic Microstructure Simulator (RMS): Monte Carlo simulations of diffusion in three-dimensional cell segmentations of microscopy images,Journal of Neuroscience Methods,2020,12,
"R. Ragusa, M. Spavone, E. Iodice, S. Brough, M. A. Raj, M. Paolillo, M. Cantiello, D. Forbes, A. Marca, G. D. Ago, R. Rampazzo, P. D. I. O. Capodimonte, U. Federico, School of Physics University of New South Wales, I. A. Observatory, Centre for Gravitational Astrophysics, S. U. O. Technology., I. D. A. -. P. U. C. Chile, I. Padova",d289bd1bcd73b165b1600293f80814a858b437f2,VEGAS: a VST Early-type GAlaxy Survey,Astronomy & Astrophysics,2020,12,"Context. This paper is based on the multi-band VST Early-type GAlaxy Survey (VEGAS) with the VLT Survey Telescope (VST). We present new deep photometry of the IC 1459 group in g and r band.
Aims. The main goal of this work is to investigate the photometric properties of the IC 1459 group, and to compare our results with those obtained for other galaxy groups studied in VEGAS, in order to provide an initial view of the variation of their properties as a function of the evolution of the system.
Methods. For all galaxies in the IC 1459 group, we fit isophotes and extract the azimuthally averaged surface-brightness profiles, the position angle, and ellipticity profiles as a function of the semi-major axis. We also extract the average colour profile. In each band, we estimate the total magnitude, effective radius, mean colour, and total stellar mass for each galaxy in the group. We then look at the structure of the brightest galaxies and the faint features in their outskirts, considering also the intragroup component.
Results. The wide field of view, long integration time, high angular resolution, and arcsec-level seeing of OmegaCAM at VST allow us to map the light distribution of IC 1459 down to a surface brightness level of 29.26 mag arcsec−2 in g band and 28.85 mag arcsec−2 in r band, and out to 7−10Re, and to detect the optical counterpart of HI gas around IC 1459. We also carry out an in-depth exploration of three low-density environments and provide information to understand how galaxy and group properties change with the group evolution stage.
Conclusions. Good agreement is found between our results and predictions of numerical simulations regarding the structural properties of the brightest galaxies of the groups. We suggest that the structure of the outer envelope of he brightest cluster galaxies (i.e. the signatures of past mergers and tidal interactions), the intra-group light, and the HI amount and distribution may be used as indicators of the evolutionary stage and mass assembly of galaxy groups."
"Jan Martin, Sebastian Endt, A. Wetscherek, T. Kuder, A. Doerfler, M. Uder, B. Hensel, F. Laun",a91ea111d24f07046d5caaee2b3bff8423edee31,Contrast-to-noise ratio analysis of microscopic diffusion anisotropy indices in q-space trajectory imaging.,Zeitschrift für Medizinische Physik,2020,9,
U. Nnolim,66ba10d26b594573546afa93437c60c7905cef12,Single Image De-Hazing via Multiscale Wavelet Decomposition and Estimation with Fractional Gradient-Anisotropic Diffusion Fusion,International Journal of Image and Graphics,2020,8,"This paper presents algorithms based on fractional multiscale gradient fusion and multilevel wavelet decomposition for underwater and hazy image enhancement. The algorithms utilize partial differential equation (PDE)-generated low- and high-frequency images fused via gradient domain and anisotropic diffusion. Furthermore, wavelet multi-level decomposition, estimation and adjustment of detail and approximation coefficients are employed in improving local and global enhancement. Solutions to halo effect are also developed using compressive bilateral filters or other nonlinear/nonlocal means filter. Ultimately, experimental comparisons indicate that the proposed methods surpass or are comparable to several algorithms from the literature."
"D. Forbes, J. Gannon, A. Romanowsky, A. Alabi, J. Brodie, W. Couch, A. Ferré-Mateu",03f675312b8902afe256cf01706cc88740b7b509,Stellar velocity dispersion and dynamical mass of the ultra diffuse galaxy NGC 5846_UDG1 from the keck cosmic web imager,,2020,8,"The ultra-diffuse galaxy in the NGC 5846 group (NGC 5846_UDG1) was shown to have a large number of globular cluster (GC) candidates from deep imaging as part of the VEGAS survey. Recently, Muller et al. published a velocity dispersion, based on a dozen of its GCs. Within their quoted uncertainties, the resulting dynamical mass allowed for either a dark matter free or a dark matter dominated galaxy. Here we present spectra from KCWI which reconfirms membership of the NGC 5846 group and reveals a stellar velocity dispersion for UDG1 of $\sigma_{GC}$ = 17 $\pm$ 2 km/s. Our dynamical mass, with a reduced uncertainty, indicates a very high contribution of dark matter within the effective radius. We also derive an enclosed mass from the locations and motions of the GCs using the Tracer Mass Estimator, finding a similar mass inferred from our stellar velocity dispersion. We find no evidence that the galaxy is rotating and is thus likely pressure-supported. The number of confirmed GCs, and the total number inferred for the system ($\sim$45), suggest a total halo mass of $\sim2 \times 10^{11}$ M$_{\odot}$. A cored mass profile is favoured when compared to our dynamical mass. Given its stellar mass of 1.1$\times$10$^{8}$ M$_{\odot}$, NGC 5846_UDG1 appears to be an ultra-diffuse galaxy with a dwarf-like stellar mass and an overly massive halo."
"Talon Chandler, H. Shroff, R. Oldenbourg, P. L. La Riviere",7b2f57473609d29f79622d6fe76b2581f2a60cda,"Spatio-angular fluorescence microscopy III. Constrained angular diffusion, polarized excitation, and high-NA imaging.",Journal of The Optical Society of America A-optics Image Science and Vision,2020,8,"We investigate rotational diffusion of fluorescent molecules in angular potential wells, the excitation and subsequent emissions from these diffusing molecules, and the imaging of these emissions with high-NA aplanatic optical microscopes. Although dipole emissions only transmit six low-frequency angular components, we show that angular structured illumination can alias higher-frequency angular components into the passband of the imaging system. We show that the number of measurable angular components is limited by the relationships between three time scales: the rotational diffusion time, the fluorescence decay time, and the acquisition time. We demonstrate our model by simulating a numerical phantom in the limits of fast angular diffusion, slow angular diffusion, and weak potentials."
"A. Reymbaut, A. Caron, G. Gilbert, F. Szczepankiewicz, M. Nilsson, S. Warfield, M. Descoteaux, B. Scherrer",5da77ca9883e72d2ab502e111b40e179fc149e1b,Magic DIAMOND: Multi-fascicle diffusion compartment imaging with tensor distribution modeling and tensor-valued diffusion encoding,Medical Image Anal.,2020,7,
"J. Radford, A. Lyons, F. Tonolini, D. Faccio",242006ffc38d6491f2aceafcfc001ba31ac601ee,Role of late photons in diffuse optical imaging.,Optics Express,2020,6,"The ability to image through turbid media, such as organic tissues, is a highly attractive prospect for biological and medical imaging. This is challenging, however, due to the highly scattering properties of tissues which scramble the image information. The earliest photons that arrive at the detector are often associated with ballistic transmission, whilst the later photons are associated with complex paths due to multiple independent scattering events and are therefore typically considered to be detrimental to the final image formation process. In this work, we report on the importance of these highly diffuse, ""late"" photons for computational time-of-flight diffuse optical imaging. In thick scattering materials, >80 transport mean free paths, we provide evidence that including late photons in the inverse retrieval enhances the image reconstruction quality. We also show that the late photons alone have sufficient information to retrieve images of a similar quality to early photon gated data. This result emphasises the importance in the strongly diffusive regime of fully time-resolved imaging techniques."
"Yiman Huang, Xinlin Zhang, Hua Guo, Huijun Chen, D. Guo, F. Huang, Qinghong Xu, X. Qu",385065b00c72de386c26a57493599acd9a75c590,Phase-constrained reconstruction of high-resolution multi-shot diffusion weighted image.,"Journal of magnetic resonance (San Diego, Calif. 1997 : Print)",2020,5,
"Tianhui Zhu, D. Olson, P. Hopkins, M. Zebarjadi",285a217d4f69f1653bffc3f89eaf0aa11e909772,Heat diffusion imaging: In-plane thermal conductivity measurement of thin films in a broad temperature range.,Review of Scientific Instruments,2020,5,"This work combines the principles of the heat spreader method and the imaging capability of the thermoreflectance measurements to measure the in-plane thermal conductivity of thin films without the requirement of film suspension or multiple thermometer deposition. We refer to this hybrid technique as heat diffusion imaging. The thermoreflectance imaging system provides a temperature distribution map across the film surface. The in-plane thermal conductivity can be extracted from the temperature decay profile. By coupling the system with a cryostat, we were able to conduct measurements from 40 K to 400 K. Silicon thin film samples with and without periodic holes were measured and compared with in-plane time-domain thermoreflectance measurements and literature data as validation for heat diffusion imaging."
"Zhiyong Dou, Haotian Cui, Bo Wang",2476bf49ed92cd14e16d44cdf1645827e75014e2,Learning Global and Local Consistent Representations for Unsupervised Image Retrieval via Deep Graph Diffusion Networks,ArXiv,2020,5,"Diffusion has shown great success in improving accuracy of unsupervised image retrieval systems by utilizing high-order structures of image manifold. However, existing diffusion methods suffer from three major limitations: 1) they usually rely on local structures without considering global manifold information; 2) they focus on improving pair-wise similarities within existing images input output transductively while lacking flexibility to learn representations for novel unseen instances inductively; 3) they fail to scale to large datasets due to prohibitive memory consumption and computational burden due to intrinsic high-order operations on the whole graph. In this paper, to address these limitations, we propose a novel method, Graph Diffusion Networks (GRAD-Net), that adopts graph neural networks (GNNs), a novel variant of deep learning algorithms on irregular graphs. GRAD-Net learns semantic representations by exploiting both local and global structures of image manifold in an unsupervised fashion. By utilizing sparse coding techniques, GRAD-Net not only preserves global information on the image manifold, but also enables scalable training and efficient querying. Experiments on several large benchmark datasets demonstrate effectiveness of our method over state-of-the-art diffusion algorithms for unsupervised image retrieval."
"Alejandro Ungr'ia Hirte, Moritz Platscher, T. Joyce, J. Heit, E. Tranvinh, C. Federau",9f87d4b03d3b73e8e7e93f69fdf044f0401d4f25,Diffusion-Weighted Magnetic Resonance Brain Images Generation with Generative Adversarial Networks and Variational Autoencoders: A Comparison Study,ArXiv,2020,4,"We show that high quality, diverse and realistic-looking diffusion-weighted magnetic resonance images can be synthesized using deep generative models. Based on professional neuroradiologists' evaluations and diverse metrics with respect to quality and diversity of the generated synthetic brain images, we present two networks, the Introspective Variational Autoencoder and the Style-Based GAN, that qualify for data augmentation in the medical field, where information is saved in a dispatched and inhomogeneous way and access to it is in many aspects restricted."
"D. Karimi, L. Vasung, C. Jaimes, F. Machado-Rivas, Shadab Khan, S. Warfield, A. Gholipour",926b18720a105844c4158060c86dd34789ff3140,A machine learning-based method for estimating the number and orientations of major fascicles in diffusion-weighted magnetic resonance imaging,Medical Image Anal.,2020,4,
"Ikram Jumakulyyev, T. Schultz",478adf5bc85fca756c3230998894ef441ebc5d3c,Fourth-Order Anisotropic Diffusion for Inpainting and Image Compression,ArXiv,2020,4,
"Francis J. Chung, Ru-Yu Lai, Qin Li",44ab1c56ee4f123ed94ee0c8fb9ec0c3478fdfc9,On diffusive scaling in acousto-optic imaging,Inverse Problems,2020,4,"Acousto-optic imaging (AOI) is a hybrid imaging process. By perturbing the to-be-reconstructed tissues with acoustic waves, one introduces the interaction between the acoustic and optical waves, leading to a more stable reconstruction of the optical properties. The mathematical model was described in [], with the radiative transfer equation serving as the forward model for the optical transport. In this paper we investigate the stability of the reconstruction. In particular, we are interested in how the stability depends on the Knudsen number, Kn, a quantity that measures the intensity of the scattering effect of photon particles in a media. Our analysis shows that as Kn decreases to zero, photons scatter more frequently, and since information is lost, the reconstruction becomes harder. To counter this effect, devices need to be constructed so that laser beam is highly concentrated. We will give a quantitative error bound, and explicitly show that such concentration has an exponential dependence on Kn. Numerical evidence will be provided to verify the proof."
"I. Grigorescu, Alena Uus, D. Christiaens, L. Cordero-Grande, J. Hutter, A. Edwards, J. Hajnal, M. Modat, M. Deprez",af97776206e01c5310469ea0f059911c471229b8,Diffusion Tensor Driven Image Registration: A Deep Learning Approach,Workshop on Biomedical Image Registration,2020,3,
"Yunzhe Li, Gregory N. McKay, N. Durr, L. Tian",95fad35749147f1437157cff403ea0f24e53dc57,Diffuser-based computational imaging funduscope.,Optics Express,2020,3,"Poor access to eye care is a major global challenge that could be ameliorated by low-cost, portable, and easy-to-use diagnostic technologies. Diffuser-based imaging has the potential to enable inexpensive, compact optical systems that can reconstruct a focused image of an object over a range of defocus errors. Here, we present a diffuser-based computational funduscope that reconstructs important clinical features of a model eye. Compared to existing diffuser-imager architectures, our system features an infinite-conjugate design by relaying the ocular lens onto the diffuser. This offers shift-invariance across a wide field-of-view (FOV) and an invariant magnification across an extended depth range. Experimentally, we demonstrate fundus image reconstruction over a 33° FOV and robustness to ±4D refractive error using a constant point-spread-function. Combined with diffuser-based wavefront sensing, this technology could enable combined ocular aberrometry and funduscopic screening through a single diffuser sensor."
"Mengqi Xu, W. Rogers, W. Ahmed, J. Ross",82271138a61efa77b1953d576d4b47fe722fb5f0,Comparison of different approaches to single-molecule imaging of enhanced enzyme diffusion,,2020,2,"Enzymes have been shown to diffuse faster in the presence of their reactants. Recently, we revealed new insights into this process of enhanced diffusion using single-particle tracking (SPT) with total internal reflection fluorescence (TIRF) microscopy. We found that the mobility of individual enzymes was enhanced three fold in the presence of the substrate, and the motion remained Brownian. In this work, we compare different experimental designs, as well as different data analysis approaches, for studying single enzyme diffusion. We first tether enzymes directly on supported lipid bilayers (SLBs) to constrain the diffusion of enzymes to two dimensions. This experimental design recovers the 3-fold enhancement in enzyme diffusion in the presence of the substrate, as we observed before. We also simplify our system by replacing the bulky polymers used in the prior chamber design with a SLB-coated surface and glycerol. Using this newly-designed SLB/glycerol chamber, we compare two different analysis approaches for SPT: the mean-squared displacement (MSD) analysis and the jump-length analysis. We find that the MSD analysis requires high viscosity and large particles to accurately report the diffusion coefficient, while jump-length analysis depends less on the viscosity or size. Furthermore, the SLB-glycerol chamber fails to reproduce the enhanced diffusion of enzymes because glycerol inhibits enzyme activity."
"Ashirbani Saha, Pantea Fadaiefard, J. Rabski, Alireza Sadeghian, M. Cusimano",8ef9e16ee98b76393522c5e8e83ef35c316f48d2,Machine learning applications using diffusion tensor imaging of human brain: A PubMed literature review,ArXiv,2020,2,"We performed a PubMed search to find 148 papers published between January 2010 and December 2019 related to human brain, Diffusion Tensor Imaging (DTI), and Machine Learning (ML). The studies focused on healthy cohorts (n = 15), mental health disorders (n = 25), tumor (n = 19), trauma (n = 5), dementia (n = 24), developmental disorders (n = 5), movement disorders (n = 9), other neurological disorders (n = 27), miscellaneous non-neurological disorders, or without stating the disease of focus (n = 7), and multiple combinations of the aforementioned categories (n = 12). Classification of patients using information from DTI stands out to be the most commonly (n = 114) performed ML application. A significant number (n = 93) of studies used support vector machines (SVM) as the preferred choice of ML model for classification. A significant portion (31/44) of publications in the recent years (2018-2019) continued to use SVM, support vector regression, and random forest which are a part of traditional ML. Though many types of applications across various health conditions (including healthy) were conducted, majority of the studies were based on small cohorts (less than 100) and did not conduct independent/external validation on test sets."
"Jardel Vieira, E. Abreu, J. Florindo",178780707ab15cc7b7d1d693d1f72507b392a434,Texture image classification based on a pseudo-parabolic diffusion model,Multimedia tools and applications,2020,2,
James M. Murphy,2c0ebc9ae3c3749d5dbf08b01c61290c74c7534b,Patch-Based Diffusion Learning for Hyperspectral Image Clustering,IEEE International Geoscience and Remote Sensing Symposium,2020,1,"An algorithm for clustering hyperspectral images (HSI) based on diffusion geometry in the space of high-dimensional image patches is proposed. By using the patch structure of the HSI, robustness to noise is achieved in the clustering process. Results on real hyperspectral data indicate the effectiveness of working in the space of HSI patches, compared to working in the space of HSI pixels."
"L. Brusch, Y. Kalaidzidis, Kirstin Meyer, I. Sbalzarini, Marino Zerial Zih at Technische Universitat Dresden, Max Planck Institute of Molecular Cell Biology, Genetics Dresden, Ucsf Cardiovascular Research Institute, Chair of Scientific Computing for Systems Biology at Fac Dresden, Center for Systems Biology Dresden, Cluster of Excellence Physics of Life Dresden",691d14bcab2ed8bf41d933b1c8b5d9ff3ba5e539,Letter to the Editor and Comments on: Intravital dynamic and correlative imaging reveals diffusion-dominated canalicular and flow-augmented ductular bile flux,,2020,1,"1 Center for Information Services and High Performance Computing, Technische Universität Dresden, 01062 Dresden, Saxony, Germany 2) Max Planck Institute of Molecular Cell Biology and Genetics, 01307 Dresden, Saxony, Germany 3) UCSF, Cardiovascular Research Institute, Department of Biochemistry and Biophysics, California, USA 4) Chair of Scientific Computing for Systems Biology, Faculty of Computer Science, Technische Universität Dresden, 01187 Dresden, Saxony, Germany 5) Center for Systems Biology Dresden, 01307 Dresden, Saxony, Germany 6) Cluster of Excellence Physics of Life, Technische Universität Dresden, 01187 Dresden, Saxony, Germany"
"Wei-Tang Chang, Khoi Minh Huynh, P. Yap, Weili Lin",e0cc49dd086826b3d119be0db88598e7cae77056,Navigator-Free Submillimeter Diffusion Imaging Using Multishot-Encoded Simultaneous Multi-Slice (MUSIUM),,2020,1,"
 The ability to achieve submillimter isotropic resolution diffusion MR imaging (dMRI) is critically important to study fine-scale brain structures. One of the major challenges in submillimeter dMRI is the inherently low signal-to-noise ratio (SNR). While approaches capable of mitigating the low SNR have been proposed, namely simultaneous multi-slab (SMSlab) and generalized slice dithered enhanced resolution with simultaneous multislice (gSlider-SMS), limitations are associated with these approaches. The SMSlab sequences suffer from the slab boundary artifacts and require additional navigators for phase estimation. On the other hand, gSlider sequences require relatively high RF power and peak amplitude, which increase the SAR and complicate the RF excitation. In this work, we developed a navigator-free multishot-encoded simultaneous multi-slice (MUSIUM) imaging approach, achieving enhanced SNR, low RF power and peak amplitude, and being free from slab boundary artifacts. The dMRI with ultrahigh resolution (0.86 mm isotropic), whole brain coverage and ~12.5 minute acquisition time were achieved, revealing detailed structures at cortical and white matter areas. The simulated and in vivo results also demonstrated that the MUSIUM imaging was minimally affected by the motion. Taken together, the MUSIUM imaging is a promising approach to achieve submillimeter diffusion imaging on 3T scanner within clinically feasible scan time."
"Xin Jin, Xiqiao Li, Heng Huang, Xiaodong Li, Xinghui Zhou",e22109121ffaca47628f70a3e305b57f8fbf16df,A Deep Drift-Diffusion Model for Image Aesthetic Score Distribution Prediction,2022 IEEE International Conference on Multimedia and Expo Workshops (ICMEW),2020,1,"The task of aesthetic quality assessment is complicated due to its subjectivity. In recent years, the target representation of image aesthetic quality has changed from a one-dimensional binary classification label or numerical score to a multi-dimensional score distribution. According to current methods, the ground truth score distributions are straightforwardly regressed. However, the subjectivity of aesthetics is not taken into account, that is to say, the psychological processes of human beings are not taken into consideration, which limits the performance of the task. In this paper, we propose a Deep Drift-Diffusion (DDD) model inspired by psychologists to predict aesthetic score distribution from images. The DDD model can describe the psychological process of aesthetic perception instead of traditional modelling of the results of assessment. We use deep convolution neural networks to regress the parameters of the drift-diffusion model. The experimental results in large scale aesthetic image datasets reveal that our novel DDD model is simple but efficient, which outperforms the state-of-the-art methods in aesthetic score distribution prediction. Besides, different psychological processes can also be predicted by our model. Our work applies drift-diffusion psychological model into score distribution prediction of visual aesthetics, and has the potential of inspiring more attentions to model the psychology process of aesthetic perception."
"Ruining Deng, Quan Liu, S. Bao, Aadarsh Jha, Catie Chang, Bryan A. Millis, M. Tyska, Yuankai Huo",4d125f7c9371cfd90fbeef826343f45905658d82,CaCL: Class-aware Codebook Learning for Weakly Supervised Segmentation on Diffuse Image Patterns,DGM4MICCAI/DALI@MICCAI,2020,0,
M. Chung,acce5b67aad854fb458091cb36cc08bce16207bb,Diffusion Equations for Medical Images,,2020,0,"In brain imaging, the image acquisition and processing processes themselves are likely to introduce noise to the images. It is therefore imperative to reduce the noise while preserving the geometric details of the anatomical structures for various applications. Traditionally Gaussian kernel smoothing has been often used in brain image processing and analysis. However, the direct application of Gaussian kernel smoothing tend to cause various numerical issues in irregular domains with boundaries. For example, if one uses large bandwidth in kernel smoothing in a cortical bounded region, the smoothing will blur signals across boundaries. So in kernel smoothing and regression literature, various ad-hoc procedures were introduce to remedy the boundary effect. Motivated by Perona & Malik (1990), diffusion equations have been widely used in brain imaging as a form of noise reduction. The most natural straightforward way to smooth images in irregular domains with boundaries is to formulate the problem as boundary value problems using partial differential equations. Numerous diffusion-based techniques have been developed in image processing (Sochen et al. 1998, Malladi & Ravve 2002, Tang et al. 1999, Taubin 2000, Andrade et al. 2001, Chung et al. 2001, Chung, Worsley, Robbins, Paus, Taylor, Giedd, Rapoport & Evans 2003, Chung, Robbins & Evans 2005, Chung & Taylor 2004, Cachia, Mangin, Riviére, Papadopoulos-Orfanos, Kherif, Bloch & Régis 2003, Cachia, Mangin, Riviére, Kherif, Boddaert, Andrade, PapadopoulosOrfanos, Poline, Bloch, Zilbovicius, Sonigo, Brunelle & Régis 2003, Joshi et al. 2009). In this paper, we will overview the basics of isotropic diffusion equations and explain how to solve them on regular grids and irregular grids such as graphs."
M. Tamal,0eb60c1268a74e58c02a3291daddb44f9af4692e,Positron Emission Tomography (PET) image enhancement using a gradient vector orientation based nonlinear diffusion filter (GVOF) for accurate quantitation of radioactivity concentration,ArXiv,2020,0,"To accurately quantify in vivo radiotracer uptake using Positron Emission Tomography (PET) is a challenging task due to low signal-to-noise ratio (SNR) and poor spatial resolution of PET camera along with the finite image sampling constraint. Furthermore, inter lesion variations of the SNR and contrast along with the variations in size of the lesion make the quantitation even more difficult. One of the ways to improve the quantitation is via post reconstruction filtering with Gaussian Filter (GF). Edge preserving Bilateral Filter (BF) and Nonlinear Diffusion Filter (NDF) are the alternatives to GF that can improve the SNR without degrading the image resolution. However, the performance of these edge preserving methods are only optimum for high count and low noise cases. A novel parameter free gradient vector orientation based nonlinear diffusion filter (GVOF) is proposed in this paper that is insensitive to statistical fluctuations (e. g., SNR, contrast, size etc.). GVOF method applied on the PET images collected with the NEMA phantom with varying levels of contrast and noise reveals that the GVOF method provides the highest SNR, CNR (contrast-to-noise ratio) and resolution compared to the original and other filtered images. The percentage bias in estimating the maximum activity representing SUVmax (Maximum Standardized Uptake Value) for the spheres with diameter > 2cm where the partial volume effects (PVE) is negligible is the lowest for the GVOF method. The GVOF method also improves the maximum intensity reproducibility. Robustness of the GVOF against variation in sizes, contrast levels and SNR makes it a suitable post filtering method for both accurate diagnosis and response assessment. Furthermore, its capability to provide accurate quantitative measurements irrespective of the SNR, it can also be effective in reduction of radioactivity dose."
"M. Palombo, A. Ianuş, Michele Guerreri, Daniel Nunes, D. Alexander, N. Shemesh, Hui Zhang",d5d6e028938e510acc437b8e73afe11ef1b2681d,SANDI: A compartment-based model for non-invasive apparent soma and neurite imaging by diffusion MRI,NeuroImage,2019,116,
"Haiyi Wu, Wen-Zhen Fang, Q. Kang, W. Tao, Rui Qiao",ccb2dd19d2ebb81933df1cacf9c2c250ed1e34ff,Predicting Effective Diffusivity of Porous Media from Images by Deep Learning,Scientific Reports,2019,82,
"Lizhen Deng, Hu Zhu, Zhen Yang, Yujie Li",c537f6b0bee5fe82d82fc1ad6ebdb188570c239b,Hessian matrix-based fourth-order anisotropic diffusion filter for image denoising,Optics and Laser Technology,2019,32,
"Brian H. Wang, Wei-Lun Chao, Yan Wang, B. Hariharan, Kilian Q. Weinberger, M. Campbell",fbf393b537b87bde29857c34e7bc5f02ed60b32f,LDLS: 3-D Object Segmentation Through Label Diffusion From 2-D Images,IEEE Robotics and Automation Letters,2019,23,"Object segmentation in three-dimensional (3-D) point clouds is a critical task for robots capable of 3-D perception. Despite the impressive performance of deep learning-based approaches on object segmentation in 2-D images, deep learning has not been applied nearly as successfully for 3-D point cloud segmentation. Deep networks generally require large amounts of labeled training data, which are readily available for 2-D images but are difficult to produce for 3-D point clouds. In this letter, we present Label Diffusion Lidar Segmentation (LDLS), a novel approach for 3-D point cloud segmentation, which leverages 2-D segmentation of an RGB image from an aligned camera to avoid the need for training on annotated 3-D data. We obtain 2-D segmentation predictions by applying Mask-RCNN to the RGB image, and then link this image to a 3-D lidar point cloud by building a graph of connections among 3-D points and 2-D pixels. This graph then directs a semi-supervised label diffusion process, where the 2-D pixels act as source nodes that diffuse object label information through the 3-D point cloud, resulting in a complete 3-D point cloud segmentation. We conduct empirical studies on the KITTI benchmark dataset and on a mobile robot, demonstrating wide applicability and superior performance of LDLS compared with the previous state of the art in 3-D point cloud segmentation, without any need for either 3-D training data or fine tuning of the 2-D image segmentation model."
"James M. Murphy, M. Maggioni",698f813d2cb2fbe92e160b76e83bd10583534fdc,Spectral–Spatial Diffusion Geometry for Hyperspectral Image Clustering,IEEE Geoscience and Remote Sensing Letters,2019,20,"An unsupervised learning algorithm to cluster hyperspectral image (HSI) data that leverages spatially regularized random walks is proposed. Markov diffusions are defined on the space of HSI spectra with transitions constrained to near spatial neighbors. The explicit incorporation of spatial regularity into the diffusion construction leads to smoother random processes that are more adapted for unsupervised machine learning than those based on spectra alone. The regularized diffusion process is subsequently used to embed the high-dimensional HSI into a lower-dimensional space through diffusion distances. Cluster modes are computed using kernel density estimation and diffusion distances, and all other points are labeled according to these modes. The proposed method has low computational complexity and performs competitively against state-of-the-art HSI clustering algorithms on real data. In particular, the proposed spatial regularization confers both theoretical and empirical advantages over nonregularized methods."
"S. Bai, Zhichao Zhou, Jingdong Wang, X. Bai, Longin Jan Latecki, Q. Tian",17413380c1f45b5243f875e7c9bcfe1b486d59af,Automatic Ensemble Diffusion for 3D Shape and Image Retrieval,IEEE Transactions on Image Processing,2019,18,"As a post-processing procedure, the diffusion process has demonstrated its ability of substantially improving the performance of various visual retrieval systems. Whereas, great efforts are also devoted to similarity (or metric) fusion, seeing that only one individual type of similarity cannot fully reveal the intrinsic relationship between objects. This stimulates a great research interest of considering similarity fusion in the framework of the diffusion process (i.e., fusion with diffusion) for robust retrieval. In this paper, we first revisit representative methods about fusion with diffusion and provide new insights which are ignored by previous researchers. Then, observing that existing algorithms are susceptible to noisy similarities, the proposed regularized ensemble diffusion (RED) is bundled with an automatic weight learning paradigm, so that the negative impacts of noisy similarities are suppressed. Though formulated as a convex optimization problem, one advantage of RED is that it converts back into the iteration-based solver with the same computational complexity as the conventional diffusion process. At last, we integrate several recently-proposed similarities with the proposed framework. The experimental results suggest that we can achieve new state-of-the-art performances on various retrieval tasks, including 3D shape retrieval on the ModelNet data set, and image retrieval on the Holidays and Ukbench data sets."
"Z. R. Samani, Jacob A. Alappatt, D. Parker, A. A. O. Ismail, R. Verma",b93777b59da3c81689e46d42b5877c27814ea47b,QC-Automator: Deep Learning-Based Automated Quality Control for Diffusion MR Images,Frontiers in Neuroscience,2019,16,"Quality assessment of diffusion MRI (dMRI) data is essential prior to any analysis, so that appropriate pre-processing can be used to improve data quality and ensure that the presence of MRI artifacts do not affect the results of subsequent image analysis. Manual quality assessment of the data is subjective, possibly error-prone, and infeasible, especially considering the growing number of consortium-like studies, underlining the need for automation of the process. In this paper, we have developed a deep-learning-based automated quality control (QC) tool, QC-Automator, for dMRI data, that can handle a variety of artifacts such as motion, multiband interleaving, ghosting, susceptibility, herringbone, and chemical shifts. QC-Automator uses convolutional neural networks along with transfer learning to train the automated artifact detection on a labeled dataset of ∼332,000 slices of dMRI data, from 155 unique subjects and 5 scanners with different dMRI acquisitions, achieving a 98% accuracy in detecting artifacts. The method is fast and paves the way for efficient and effective artifact detection in large datasets. It is also demonstrated to be replicable on other datasets with different acquisition parameters."
"M. Mani, M. Jacob, G. Mckinnon, Baolian Yang, B. Rutt, A. Kerr, V. Magnotta",8087ea15b9ba3d3e0dff2a106ef49d9c37fa2bcf,SMS MUSSELS: A navigator‐free reconstruction for simultaneous multi‐slice‐accelerated multi‐shot diffusion weighted imaging,Magnetic Resonance in Medicine,2019,14,To introduce a novel reconstruction method for simultaneous multi‐slice (SMS)‐accelerated multi‐shot diffusion weighted imaging (ms‐DWI).
"W. Panyarak, T. Chikui, Y. Yamashita, T. Kamitani, K. Yoshiura",17179b43f6f958bca60a9fdb8e4e857c37997141,Image Quality and ADC Assessment in Turbo Spin-Echo and Echo-Planar Diffusion-Weighted MR Imaging of Tumors of the Head and Neck.,Academic Radiology,2019,12,
"H. An, Xiaodong Ma, Ziyi Pan, Hua Guo, E. Lee",2f39c00a1d718b9495b219d836007f223c86da33,Qualitative and quantitative comparison of image quality between single-shot echo-planar and interleaved multi-shot echo-planar diffusion-weighted imaging in female pelvis,European Radiology,2019,10,
James M. Murphy,35ddfdfcc8f780390bed9cc61c0a3a6dfcbb95b0,Spatially regularized active diffusion learning for high-dimensional images,Pattern Recognition Letters,2019,9,
"Federico Magliani, Laura Sani, S. Cagnoni, A. Prati",cd7b7957f90bc0e21d1b29ccd6fe64b4a16a1df4,Genetic Algorithms for the Optimization of Diffusion Parameters in Content-Based Image Retrieval,ACM/IEEE International Conference on Distributed Smart Cameras,2019,9,"Several computer vision and artificial intelligence projects are nowadays exploiting the manifold data distribution using, e.g., the diffusion process. This approach has produced dramatic improvements on the final performance thanks to the application of such algorithms to the kNN graph. Unfortunately, this recent technique needs a manual configuration of several parameters, thus it is not straightforward to find the best configuration for each dataset. Moreover, the brute-force approach is computationally very demanding when used to optimally set the parameters of the diffusion approach. We propose to use genetic algorithms to find the optimal setting of all the diffusion parameters with respect to retrieval performance for each different dataset. Our approach is faster than others used as references (brute-force, random-search and PSO). A comparison with these methods has been made on three public image datasets: Oxford5k, Paris6k and Oxford105k."
"Noel M. Naughton, J. Georgiadis",8abb6c013b45aca78399f8163d2cde0469399f8d,Lattice Boltzmann method for simulation of diffusion magnetic resonance imaging physics in heterogeneous tissue models,ArXiv,2019,9,"We report the first implementation of the Lattice Boltzmann method (LBM) to integrate the Bloch-Torrey equation, which describes the evolution of the transverse magnetization vector and the fate of the signal of diffusion magnetic resonance imaging (dMRI). Motivated by the need to interpret dMRI experiments on skeletal muscle, and to offset the small time step limitation of classical LBM, a hybrid LBM scheme is introduced and implemented to solve the Bloch-Torrey equation in a tissue model consisting of cylindrical inclusions (representing bundles of parallel myocytes), delineated by thin permeable membranes (sarcolemma) and surrounded by an extracellular domain (endomysium). As implemented, the hybrid LBM scheme accommodates piece-wise uniform transport, dMRI parameters, periodic outer boundary conditions, and finite membrane permeabilities on non-boundary-conforming inner boundaries. The geometry is discretized in uniform 2D or 3D lattices by locating the curved cylindrical boundaries halfway between lattice nodes. By comparing with analytical solutions of limiting cases, we demonstrate that the hybrid LBM scheme is more accurate than the classical LBM scheme. The proposed explicit LBM scheme maintains second-order spatial accuracy, stability, and first-order temporal accuracy for a wide range of parameters. The parallel implementation of the hybrid LBM code in a multi-CPU computer system with MPI is straightforward. For a domain decomposition algorithm on one million lattice nodes, the speedup is linear up to 168 MPI processes. While offering certain advantages over finite element or Monte Carlo schemes, the proposed hybrid LBM constitutes a sui generis scheme that can be easily adapted to model more complex interfacial conditions and physics in heterogeneous multiphase tissue models and to accommodate sophisticated dMRI sequences."
"A. Sridharan, Nakita K. Noel, H. Hwang, Soroush Hafezian, B. Rand, St'ephane K'ena-Cohen",1206b93800152c346e5035c112869839182a4157,Time-resolved imaging of non-diffusive carrier transport in long-lifetime halide perovskite thin films.,,2019,9,"Owing to their exceptional semiconducting properties, hybrid inorganic-organic perovskites show great promise as photovoltaic absorbers. In these materials, long-range diffusion of charge carriers allows for most of the photogenerated carriers to contribute to the photovoltaic efficiency. Here, time-resolved photoluminescence (PL) microscopy is used to directly probe ambipolar carrier diffusion and recombination kinetics in hybrid perovskites. This technique is applied to thin films of methylammonium lead tri-iodide MAPbI$_3$ obtained with two different fabrication routes, methylammonium lead tribromide (MAPbBr$_3$), and an alloy of formamidinium lead tri-iodide (FAPbI$_3$) and methylammonium lead bromide FA$_{0.85}$MA$_{0.15}$Pb(I$_{0.85}$Br_${0.15}$)$_3$. Average diffusion coefficients in the films leading to the highest device efficiencies and longest lifetimes, i.e., in FA$_{0.85}$MA$_{0.15}$Pb(I$_{0.85}$Br$_{0.15}$)$_3$ and acetonitrile-processed MAPbI$_3$, are found to be several orders of magnitude lower than in the other films. Further examination of the time-dependence shows strong evidence for non-diffusive transport. In particular, acetonitrile-processed MAPbI$_3$ shows distinct diffusion regimes on short and long timescales with an effective diffusion constant varying over 2 orders of magnitude. Our results also highlight the fact that increases in carrier lifetime in this class of materials are not necessarily concomitant with increased diffusion lengths and that the PL quantum efficiency under solar cell operating conditions is a greater indication of material, and ultimately device, quality."
"Federico Magliani, Kevin McGuinness, Eva Mohedano, A. Prati",82fdd4327384d92df2b20d203c3219c919ac1aa1,An Efficient Approximate kNN Graph Method for Diffusion on Image Retrieval,International Conference on Image Analysis and Processing,2019,6,
"Yifeng Fan, Zhizhen Zhao",5acfbeb4dc2df20e609ed7d6938bcabd5f3062a3,Cryo-Electron Microscopy Image Analysis Using Multi-Frequency Vector Diffusion Maps,ArXiv,2019,6,"Cryo-electron microscopy (EM) single particle reconstruction is an entirely general technique for 3D structure determination of macromolecular complexes. However, because the images are taken at low electron dose, it is extremely hard to visualize the individual particle with low contrast and high noise level. In this paper, we propose a novel approach called multi-frequency vector diffusion maps (MFVDM) to improve the efficiency and accuracy of cryo-EM 2D image classification and denoising. This framework incorporates different irreducible representations of the estimated alignment between similar images. In addition, we propose a graph filtering scheme to denoise the images using the eigenvalues and eigenvectors of the MFVDM matrices. Through both simulated and publicly available real data, we demonstrate that our proposed method is efficient and robust to noise compared with the state-of-the-art cryo-EM 2D class averaging and image restoration algorithms."
"Haifeng Dong, Jing-Ling Chen, Ji-min Li, Chen Liu, Ai-xian Li, Nan Zhao, F. Guo",5b8010d75d2dffa1b64e274c15dc9b6bce399265,Spin image of an atomic vapor cell with a resolution smaller than the diffusion crosstalk free distance,Journal of Applied Physics,2019,5,"The diffusion crosstalk free distance is an important parameter for spin images in atomic vapor cells and is also regarded as a limit on the spatial resolution. However, by modulating the pumping light both spatially and temporally using a digital micromirror device, a spin image of a vapor cell has been obtained with a distinguishable stripe width of 13.7  μm, which is much smaller than the corresponding diffusion crosstalk free distance of ∼138  μm. The fundamental limit on the spatial resolution as determined by diffusion and the uncertainty principle is analyzed.The diffusion crosstalk free distance is an important parameter for spin images in atomic vapor cells and is also regarded as a limit on the spatial resolution. However, by modulating the pumping light both spatially and temporally using a digital micromirror device, a spin image of a vapor cell has been obtained with a distinguishable stripe width of 13.7  μm, which is much smaller than the corresponding diffusion crosstalk free distance of ∼138  μm. The fundamental limit on the spatial resolution as determined by diffusion and the uncertainty principle is analyzed."
"Zhou Lan, B. Reich, J. Guinness, D. Bandyopadhyay, Liangsuo Ma, F. Moeller",cb62b6aafdc989b863501653d1ad5d4d8e2be260,Geostatistical modeling of positive‐definite matrices: An application to diffusion tensor imaging,Biometrics,2019,4,"Geostatistical modeling for continuous point‐referenced data has extensively been applied to neuroimaging because it produces efficient and valid statistical inference. However, diffusion tensor imaging (DTI), a neuroimaging technique characterizing the brain's anatomical structure, produces a positive‐definite (p.d.) matrix for each voxel. Currently, only a few geostatistical models for p.d. matrices have been proposed because introducing spatial dependence among p.d. matrices properly is challenging. In this paper, we use the spatial Wishart process, a spatial stochastic process (random field), where each p.d. matrix‐variate random variable marginally follows a Wishart distribution, and spatial dependence between random matrices is induced by latent Gaussian processes. This process is valid on an uncountable collection of spatial locations and is almost‐surely continuous, leading to a reasonable way of modeling spatial dependence. Motivated by a DTI data set of cocaine users, we propose a spatial matrix‐variate regression model based on the spatial Wishart process. A problematic issue is that the spatial Wishart process has no closed‐form density function. Hence, we propose an approximation method to obtain a feasible Cholesky decomposition model, which we show to be asymptotically equivalent to the spatial Wishart process model. A local likelihood approximation method is also applied to achieve fast computation. The simulation studies and real data application demonstrate that the Cholesky decomposition process model produces reliable inference and improved performance, compared to other methods."
"Zhou Lan, B. Reich, D. Bandyopadhyay",48dd02f684de882e0cabd611d72f0c0190f8789b,A spatial Bayesian semiparametric mixture model for positive definite matrices with applications in diffusion tensor imaging,Canadian journal of statistics,2019,4,"Studies on diffusion tensor imaging (DTI) quantify the diffusion of water molecules in a brain voxel using an estimated 3 × 3 symmetric positive definite (p.d.) diffusion tensor matrix. Due to the challenges associated with modelling matrix‐variate responses, the voxel‐level DTI data are usually summarized by univariate quantities, such as fractional anisotropy. This approach leads to evident loss of information. Furthermore, DTI analyses often ignore the spatial association among neighbouring voxels, leading to imprecise estimates. Although the spatial modelling literature is rich, modelling spatially dependent p.d. matrices is challenging. To mitigate these issues, we propose a matrix‐variate Bayesian semiparametric mixture model, where the p.d. matrices are distributed as a mixture of inverse Wishart distributions, with the spatial dependence captured by a Markov model for the mixture component labels. Related Bayesian computing is facilitated by conjugacy results and use of the double Metropolis–Hastings algorithm. Our simulation study shows that the proposed method is more powerful than competing non‐spatial methods. We also apply our method to investigate the effect of cocaine use on brain microstructure. By extending spatial statistics to matrix‐variate data, we contribute to providing a novel and computationally tractable inferential tool for DTI analysis."
"S. Alotaibi, W. Smith",7f1ea86df8d7e6af8df8c0003d3388b5f733832e,Decomposing Multispectral Face Images into Diffuse and Specular Shading and Biophysical Parameters,International Conference on Information Photonics,2019,4,We propose a novel biophysical and dichromatic reflectance model that efficiently characterises spectral skin reflectance. We show how to fit the model to multispectral face images enabling high quality estimation of diffuse and specular shading as well as biophysical parameter maps (melanin and haemoglobin). Our method works from a single image without requiring complex controlled lighting setups yet provides quantitatively accurate reconstructions and qualitatively convincing decomposition and editing.
J. C. Mihos,21bb2972184c13cf722015f22ab0b89a7cd62089,Deep Imaging of Diffuse Light Around Galaxies and Clusters: Progress and Challenges,,2019,3,"Over the past several decades, advances in telescope/detector technologies and deep imaging techniques have pushed surface brightness limits to ever fainter levels. We can now both detect and measure the diffuse, extended star light that surrounds galaxies and permeates galaxy clusters, enabling the study of galaxy halos, tidal streams, diffuse galaxy populations, and the assembly history of galaxies and galaxy clusters. With successes come new challenges, however, and pushing even deeper will require careful attention to systematic sources of error. In this review I highlight recent advances in the study of diffuse starlight in galaxies, and discuss challenges faced by the next generation of deep imaging campaigns."
"Subi Jain, Sudeb Majee, R. K. Ray, A. Majee",1218b78dee185e2cbe0a3d4d9511deaa9b0b517e,Analysis and Simulation of a Coupled Diffusion based Image Denoising Model,ArXiv,2019,3,"In this study, a new coupled Partial Differential Equation (CPDE) based image denoising model incorporating space-time regularization into non-linear diffusion is proposed. This proposed model is fitted with additive Gaussian noise which performs efficient image smoothing along with the preservation of edges and fine structures. For this purpose, we propose a new functional minimization framework to remove the image noise, which results in solving a system of three partial differential equations (PDEs). Our proposed model is dissimilar from the existing CPDE models as it includes two additional evolution equations to handle edge strength function and data fidelity term. These two evolution equations control the smoothing process and force the resultant denoised solution to be close to the initial solution. To the best of our knowledge, the proposed model is the only work, which deciphers the combined effect of both the terms using separate PDEs. Furthermore, we establish the existence and uniqueness of a weak solution of the proposed system using the time discretization method with $H^1$ initial data. Finally, we used a generalized weighted average finite difference scheme to efficiently solve the coupled system and experiment results show the effectiveness of the proposed CPDE model."
"Zhiri Tang, Yanhua Chen, Ruihan Hu, R. Zhu, Hao Wang, Jin He, Q. Huang, Sheng Chang",06b9d29c762ac5436b3024911e0576be6bea6b06,Fully Memristive Neural Network Merging Image Preprocessing and Pattern Recognition,ArXiv,2019,3,"With the development of research on novel memristor model and device, fully memristive neural networks have become a hot research topic recently. However, some other devices besides memristors are still needed in state-of-the-art works about fully memristive neural networks. In this paper, a novel kind of fully memristive neural network is introduced, in which diffusion and drift memristor models are applied to construct neural network for both image preprocessing and pattern recognition, respectively. Specifically, the entire network consists of two diffusion memristive cellular layers and one drift memristive feedforward layer. Experimental results show that a good recognition accuracy of noisy MNIST is obtained due to the fusion of image preprocessing and pattern recognition. Moreover, owing to high-efficiency in-memory computing and brief spiking encoding methods, high processing speed and few hardware resources of the entire network are achieved."
"M. Mani, H. Aggarwal, V. Magnotta, M. Jacob",531fe7e458065b6f5fd0d4524c0ca64e63790307,Improved Reconstruction for high-resolution Multi-shot Diffusion Weighted Imaging.,,2019,2,"Purpose: To introduce a fast and improved direct reconstruction method for multi-shot diffusion weighted (msDW) scans for high-resolution studies. 
Methods:Multi-shot EPI methods can enable higher spatial resolution for diffusion MRI studies. Traditionally, such acquisitions required specialized reconstructions involving phase compensation to correct for inter-shot motion artifacts. The recently proposed MUSSELS reconstruction belongs to a new class of parallel imaging-based methods that recover artifact-free DWIs from msDW data without needing phase compensation. However, computational demands of the MUSSELS reconstruction scales as the matrix size and the number of shots increases, which hinders its practical utility for high-resolution applications. In this work, we propose a computationally efficient formulation using iterative reweighted least squares (IRLS) method. The new formulation is not only fast but it enables to accommodate additional priors such as conjugate symmetry property of the k-space data to improve the reconstruction. Using whole-brain in-vivo data, we show the utility of the new formulation for routine high-resolution studies with minimal computational burden. 
Results: The IRLS formulation provides about six times faster reconstruction for matrix sizes 192x192 and 256x256, compared to the original implementations. The reconstruction quality is improved by the addition of conjugate symmetry priors that reduce blurring and preserves the high-resolution details from partial Fourier acquisitions. 
Conclusion: The proposed method is shown to be computationally efficient to enable routine high-resolution studies. The computational complexity matches the traditional msDWI reconstruction methods and provides improved reconstruction results."
Feng-Yu Wang,94fc419e0f738c3dcadaf8414881ce910526c363,Diffusions and PDEs on Wasserstein Space,,2019,2,"We propose a new type SDE, whose coefficients depend on the image of solutions, to investigate the diffusion process on the Wasserstein space $\mathcal P_2$ over $\mathbb R^d$, generated by the following time-dependent differential operator for $f\in C_b^2(\mathcal P_2)$: \begin{equation*} \begin{split}& \mathcal A_t f (\mu):= \ \frac 1 2\int_{\mathbb R^d\times \mathbb R^d} \big\langle \sigma (t,x,\mu)\sigma(t,y,\mu)^*, D^2 f(\mu)(x,y)\big\rangle \mu(d x)\mu(d y) \\ & + \int_{\mathbb R^d} \Big(\frac 1 2 \big\langle (\sigma\sigma^*)(t,x,\mu), \nabla\{Df(\mu)\}(x)\big\rangle +\big\langle b(t,x,\mu), Df(\mu)(x)\big\rangle \Big)\mu(d x),\ \mu\in \mathcal P_2, \end{split}\end{equation*} where $\langle \cdot,\cdot\rangle$ is the inner product on $\mathbb R^d$ or $\mathbb R^d\otimes\mathbb R^d$, $\nabla$ is the gradient operator on $\mathbb R^d$, $D$ is the intrinsic (or Lions) derivative on $\mathcal P_2$, and $$b: [0,\infty)\times \mathbb R^d\times\mathcal P_2\to \mathbb R^d,\ \ \sigma: [0,\infty)\times \mathbb R^d\times\mathcal P_2\to \mathbb R^{d}\otimes\mathbb R^m$$ are measurable. 
We study the exponential convergence of the diffusion process, and use the diffusion process to solve the following PDE $$(\partial_t+\mathcal A_t)U (t,\mu) + (V U)(t,\mu) +F(t,\mu)=0,\ \ (t,\mu)\in [0,T]\times \mathcal P_2,$$ where $V$ and $F$ are functions on $[0,T]\times \mathcal P_2.$ Moreover, the structure of the invariant probability measure is described."
"Sudeb Majee, R. K. Ray, A. Majee",463d2f934caa5b592580924b291459b71158dc8a,A Gray Level Indicator-Based Regularized Telegraph Diffusion Equation Applied to Image Despeckling,ArXiv,2019,1,"In this work, a gray level indicator based non-linear telegraph diffusion model is presented for multiplicative noise removal problem. Most of the researchers focus only on diffusion equation-based model for multiplicative noise removal problem. The suggested model uses the benefit of the combined effect of diffusion equation as well as the wave equation. Wave nature of the model preserves the high oscillatory and texture pattern in an image. In this model, the diffusion coefficient depends not only on the image gradient but also on the gray level of the image, which controls the diffusion process better than only gradient-based diffusion models. Moreover, we prove the well-posedness of the present model using Schauder fixed point theorem. Furthermore, we show the superiority of the proposed model over a recently developed method on a set of gray level test images which are corrupted by speckle noise."
"Zeyu Deng, Lihui Wang, Zi-Xiang Kuai, Qijian Chen, Xinyu Cheng, Feng Yang, Jie Yang, Yuemin M. Zhu",26fdce473bfa01902b051484aa8f7d506e70afb1,CNN-Based Invertible Wavelet Scattering for the Investigation of Diffusion Properties of the In Vivo Human Heart in Diffusion Tensor Imaging,ArXiv,2019,0,"In vivo diffusion tensor imaging (DTI) is a promising technique to investigate noninvasively the fiber structures of the in vivo human heart. However, signal loss due to motions remains a persistent problem in in vivo cardiac DTI. We propose a novel motion-compensation method for investigating in vivo myocardium structures in DTI with free-breathing acquisitions. The method is based on an invertible Wavelet Scattering achieved by means of Convolutional Neural Network (WSCNN). It consists of first extracting translation-invariant wavelet scattering features from DW images acquired at different trigger delays and then mapping the fused scattering features into motion-compensated spatial DW images by performing an inverse wavelet scattering transform achieved using CNN. The results on both simulated and acquired in vivo cardiac DW images showed that the proposed WSCNN method effectively compensates for motion-induced signal loss and produces in vivo cardiac DW images with better quality and more coherent fiber structures with respect to existing methods, which makes it an interesting method for measuring correctly the diffusion properties of the in vivo human heart in DTI under free breathing."
"I. Svalbe, D. Paganin, T. Petersen",f13b21f70471bdd3bca11dd5e4e1de785bfe4695,Sharp images from diffuse beams: factorisation of the discrete delta function,,2019,0,"Discrete delta functions define the limits of attainable spatial resolution for all imaging systems. Here we construct broad, multi-dimensional discrete functions that replicate closely the action of a Dirac delta function under aperiodic convolution. These arrays spread the energy of a sharp probe beam to simultaneously sample multiple points across the volume of a large object, without losing image sharpness. A diffuse pointspread function applied in any imaging system can reveal the underlying structure of objects less intrusively and with equal or better signal-to-noise ratio. These multi-dimensional arrays are related to previously known, but relatively rarely employed, onedimensional integer Huffman sequences. Practical point-spread functions can now be made sufficiently large to span the size of the object under measure. Such large arrays can be applied to ghost imaging, which has demonstrated potential to greatly improve signal-to-noise ratios and reduce the total dose required for tomographic imaging. The discrete arrays built here parallel the continuum self-adjoint or Hermitian functions that underpin wave theory and quantum mechanics."
"Sudeb Majee, Subi Jain, R. K. Ray, A. Majee",5d637cd5d25073468d70e34da49345846439aadf,New Coupled Non-linear Telegraph-Diffusion Model for Image Restoration,,2019,0,"In this work, we propose a new telegraph coupled partial differential equation (TCPDE) based model for image restoration. New framework interpolates between a coupled wave equation system and a diffusion equation. This proposed strategy can be applied to significantly preserve the oscillatory and texture pattern in an image, even in low signal-to-noise ratio. First, we prove that the present model has a unique global weak solution using Banach fixed point theorem. Then apply our model over a set of gray-level images to illustrate the superiority of the proposed model over the recently developed hyperbolic-parabolic PDE based models as well as coupled diffusion-based model."
"Henrik G. Jensen, Franccois Lauze, S. Darkner",3bff998e779cccd2abb91dde72fd4d3c28f92927,Information-Theoretic Registration with Explicit Reorientation of Diffusion-Weighted Images,Journal of Mathematical Imaging and Vision,2019,0,
"Wei-Na Li, Zhengyun Zhang, Jianshe Ma, Xiaohao Wang, Ping Su",f82b8260c17bc8c5229776607f13dcd57cb7d07c,Unfocused images removal of z-axis overlapping Mie scattering particles by using three-dimensional nonlinear diffusion based on digital holography,ArXiv,2019,0,"We propose a three-dimensional nonlinear diffusion method to implement the similar autofocusing function of multiple micro-objects and simultaneously remove the defocused images, which can distinguish the locations of certain sized scattering particles that are overlapping along z-axis. It is applied to all of the reconstruction slices that are generated from the captured hologram after each back propagation. For certain small sized particles, the maxima of maximum gradient magnitude of each reconstruction slice appears at the ground truth z position after applying the proposed scheme when the reconstruction range along z-axis is sufficiently long and the reconstruction depth spacing is sufficiently fine. Therefore, the reconstructed image at ground truth z position is remained, while the defocused images are diffused out. The results demonstrated that the proposed scheme can diffuse out the defocused images which are 20 um away from the ground truth z position in spite of that several scattering particles with different diameters are completely overlapping along z-axis with a distance of 800 um when the hologram pixel pitch is 2 um. It also demonstrated that the sparsity distribution of the ground truth z slice cannot be affected by the sparsity distribution of corresponding defocused images when the diameter of the particle is not more than 35um and the reconstruction depth spacing is not less than 20 um."
"A. Arbabi, C. Baron",cbf1036bc53d75d4bcaa8a0dfd0edafddd897f49,Diffusion Dispersion Imaging: Mapping OGSE Frequency Dependence in the Human Brain,,2019,0,"Purpose: Oscillating gradient spin-echo (OGSE) diffusion MRI provides information about the microstructure of biological tissues via the frequency dependence of the apparent diffusion coefficient (ADC). ADC dependence on OGSE frequency has been explored in numerous rodent studies, but applications in the human brain have been limited and have suffered from low contrast between different frequencies, long scan times and a limited exploration of the nature of the ADC dependence on frequency. Methods: Multiple frequency OGSE acquisitions were acquired in healthy subjects at 7 T to explore the power-law frequency dependence of ADC, the ""diffusion dispersion"". Further, a method for optimizing the estimation of the ADC difference between different OGSE frequencies was developed, which enabled the design of a highly efficient protocol for mapping diffusion dispersion. Results: For the first time, evidence of a linear dependence of ADC on the square root of frequency in healthy human white matter was obtained. Using the optimized protocol, high quality, full-brain maps of apparent diffusion dispersion rate were also demonstrated at an isotropic resolution of 2 mm in a scan time of 6 minutes. Conclusion: This work sheds light on the nature of diffusion dispersion in the healthy human brain and introduces full brain diffusion dispersion mapping at clinically relevant scan times. These advances may lead to new biomarkers of pathology or improved microstructural modelling."
"L. Cordero-Grande, D. Christiaens, J. Hutter, A. Price, J. Hajnal",74cd511a18791ec73a38012711f168b22f779c4c,Complex diffusion-weighted image estimation via matrix recovery under general noise models,NeuroImage,2018,131,
"Yuxin Hu, Evan Levine, Q. Tian, C. Moran, Xiaole Wang, V. Taviani, S. Vasanawala, J. McNab, Bruce Daniel, Brian Hargreaves",6183b3cb790bd712f45e6f10033d5320424d4326,Motion‐robust reconstruction of multishot diffusion‐weighted images without phase estimation through locally low‐rank regularization,Magnetic Resonance in Medicine,2018,42,The goal of this work is to propose a motion robust reconstruction method for diffusion‐weighted MRI that resolves shot‐to‐shot phase mismatches without using phase estimation.
"Yang Peng, Zhen Li, Hao Tang, Yanchun Wang, Xuemei Hu, Yaqi Shen, D. Hu",a02be997daf4d76d32f984e7b096b5f6f434e151,Comparison of reduced field‐of‐view diffusion‐weighted imaging (DWI) and conventional DWI techniques in the assessment of rectal carcinoma at 3.0T: Image quality and histological T staging,Journal of Magnetic Resonance Imaging,2018,39,"To compare image quality (IQ) of reduced field‐of‐view (rFOV) and full FOV (fFOV) diffusion‐weighted imaging (DWI) sequences at 3T, with histological T staging of rectal cancer as a reference standard."
"F. Yang, Ryota Hinami, Yusuke Matsui, Steven Ly, S. Satoh",ea8ca0769d139acd318d0007de2b81a1a73d18d3,Efficient Image Retrieval via Decoupling Diffusion into Online and Offline Processing,AAAI Conference on Artificial Intelligence,2018,38,"Diffusion is commonly used as a ranking or re-ranking method in retrieval tasks to achieve higher retrieval performance, and has attracted lots of attention in recent years. A downside to diffusion is that it performs slowly in comparison to the naive k-NN search, which causes a non-trivial online computational cost on large datasets. To overcome this weakness, we propose a novel diffusion technique in this paper. In our work, instead of applying diffusion to the query, we precompute the diffusion results of each element in the database, making the online search a simple linear combination on top of the k-NN search process. Our proposed method becomes 10∼ times faster in terms of online search speed. Moreover, we propose to use late truncation instead of early truncation in previous works to achieve better retrieval performance."
"Mengqi Xu, J. Ross, Lyanne Valdez, Aysuman Sen",2d0ebe8e0a5d918b90b98b006bceb1070c14e140,Direct Single Molecule Imaging of Enhanced Enzyme Diffusion.,Physical Review Letters,2018,32,"Recent experimental results have shown that enzymes can diffuse faster when they are in the presence of their reactants (substrate). This faster diffusion has been termed enhanced diffusion. Fluorescence correlation spectroscopy (FCS), which has been employed as the only method to make these measurements, relies on analyzing the fluctuations in fluorescence intensity to measure the diffusion coefficient of particles. Recently, artifacts in FCS measurements due to its sensitivity to environmental conditions have been evaluated, calling prior enhanced diffusion results into question. It behooves us to adopt complementary and direct methods to measure the mobility of enzymes. Herein, we use a technique of direct single molecule imaging to observe the diffusion of individual enzymes in solution. This technique is less sensitive to intensity fluctuations and deduces the diffusion coefficient directly based on the trajectory of the enzyme. Our measurements recapitulate that enzyme diffusion is enhanced in the presence of its substrate and find that the relative increase in diffusion of a single enzyme is even higher than those previously reported using FCS. We also use this complementary method to test if the total enzyme concentration affects the relative increase in diffusion and if the enzyme oligomerization state changes during its catalytic turnover. We find that the diffusion increase is independent of the total concentration of enzymes and the presence of substrate does not change the oligomerization state of enzymes."
"C. Liao, J. Stockmann, Q. Tian, B. Bilgiç, N. Arango, Mary Kate Manhard, S. Huang, W. Grissom, L. Wald, K. Setsompop",b1b4c38a5da02f9a224965a7f913132b23e5417c,"High‐fidelity, high‐isotropic‐resolution diffusion imaging through gSlider acquisition with B1+ and T1 corrections and integrated ΔB0/Rx shim array",Magnetic Resonance in Medicine,2018,27,B1+ and T1 corrections and dynamic multicoil shimming approaches were proposed to improve the fidelity of high‐isotropic‐resolution generalized slice‐dithered enhanced resolution (gSlider) diffusion imaging.
"Shervin Minaee, Yao Wang, Alp Aygar, Sohae Chung, X. Wang, Y. Lui, E. Fieremans, S. Flanagan, J. Rath",442190ea079d34e80ed4e89554f84df1a2c06b9f,MTBI Identification From Diffusion MR Images Using Bag of Adversarial Visual Features,IEEE Transactions on Medical Imaging,2018,25,"In this paper, we propose bag of adversarial features (BAFs) for identifying mild traumatic brain injury (MTBI) patients from their diffusion magnetic resonance images (MRIs) (obtained within one month of injury) by incorporating unsupervised feature learning techniques. MTBI is a growing public health problem with an estimated incidence of over 1.7 million people annually in USA. Diagnosis is based on clinical history and symptoms, and accurate, concrete measures of injury are lacking. Unlike most of the previous works, which use hand-crafted features extracted from different parts of brain for MTBI classification, we employ feature learning algorithms to learn more discriminative representation for this task. A major challenge in this field thus far is the relatively small number of subjects available for training. This makes it difficult to use an end-to-end convolutional neural network to directly classify a subject from MRIs. To overcome this challenge, we first apply an adversarial auto-encoder (with convolutional structure) to learn patch-level features, from overlapping image patches extracted from different brain regions. We then aggregate these features through a bag-of-words approach. We perform an extensive experimental study on a dataset of 227 subjects (including 109 MTBI patients, and 118 age and sex-matched healthy controls) and compare the bag-of-deep-features with several previous approaches. Our experimental results show that the BAF significantly outperforms earlier works relying on the mean values of MR metrics in selected brain regions."
"A. Abirami, P. Prakash, K. Thangavel",d872fd733c83a97f517132daeb1e963256f18b7b,Fractional diffusion equation-based image denoising model using CN–GL scheme,International Journal of Computational Mathematics,2018,24,"ABSTRACT In recent decades, variational methods have achieved great success in reducing noise owing to the use of total variation (TV). The TV-based denoising model introduced by Rudin–Osher–Fatemi (ROF) is playing vital role in denoising the different types of images. In this paper, a new denoising model based on space fractional diffusion equation is proposed with a finite domain discretized using effective applications of Crank–Nicholson and Grünwald Letnikov difference schemes. The ROF model has been adopted to solve the proposed model with the help of Alternative Direction Implicit method to denoise the image. The experimental results of the proposed model have been compared with those of the Gaussian model and it is observed that the Peak Signal-to-Noise Ratio has been improved."
"Jian Bai, Xiangchu Feng",0a2aa57cfc8d13b1532f36bd84b132e8eab08e6b,Image Denoising Using Generalized Anisotropic Diffusion,Journal of Mathematical Imaging and Vision,2018,23,
"Xuan Gu, H. Knutsson, A. Eklund",971a691755180ee36f775e8e20bc7bbc351fd87a,Generating Diffusion MRI scalar maps from T1 weighted images using generative adversarial networks,Scandinavian Conference on Image Analysis,2018,18,
"A. Chuhutin, B. Hansen, A. Wlodarczyk, T. Owens, N. Shemesh, S. Jespersen",403978fd3291c4b8d0ea470ed0eb700811b2c743,Diffusion Kurtosis Imaging maps neural damage in the EAE model of multiple sclerosis,NeuroImage,2018,16,
"Shanmin Pang, Jin Ma, Jianru Xue, Jihua Zhu, Vicente Ordonez",3f09e7e3b4437eeab2ce7ba271350d1252c193ee,Deep Feature Aggregation and Image Re-Ranking With Heat Diffusion for Image Retrieval,IEEE transactions on multimedia,2018,16,"Image retrieval based on deep convolutional features has demonstrated state-of-the-art performance in popular benchmarks. In this paper, we present a unified solution to address deep convolutional feature aggregation and image re-ranking by simulating the dynamics of heat diffusion. A distinctive problem in image retrieval is that repetitive or bursty features tend to dominate final image representations, resulting in representations less distinguishable. We show that by considering each deep feature as a heat source, our unsupervised aggregation method is able to avoid over-representation of bursty features. We additionally provide a practical solution for the proposed aggregation method and further show the efficiency of our method in experimental evaluation. Inspired by the aforementioned deep feature aggregation method, we also propose a method to re-rank a number of top ranked images for a given query image by considering the query as the heat source. Finally, we extensively evaluate the proposed approach with pre-trained and fine-tuned deep networks on common public benchmarks and show superior performance compared to previous work."
"S. Arridge, A. Hauptmann",746a5d1a7d51487089b349b678d2db73823e1e28,Networks for Nonlinear Diffusion Problems in Imaging,Journal of Mathematical Imaging and Vision,2018,15,
"Sung In Cho, Suk‐Ju Kang",805a764d002bfc12ab220610c4e5a6b047f640ac,Geodesic Path-Based Diffusion Acceleration for Image Denoising,IEEE transactions on multimedia,2018,14,"We propose an advanced anisotropic-diffusion (AD)-based approach for an image denoising method, which utilizes a geodesic path to produce single-pass adaptive smoothing by analyzing the diffusion continuity. The proposed method consists of the following four procedures: element-weight determination, geodesic path-based kernel (GPK) generation, single-pass smoothing using the GPK, and post-processing of the GPK smoothing. In the first procedure, weights for neighboring pixels are calculated by diffusivity analysis. In the second procedure, a geodesic path is selected using a geodesic distance that is calculated by a diffusion continuity analysis. In the third procedure, GPK-based smoothing is applied to a given noisy image to extract the noise-free pixel value. Finally, a distant AD that uses the double diffusion length is applied to the resultant image by the GPK filtering to enhance the quality of noise suppression in smooth regions. In addition to the main procedures, schemes for the robust outlier reduction and complexity reduction are introduced. The simulation results showed that the proposed method improved the denoising quality by increasing the peak signal-to-noise ratio (PSNR) and structural similarity (SSIM) by up to 4.094 dB and 0.057, respectively, compared to the AD-based benchmark methods. Compared to block-matching and 3-D filtering, the proposed method showed comparable quality of noise reduction with similar PSNR and SSIM values, which it accomplished with much less computation time."
"B. Osting, Dong Wang",8ad545013a47f79a110881027dd2cef0df193cdb,Diffusion generated methods for denoising target-valued images,Inverse Problems and Imaging,2018,13,"We consider the inverse problem of denoising an image where each point (pixel) is an element of a target set, which we refer to as a target-valued image. The target sets considered are either (i) a closed convex set of Euclidean space or (ii) a closed subset of the sphere such that the closest point mapping is defined almost everywhere. The energy for the denoising problem consists of an $L^2$-fidelity term which is regularized by the Dirichlet energy. A relaxation of this energy, based on the heat kernel, is introduced and the associated minimization problem is proven to be well-posed. We introduce a diffusion generated method which can be used to efficiently find minimizers of this energy. We prove results for the stability and convergence of the method for both types of target sets. The method is demonstrated on a variety of synthetic and test problems, with associated target sets given by the semi-positive definite matrices, the cube, spheres, the orthogonal matrices, and the real projective line."
"Sen Ma, C. Nguyen, A. Christodoulou, D. Luthringer, J. Kobashigawa, Sang-Eun Lee, Hyuk-Jae Chang, Debiao Li",0a0e31c8906ce5d37e710b4e96a70e9a16c01d6a,Accelerated Cardiac Diffusion Tensor Imaging Using Joint Low-Rank and Sparsity Constraints,IEEE Transactions on Biomedical Engineering,2018,13,"Objective: The purpose of this paper is to accelerate cardiac diffusion tensor imaging (CDTI) by integrating low-rankness and compressed sensing. Methods: Diffusion-weighted images exhibit both transform sparsity and low-rankness. These properties can jointly be exploited to accelerate CDTI, especially when a phase map is applied to correct for the phase inconsistency across diffusion directions, thereby enhancing low-rankness. The proposed method is evaluated both ex vivo and in vivo, and is compared to methods using either a low-rank or sparsity constraint alone. Results: Compared to using a low-rank or sparsity constraint alone, the proposed method preserves more accurate helix angle features, the transmural continuum across the myocardium wall, and mean diffusivity at higher acceleration, while yielding significantly lower bias and higher intraclass correlation coefficient. Conclusion: Low-rankness and compressed sensing together facilitate acceleration for both ex vivo and in vivo CDTI, improving reconstruction accuracy compared to employing either constraint alone. Significance: Compared to previous methods for accelerating CDTI, the proposed method has the potential to reach higher acceleration while preserving myofiber architecture features, which may allow more spatial coverage, higher spatial resolution, and shorter temporal footprint in the future."
"E. Miller, R. Foster, C. Lage, G. Prigozhin, M. Bautz, C. Grant, B. LaMarr, A. Malonis",04f7ef71cbe1320e34031c49f1c4786df64f5a07,The effects of charge diffusion on soft x-ray response for future high-resolution imagers,Astronomical Telescopes + Instrumentation,2018,11,"Future solid state imagers for high-spatial-resolution X-ray missions will require an unprecedented combination of small pixel size and large detector thickness. This presents challenges for the accurate detection of soft X-rays, since the cloud of charge produced by these photons near the entrance window will laterally diffuse to multiple pixels by the time it is collected by the rear surface electrodes, complicating photon energy reconstruction. Using realistic models for the electric field distribution in a silicon-based detector, we have performed simulations of soft X-ray detection over a range of depletion depth, pixel size, and back bias voltage. These simulations start at the generation of photoelectrons by the incoming X-ray, and include diffusion to surrounding pixels as the charge cloud is quickly gathered by the electrode gate structure. We then perform standard X-ray event identification in the presence of a range of simulated pixel-based noise, and compare the spectral response to predicted requirements for future missions at energies down to 0.2 keV. The results show that while increasing the backside bias voltage can decrease the charge collection time and thus also the lateral diffusion, charge splitting among pixels is still significant. The soft X-ray response of future high-resolution missions will greatly benefit from few-electron readout noise or better."
"James M. Murphy, M. Maggioni",cbbf87873ba8acc09b9e7653fcd2504551ab69b6,Iterative active learning with diffusion geometry for hyperspectral images,Workshop on Hyperspectral Image and Signal Processing,2018,10,"We propose an active learning algorithm for labeling hyperspectral images (HSI). Pixels with ambiguous class affinity are iteratively estimated using geometric and statistical properties of the data. These pixels are then labeled with ground truth data, yielding a small but potent set of labeled pixels, which are consequently used to label the remaining data. The proposed method enjoys quasilinear complexity in the number of sample pixels, as well as competitive empirical performance on real HSI. Substantial improvement in labeling accuracy compared to unsupervised learning and existing active learning methods is observed with just a few well-selected label queries."
"A. Ciritsis, A. Boss, Cristina Rossi",48a02f1050569fb3a1142805093cdf7b13e95073,Automated pixel‐wise brain tissue segmentation of diffusion‐weighted images via machine learning,NMR in Biomedicine,2018,10,"The diffusion‐weighted (DW) MR signal sampled over a wide range of b‐values potentially allows for tissue differentiation in terms of cellularity, microstructure, perfusion, and T2 relaxivity. This study aimed to implement a machine learning algorithm for automatic brain tissue segmentation from DW‐MRI datasets, and to determine the optimal sub‐set of features for accurate segmentation."
"Xiaodan Hu, A. Chung, P. Fieguth, F. Khalvati, M. Haider, A. Wong",3d23e3fdb28330dea6e68bdb59224218def0b5bc,ProstateGAN: Mitigating Data Bias via Prostate Diffusion Imaging Synthesis with Generative Adversarial Networks,ArXiv,2018,8,"Generative Adversarial Networks (GANs) have shown considerable promise for mitigating the challenge of data scarcity when building machine learning-driven analysis algorithms. Specifically, a number of studies have shown that GAN-based image synthesis for data augmentation can aid in improving classification accuracy in a number of medical image analysis tasks, such as brain and liver image analysis. However, the efficacy of leveraging GANs for tackling prostate cancer analysis has not been previously explored. Motivated by this, in this study we introduce ProstateGAN, a GAN-based model for synthesizing realistic prostate diffusion imaging data. More specifically, in order to generate new diffusion imaging data corresponding to a particular cancer grade (Gleason score), we propose a conditional deep convolutional GAN architecture that takes Gleason scores into consideration during the training process. Experimental results show that high-quality synthetic prostate diffusion imaging data can be generated using the proposed ProstateGAN for specified Gleason scores."
"Simon Koppers, D. Merhof",2a4c308bcfebe6fa13f282630a6cf3ba673db1dc,DELIMIT PyTorch - An extension for Deep Learning in Diffusion Imaging,ArXiv,2018,5,"DELIMIT is a framework extension for deep learning in diffusion imaging, which extends the basic framework PyTorch towards spherical signals. Based on several novel layers, deep learning can be applied to spherical diffusion imaging data in a very convenient way. First, two spherical harmonic interpolation layers are added to the extension, which allow to transform the signal from spherical surface space into the spherical harmonic space, and vice versa. In addition, a local spherical convolution layer is introduced that adds the possibility to include gradient neighborhood information within the network. Furthermore, these extensions can also be utilized for the preprocessing of diffusion signals."
"S. HashemizadehKolowri, Rong-Rong Chen, E. D. Bella, E. Hsu, L. Ying, G. Adluru",62ceb18abf6587e225ee394179d503c7c9ee1963,Improving image reconstructions for simultaneous multi-slice readout-segmented diffusion MRI data with phase errors,IEEE International Symposium on Biomedical Imaging,2018,3,"Readout-segmented echo planar imaging (RS-EPI) combined with controlled aliasing simultaneous multi-slice (SMS) acquisition improves spatial resolution of diffusion-weighted images (DWIs) with a scan time that is reduced by a factor proportional to the number of simultaneous slices. Split slice-GRAPPA (SSG) is a commonly used method to de-alias SMS DWIs using kernels trained from baseline b=0 images. When applying SSG to datasets acquired from a RS-EPI sequence, we found that SSG kernels trained from baselines do not de-alias DWIs effectively due to baseline phase errors. To overcome this issue, in this work we propose an iterative approach, termed iterative Split slice-GRAPPA (I-SSG), to train improved kernels using estimated DWIs rather than only the baseline images. Our results from two stroke patients show that the proposed I-SSG algorithm produces consistently better reconstructions in the presence of baseline phase errors. The proposed I-SSG algorithm yields over 50% improvement over the SSG method in Fractional anisotropy (FA) and Mean Diffusion (MD) estimations for slice reduction factors of up to R = 4."
"Jennifer Kamphenkel, P. Jaeger, S. Bickelhaupt, F. Laun, W. Lederer, H. Daniel, T. Kuder, S. Delorme, H. Schlemmer, Franziska Koenig, Klaus Maier-Hein",cb9b670c327f11b4b46d3c42472f1d22c8e5769b,Domain Adaptation for Deviating Acquisition Protocols in CNN-based Lesion Classification on Diffusion-Weighted MR Images,RAMBO+BIA+TIA@MICCAI,2018,3,
"H. Ammari, Bangti Jin, Wenlong Zhang",25631e21a7d836fece5e1623d082bc5fd63888eb,Linearized reconstruction for diffuse optical spectroscopic imaging,Proceedings of the Royal Society A,2018,2,"In this paper, we present a novel reconstruction method for diffuse optical spectroscopic imaging with a commonly used tissue model of optical absorption and scattering. It is based on linearization and group sparsity, which allows the diffusion coefficient and absorption coefficient to be recovered simultaneously, provided that their spectral profiles are incoherent and a sufficient number of wavelengths are judiciously taken for the measurements. We also discuss the reconstruction for an imperfectly known boundary and show that, with multi-wavelength data, the method can reduce the influence of modelling errors and still recover the absorption coefficient. Extensive numerical experiments are presented to support our analysis."
"Alice P. Bates, Z. Khalid, J. McEwen, R. Kennedy, Alessandro Daducci, Erick Jorge Canales-Rodríguez",cc2abd2352856f2eba3c67b9352f5a8328bcc022,Efficient sampling and robust 3D diffusion magnetic resonance imaging signal reconstruction,,2018,1,"This paper presents novel single and multi-shell sampling schemes for diffusion MRI. In diffusion MRI, it is paramount that the number of samples is as small as possible in order that scan times are practical in a clinical setting. The proposed schemes use an efficient number of measurements in that the number of samples is equal to the degrees of freedom in the orthonormal bases used for reconstruction. Novel reconstruction algorithms based on smaller subsystems of linear equations, as compared to the standard regularized least-squares method, are developed for both single and multi-shells sampling schemes. The smaller matrices used in these novel reconstruction algorithms are designed to be well-conditioned, leading to improved reconstruction accuracy. Accurate and robust reconstruction is also achieved through incorporation of regularization into the novel reconstruction algorithms and using a Rician or non-central Chi noise model. We quantitatively validate our single and multi-shell schemes against standard least-squares reconstruction methods to show that they enable more accurate reconstruction when the number of samples is equal to the degrees of freedom in the basis. Human brain data is also used to qualitatively evaluate reconstruction"
"Ke Chen, Xianghai Meng, Feng He, Yongjian Zhou, Jihoon Jeong, N. Sheehan, S. Bank, Yaguo Wang",d9d54dcbbde3ee9d70f6b34e421a2e3c7a0f4a60,Comparison between Grating Imaging and Transient Grating Techniques on Measuring Carrier Diffusion in Semiconductor,Nanoscale and Microscale Thermophysical Engineering,2018,1,"ABSTRACT Optical grating technique, where optical gratings are generated via light inference, has been widely used to measure charge carrier and phonon transport in semiconductors. In this paper, compared are three types of transient optical grating techniques: transient grating diffraction, transient grating heterodyne, and grating imaging, by utilizing them to measure carrier diffusion coefficient in a GaAs/AlAs superlattice. Theoretical models are constructed for each technique to extract the carrier diffusion coefficient, and the results from all three techniques are consistent. Our main findings are: (1) the transient transmission change ∆T/T0 obtained from transient grating heterodyne and grating imaging techniques are identical, even these two techniques originate from different detection principles; and (2) by adopting detection of transmission change (heterodyne amplification) instead of pure diffraction, the grating imaging technique (transient grating heterodyne) has overwhelming advantage in signal intensity than the transient grating diffraction, with a signal intensity ratio of 315:1 (157:1)."
"P. Qiao, Y. Dou, Yunjin Chen, Wensen Feng",59b5600bbd5cbf0eaff28046405f652265e69691,Learning Generic Diffusion Processes for Image Restoration,British Machine Vision Conference,2018,0,"Image restoration problems are typical ill-posed problems where the regularization term plays an important role. The regularization term learned via generative approaches is easy to transfer to various image restoration, but offers inferior restoration quality compared with that learned via discriminative approaches. On the contrary, the regularization term learned via discriminative approaches are usually trained for a specific image restoration problem, and fail in the problem for which it is not trained. To address this issue, we propose a generic diffusion process (genericDP) to handle multiple Gaussian denoising problems based on the Trainable Non-linear Reaction Diffusion (TNRD) models. Instead of one model, which consists of a diffusion and a reaction term, for one Gaussian denoising problem in TNRD, we enforce multiple TNRD models to share one diffusion term. The trained genericDP model can provide both promising denoising performance and high training efficiency compared with the original TNRD models. We also transfer the trained diffusion term to non-blind deconvolution which is unseen in the training phase. Experiment results show that the trained diffusion term for multiple Gaussian denoising can be transferred to image non-blind deconvolution as an image prior and provide competitive performance."
"Shuai Li, Mo Deng, Justin Lee, Ayan Sinha, G. Barbastathis",ff7b655595c4d0a9a8e9a457b870ffbd328aa286,Imaging through glass diffusers using densely connected convolutional networks,Optica,2017,243,"Computational imaging through scatter generally is accomplished by first characterizing the scattering medium so that its forward operator is obtained; and then imposing additional priors in the form of regularizers on the reconstruction functional so as to improve the condition of the originally ill-posed inverse problem. In the functional, the forward operator and regularizer must be entered explicitly or parametrically (e.g. scattering matrices and dictionaries, respectively.) However, the process of determining these representations is often incomplete, prone to errors, or infeasible. Recently, deep learning architectures have been proposed to instead learn both the forward operator and regularizer through examples. Here, we propose for the first time, to our knowledge, a convolutional neural network architecture called ""IDiffNet"" for the problem of imaging through diffuse media and demonstrate that IDiffNet has superior generalization capability through extensive tests with well-calibrated diffusers. We found that the Negative Pearson Correlation Coefficient loss function for training is more appropriate for spatially sparse objects and strong scattering conditions. Our results show that the convolutional architecture is robust to the choice of prior, as demonstrated by the use of multiple training and testing object databases, and capable of achieving higher space-bandwidth product reconstructions than previously reported."
"D. Alexander, D. Zikic, Aurobrata Ghosh, Ryutaro Tanno, V. Wottschel, Jiaying Zhang, Enrico Kaden, T. Dyrby, S. Sotiropoulos, Hui Zhang, A. Criminisi",d1978326ca73d2b80ed7190a171877461db387e0,Image quality transfer and applications in diffusion MRI,NeuroImage,2017,92,
"Wenchuan Wu, K. Miller",5dc84e2bf8dc2379f06909a7ee058076ce3785b5,Image formation in diffusion MRI: A review of recent technical developments,Journal of Magnetic Resonance Imaging,2017,80,"Diffusion magnetic resonance imaging (MRI) is a standard imaging tool in clinical neurology, and is becoming increasingly important for neuroscience studies due to its ability to depict complex neuroanatomy (eg, white matter connectivity). Single‐shot echo‐planar imaging is currently the predominant formation method for diffusion MRI, but suffers from blurring, distortion, and low spatial resolution. A number of methods have been proposed to address these limitations and improve diffusion MRI acquisition. Here, the recent technical developments for image formation in diffusion MRI are reviewed. We discuss three areas of advance in diffusion MRI: improving image fidelity, accelerating acquisition, and increasing the signal‐to‐noise ratio."
"P. Eichinger, E. Alberts, C. Delbridge, S. Trebeschi, A. Valentinitsch, S. Bette, T. Huber, J. Gempt, B. Meyer, J. Schlegel, C. Zimmer, J. Kirschke, Bjoern H Menze, B. Wiestler",499d64d6b24d86638de7adeab64f872a92ac4cf0,Diffusion tensor image features predict IDH genotype in newly diagnosed WHO grade II/III gliomas,Scientific Reports,2017,55,
"James M. Murphy, M. Maggioni",efa64d2e47bc02cf2aaed8cef135b564af352507,Unsupervised Clustering and Active Learning of Hyperspectral Images With Nonlinear Diffusion,IEEE Transactions on Geoscience and Remote Sensing,2017,53,"The problem of unsupervised learning and segmentation of hyperspectral images is a significant challenge in remote sensing. The high dimensionality of hyperspectral data, presence of substantial noise, and overlap of classes all contribute to the difficulty of automatically clustering and segmenting hyperspectral images. We propose an unsupervised learning technique called spectral-spatial diffusion learning (DLSS) that combines a geometric estimation of class modes with a diffusion-inspired labeling that incorporates both spectral and spatial information. The mode estimation incorporates the geometry of the hyperspectral data by using diffusion distance to promote learning a unique mode from each class. These class modes are then used to label all the points by a joint spectral-spatial nonlinear diffusion process. A related variation of DLSS is also discussed, which enables active learning by requesting labels for a very small number of well-chosen pixels, dramatically boosting overall clustering results. Extensive experimental analysis demonstrates the efficacy of the proposed methods against benchmark and state-of-the-art hyperspectral analysis techniques on a variety of real data sets, their robustness to choices of parameters, and their low computational complexity."
"J. Song, M. Bazant",858a7cffce209aefaa4c60cb807817284bb58e86,Electrochemical Impedance Imaging via the Distribution of Diffusion Times.,Physical Review Letters,2017,46,"We develop a mathematical framework to analyze electrochemical impedance spectra in terms of a distribution of diffusion times (DDT) for a parallel array of random finite-length Warburg (diffusion) or Gerischer (reaction-diffusion) circuit elements. A robust DDT inversion method is presented based on complex nonlinear least squares regression with Tikhonov regularization and illustrated for three cases of nanostructured electrodes for energy conversion: (i) a carbon nanotube supercapacitor, (ii) a silicon nanowire Li-ion battery, and (iii) a porous-carbon vanadium flow battery. The results demonstrate the feasibility of nondestructive ""impedance imaging"" to infer microstructural statistics of random, heterogeneous materials."
"Hossein Khodabakhshi Rafsanjani, M. Sedaaghi, S. Saryazdi",cc741ee55ca4118047dab10cf24c93b6822a6438,An adaptive diffusion coefficient selection for image denoising,Digit. Signal Process.,2017,43,
"Dongdong Shi, Xianzhong Zheng, Haibin Zhao, Z. Pan, Bin Li, H. Zou, Xu Zhou, K. Guo, F. An, Yu Bin Li",4ce9ef445f03b5f718b5900e6c50fbd378c8d0af,Deep Imaging of the HCG 95 Field. I. Ultra-diffuse Galaxies,,2017,33,"We present a detection of 89 candidates of ultra-diffuse galaxies (UDGs) in a 4.9 degree2 field centered on the Hickson Compact Group 95 (HCG 95) using deep g- and r-band images taken with the Chinese Near Object Survey Telescope. This field contains one rich galaxy cluster (Abell 2588 at z = 0.199) and two poor clusters (Pegasus I at z = 0.013 and Pegasus II at z = 0.040). The 89 candidates are likely associated with the two poor clusters, giving about 50–60 true UDGs with a half-light radius and a central surface brightness mag arcsec−2. Deep -band images are available for 84 of the 89 galaxies from the Dark Energy Camera Legacy Survey (DECaLS), confirming that these galaxies have an extremely low central surface brightness. Moreover, our UDG candidates are spread over a wide range in g − r color, and ∼26% are as blue as normal star-forming galaxies, which is suggestive of young UDGs that are still in formation. Interestingly, we find that one UDG linked with HCG 95 is a gas-rich galaxy with H i mass M⊙ detected by the Very Large Array, and has a stellar mass of M⊙. This indicates that UDGs at least partially overlap with the population of nearly dark galaxies found in deep H i surveys. Our results show that the high abundance of blue UDGs in the HCG 95 field is favored by the environment of poor galaxy clusters residing in H i-rich large-scale structures."
"P. Christ, Florian Ettlinger, G. Kaissis, Sebastian J. Schlecht, F. Ahmaddy, Felix Grün, A. Valentinitsch, Seyed-Ahmad Ahmadi, R. Braren, Bjoern H Menze",22a699ba4bc8b845c0bd07b296ae758b45994755,SurvivalNet: Predicting patient survival from diffusion weighted magnetic resonance images using cascaded fully convolutional and 3D Convolutional Neural Networks,IEEE International Symposium on Biomedical Imaging,2017,28,Automatic non-invasive assessment of hepatocellular carcinoma (HCC) malignancy has the potential to substantially enhance tumor treatment strategies for HCC patients. In this work we present a novel framework to automatically characterize the malignancy of HCC lesions from DWI images. We predict HCC malignancy in two steps: As a first step we automatically segment HCC tumor lesions using cascaded fully convolutional neural networks (CFCN). A 3D neural network (SurvivalNet) then predicts the HCC lesions' malignancy from the HCC tumor segmentation. We formulate this task as a classification problem with classes being “low risk” and “high risk” represented by longer or shorter survival times than the median survival. We evaluated our method on DWI of 31 HCC patients. Our proposed framework achieves an end-to-end accuracy of 65% with a Dice score for the automatic lesion segmentation of 69% and an accuracy of 68% for tumor malignancy classification based on expert annotations. We compared the SurvivalNet to classical handcrafted features such as Histogram and Haralick and show experimentally that SurvivalNet outperforms the handcrafted features in HCC malignancy classification. End-to-end assessment of tumor malignancy based on our proposed fully automatic framework corresponds to assessment based on expert annotations with high significance (p > 0.95).
"P. Qiao, Y. Dou, Wensen Feng, Rongchun Li, Yunjin Chen",ca2e2266c270824076131c9006150bd3f41746e9,Learning Non-local Image Diffusion for Image Denoising,ACM Multimedia,2017,24,"Image diffusion plays a fundamental role for the task of image denoising. The recently proposed trainable nonlinear reaction diffusion (TNRD) model defines a simple but very effective framework for image denoising. However, as the TNRD model is a local model, whose diffusion behavior is purely controlled by information of local patches, it is prone to create artifacts in the homogenous regions and over-smooth highly textured regions, especially in the case of strong noise levels. Meanwhile, it is widely known that the non-local self-similarity (NSS) prior stands as an effective image prior for image denoising, which has been widely exploited in many non-local methods. In this work, we are highly motivated to embed the NSS prior into the TNRD model to tackle its weaknesses. In order to preserve the expected property that end-to-end training remains available, we exploit the NSS prior by defining a set of non-local filters, and derive our proposed trainable non-local reaction diffusion (TNLRD) model for image denoising. Together with the local filters and influence functions, the non-local filters are learned by employing loss-specific training. The experimental results show that the trained TNLRD model produces visually plausible recovered images with more textures and less artifacts, compared to its local versions. Moreover, the trained TNLRD model can achieve strongly competitive performance to recent state-of-the-art image denoising methods in terms of peak signal-to-noise ratio (PSNR) and structural similarity index (SSIM)."
"Yuanfang Guo, O. Au, Rui Wang, Lu Fang, Xiaochun Cao",48075354e362b3622d4d46acca4ca5c02e5f9cb0,Halftone Image Watermarking by Content Aware Double-Sided Embedding Error Diffusion,IEEE Transactions on Image Processing,2017,21,"In this paper, we carry out a performance analysis from a probabilistic perspective to introduce the error diffusion-based halftone visual watermarking (EDHVW) methods’ expected performances and limitations. Then, we propose a new general EDHVW method, content aware double-sided embedding error diffusion (CaDEED), via considering the expected watermark decoding performance with specific content of the cover images and watermark, different noise tolerance abilities of various cover image content, and the different importance levels of every pixel (when being perceived) in the secret pattern (watermark). To demonstrate the effectiveness of CaDEED, we propose CaDEED with expectation constraint (CaDEED-EC) and CaDEED-noise visibility function (NVF) and importance factor (IF) (CaDEED-N&I). Specifically, we build CaDEED-EC by only considering the expected performances of specific cover images and watermark. By adopting the NVF and proposing the IF to assign weights to every embedding location and watermark pixel, respectively, we build the specific method CaDEED-N&I. In the experiments, we select the optimal parameters for NVF and IF via extensive experiments. In both the numerical and visual comparisons, the experimental results demonstrate the superiority of our proposed work."
"Yi Wang, Yu-Jia Shen, Dongyang Liu, Guoqin Li, Zhe Guo, Yangyu Fan, Yilong Niu",ab89a1871b9ed779193d3fd2f9e3dcc3ce634282,Evaluations of diffusion tensor image registration based on fiber tractography,BioMedical Engineering OnLine,2017,15,
"Thomas Vogt, J. Lellmann",0cf53c8a9694d2d74e8be20062de0c5c4891ee6b,Measure-Valued Variational Models with Applications to Diffusion-Weighted Imaging,Journal of Mathematical Imaging and Vision,2017,14,
"K. Mawatari, A. Inoue, Toru Yamada, T. Hayashino, T. Otsuka, Y. Matsuda, H. Umehata, M. Ouchi, S. Mukae",9bddebd3f7f4ec41e25217bcc3776e5e531e4d2f,Imaging of diffuse H I absorption structure in the SSA22 protocluster region at z = 3.1,,2017,12,"Using galaxies as background light sources to map intervening Lya absorption is a novel approach to study the interplay among galaxies, the circum-galactic medium (CGM), and the intergalactic medium (IGM). Introducing a new measure of z = 3.1$ HI Lya absorption relative to the cosmic mean, Delta_NB497, estimated from photometric data of star-forming galaxies at 3.3 < z < 3.5, we have made two-dimensional Delta_NB497 maps in the z = 3.1 SSA22 proto-cluster region and two control fields (SXDS and GOODS-N fields) with a spatial resolution of ~ 5 comoving Mpc. The Delta_NB497 measurements in the SSA22 field are systematically larger than those in the control fields, and this HI absorption enhancement extends more than 50 comoving Mpc. The field-averaged (i.e., ~50 comoving Mpc scale) Delta_NB497 and the overdensity of Lya emitters (LAEs) seem to be correlated, while there is no clear dependency of the Delta_NB497 on the local LAE overdensity in a few comoving Mpc scale. These results suggest that diffuse HI gas spreads out in/around the SSA22 proto-cluster. We have also found an enhancement of Delta_NB497 at a projected distance < 100 physical kpc from the nearest z = 3.1 galaxies at least in the SSA22 field, which is probably due to HI gas associated with the CGM of individual galaxies. The HI absorption enhancement in the CGM-scale tends to be weaker around galaxies with stronger Lya emission, which suggests that the Lya escape fraction from galaxies depends on hydrogen neutrality in the CGM."
"H. Ammari, L. Qiu, F. Santosa, Wenlong Zhang",b8272d73c093cc3cf9b40547cc929d9aa5a539c2,Determining anisotropic conductivity using diffusion tensor imaging data in magneto-acoustic tomography with magnetic induction,,2017,9,"In this paper we present a mathematical and numerical framework for a procedure of imaging anisotropic electrical conductivity tensor by integrating magneto-acoutic tomography with data acquired from diffusion tensor imaging. Magneto-acoustic tomography with magnetic induction (MAT-MI) is a hybrid, non-invasive medical imaging technique to produce conductivity images with improved spatial resolution and accuracy. Diffusion tensor imaging (DTI) is also a non-invasive technique for characterizing the diffusion properties of water molecules in tissues. We propose a model for anisotropic conductivity in which the conductivity is proportional to the diffusion tensor. Under this assumption, we propose an optimal control approach for reconstructing the anisotropic electrical conductivity tensor. We prove convergence and Lipschitz type stability of the algorithm and present numerical examples to illustrate its accuracy and feasibility."
"Kerstin Demberg, F. Laun, J. Windschuh, R. Umathum, P. Bachert, T. Kuder",615ef191e516aa6675065b1540bf90f312341e1d,Nuclear magnetic resonance diffusion pore imaging: Experimental phase detection by double diffusion encoding.,Physical Review E,2017,8,"Diffusion pore imaging is an extension of diffusion-weighted nuclear magnetic resonance imaging enabling the direct measurement of the shape of arbitrarily formed, closed pores by probing diffusion restrictions using the motion of spin-bearing particles. Examples of such pores comprise cells in biological tissue or oil containing cavities in porous rocks. All pores contained in the measurement volume contribute to one reconstructed image, which reduces the problem of vanishing signal at increasing resolution present in conventional magnetic resonance imaging. It has been previously experimentally demonstrated that pore imaging using a combination of a long and a narrow magnetic field gradient pulse is feasible. In this work, an experimental verification is presented showing that pores can be imaged using short gradient pulses only. Experiments were carried out using hyperpolarized xenon gas in well-defined pores. The phase required for pore image reconstruction was retrieved from double diffusion encoded (DDE) measurements, while the magnitude could either be obtained from DDE signals or classical diffusion measurements with single encoding. The occurring image artifacts caused by restrictions of the gradient system, insufficient diffusion time, and by the phase reconstruction approach were investigated. Employing short gradient pulses only is advantageous compared to the initial long-narrow approach due to a more flexible sequence design when omitting the long gradient and due to faster convergence to the diffusion long-time limit, which may enable application to larger pores."
"E. Yılmaz, T. Kayikçioglu, S. Kayıpmaz",60ed48d4b94b9b1d3a2eb0fb0def38b172ef0cbd,Noise removal of CBCT images using an adaptive anisotropic diffusion filter,International Conference on Telecommunications and Signal Processing,2017,8,"In this work we proposed an adaptive anisotropic filtering method for removing unwanted noise information that may occur in cone beam computed tomography (CBCT) images. The data used in this study consist of 1200 different image sections obtained from 30 different patients who came to Karadeniz Technical University, Faculty of Dentistry, Department of Oral Diagnosis and Radiology Clinic for routine controls. At first, to identify 2D image sections that do not contain noise information, we measured noise levels in CBCT dataset sections using a noise level estimation method. Then, we applied different levels of noise to those noise-free images. We used anisotropic diffusion filter (Perona and Malik's filter), an automatic anisotropic filter (Tsiotsios and Petrou's method), and our adaptive anisotropic filtering method to remove noise information from those images. Afterward, we obtained peak signal to noise ratio (PSNR) and mean absolute error (MAE) values derived from the results. Proposed adaptive anisotropic diffusion filter seems to be a good choice for removing noise that may occur on CBCT image sections."
"G. Aletti, M. Moroni, G. Naldi",4d4682dd8b5e62d836944eea5def99bc2a7e53c3,A New Nonlocal Nonlinear Diffusion Equation for Data Analysis,Acta Applicandae Mathematicae - An International Survey Journal on Applying Mathematics and Mathematical Applications,2017,7,
"G. Galiano, J. Valdés",ebbfca9cd09a7a8306351a65c92d2f28ef04962b,On a cross-diffusion system arising in image denoising,Computers and Mathematics with Applications,2017,6,
"A. Ianuş, N. Shemesh",0248927bdd09e1095cd27f567aaa4c340970586c,"Incomplete initial nutation diffusion imaging: An ultrafast, single‐scan approach for diffusion mapping",Magnetic Resonance in Medicine,2017,5,"Diffusion MRI is confounded by the need to acquire at least two images separated by a repetition time, thereby thwarting the detection of rapid dynamic microstructural changes. The issue is exacerbated when diffusivity variations are accompanied by rapid changes in T2. The purpose of the present study is to accelerate diffusion MRI acquisitions such that both reference and diffusion‐weighted images necessary for quantitative diffusivity mapping are acquired in a single‐shot experiment."
"U. Boscain, R. Chertovskih, J. Gauthier, D. Prandi, A. Remizov",63c8833914713ce6110bd417eb44b19cce32f5e0,Cortical-inspired image reconstruction via sub-Riemannian geometry and hypoelliptic diffusion,ArXiv,2017,5,"In this paper we review several algorithms for image inpainting based on the hypoelliptic diffusion naturally associated with a mathematical model of the primary visual cortex. In particular, we present one algorithm that does not exploit the information of where the image is corrupted, and others that do it. While the first algorithm is able to reconstruct only images that our visual system is still capable of recognize, we show that those of the second type completely transcend such limitation providing reconstructions at the state-of-the-art in image inpainting. This can be interpreted as a validation of the fact that our visual cortex actually encodes the first type of algorithm."
"Dario Gasbarra, S. Pajevic, P. Basser",500653a3ba19ca209bd7f9e1616781edc99719c1,Eigenvalues of Random Matrices with Isotropic Gaussian Noise and the Design of Diffusion Tensor Imaging Experiments,SIAM Journal of Imaging Sciences,2017,4,"Tensor-valued and matrix-valued measurements of different physical properties are increasingly available in material sciences and medical imaging applications. The eigenvalues and eigenvectors of such multivariate data provide novel and unique information, but at the cost of requiring a more complex statistical analysis. In this work we derive the distributions of eigenvalues and eigenvectors in the special but important case of m×m symmetric random matrices, D, observed with isotropic matrix-variate Gaussian noise. The properties of these distributions depend strongly on the symmetries of the mean tensor/matrix, D̄. When D̄ has repeated eigenvalues, the eigenvalues of D are not asymptotically Gaussian, and repulsion is observed between the eigenvalues corresponding to the same D̄ eigenspaces. We apply these results to diffusion tensor imaging (DTI), with m = 3, addressing an important problem of detecting the symmetries of the diffusion tensor, and seeking an experimental design that could potentially yield an isotropic Gaussian distribution. In the 3-dimensional case, when the mean tensor is spherically symmetric and the noise is Gaussian and isotropic, the asymptotic distribution of the first three eigenvalue central moment statistics is simple and can be used to test for isotropy. In order to apply such tests, we use quadrature rules of order t ≥ 4 with constant weights on the unit sphere to design a DTI-experiment with the property that isotropy of the underlying true tensor implies isotropy of the Fisher information. We also explain the potential implications of the methods using simulated DTI data with a Rician noise model."
"James M. Murphy, M. Maggioni",8b96055201ed6f7e4790340b79b5ec4467256d5a,Nonlinear Unsupervised Clustering of Hyperspectral Images with Applications to Anomaly Detection and Active Learning,,2017,4,"The problem of unsupervised learning and segmentation of hyperspectral images is a significant challenge in remote sensing. The high dimensionality of hyperspectral data, presence of substantial noise, and overlap of classes all contribute to the difficulty of automatically clustering and segmenting hyperspectral images. In this article, we propose an unsupervised learning technique that combines a geometric estimation of class modes with a diffusion-inspired labeling that incorporates both spatial and spectral information. The mode estimation incorporates the geometry of the hyperspectral data by using diffusion distance to promote learning a unique mode from each class. These class modes are then used to label all points by a joint spatial-spectral nonlinear diffusion process. The proposed method, called spatial-spectral diffusion learning (DLSS), is shown to perform competitively against benchmark and state-of-the-art hyperspectral clustering methods on a variety of synthetic and real datasets. The proposed methods are shown to enjoy low computational complexity and fast empirical runtime. Two variations of the proposed method are also discussed. The first variation combines the proposed method of mode estimation with partial least squares regression (PLSR) to efficiently segment chemical plumes in hyperspectral images for anomaly detection. The second variation incorporates active learning to allow the user to request labels for a very small number of pixels, which can dramatically improve overall clustering results. Extensive experimental analysis demonstrate the efficacy of the proposed methods, and their robustness to choices of parameters."
"I. Papadopoulos, Jonathan Phillips, R. Evans, N. Fenn, S. Shermer",150fe681ef9d9dc2215be7e9553a7a6f6b240f4b,Evaluation of diffusion weighted imaging in the context of multi-parametric MRI of the prostate in the assessment of suspected low volume prostatic carcinoma.,Magnetic Resonance Imaging,2017,2,
"Ruimao Zhang, Wei Yang, Zhanglin Peng, Xiaogang Wang, Liang Lin",ee098ed493af3abe873ce89354599e1f6bdf65be,Progressively Diffused Networks for Semantic Image Segmentation,ArXiv,2017,2,"This paper introduces Progressively Diffused Networks (PDNs) for unifying multi-scale context modeling with deep feature learning, by taking semantic image segmentation as an exemplar application. Prior neural networks, such as ResNet, tend to enhance representational power by increasing the depth of architectures and driving the training objective across layers. However, we argue that spatial dependencies in different layers, which generally represent the rich contexts among data elements, are also critical to building deep and discriminative representations. To this end, our PDNs enables to progressively broadcast information over the learned feature maps by inserting a stack of information diffusion layers, each of which exploits multi-dimensional convolutional LSTMs (Long-Short-Term Memory Structures). In each LSTM unit, a special type of atrous filters are designed to capture the short range and long range dependencies from various neighbors to a certain site of the feature map and pass the accumulated information to the next layer. From the extensive experiments on semantic image segmentation benchmarks (e.g., ImageNet Parsing, PASCAL VOC2012 and PASCAL-Part), our framework demonstrates the effectiveness to substantially improve the performances over the popular existing neural network models, and achieves state-of-the-art on ImageNet Parsing for large scale semantic segmentation."
"Wenjian Hu, Krishna Kumar Singh, Fanyi Xiao, Jinyoung Han, C. Chuah, Yong Jae Lee",fc265024485a81334b5605a54ba80676d6c30280,Predicting the Image Propagation Path in Online Social Networks,,2017,1,"Predicting the popularity of content is important and intriguing for both users and hosts of social media sites, such as Facebook, Google+, Instagram, Twitter, and Pinterest. Existing approaches for popularity prediction have largely focused on predicting a single metric, like the total number of comments, likes or shares of posts. We instead propose to learn and predict the entire diffusion path of an image in a social network. To this end, we design a tree-structured long short-term memory (LSTM) network, dubbed as Diffusion-LSTM. By combining user social features and image features together with the encoded diffusion path history stored in an explicit memory cell, our Diffusion-LSTM is able to keep track of the posting history of an image and predicts its diffusion path better than alternate baselines that rely only on either image or social features, or do not encode the posting history. Our model generalizes to new users who are not included in the training set, through a mapping between individual users and user prototypes. Finally, we also demonstrate that our Diffusion-LSTM can generate meaningful diffusion trees that closely resemble ground-truth trees."
J. Zhuang,a3adf6a7a72f59f95f04e288d0c7aea819aae944,The eddy current distortion in the multiband diffusion images: diagnosis and correction,,2017,1,"The diffusion weighted images acquired with the multiband sequence or the Lifespan protocols shows a type of slice distortion artifact. We find that this artifact is caused by the eddy currents, which can be induced by the diffusion gradient associated with either current DW image or the previous DW images. The artifact can be corrected by further tuning the compensation circuit in the MR hardware, or by a correction algorithm which includes the diffusion gradients from the current and previous DW images."
"Soroush Saryazdi, S. Saryazdi, H. Nezamabadi-pour",61e36aa9985c9c5be10bbf8514763ea99051e9fa,EDIZ: An Error Diffusion Image Zooming Scheme,,2017,0,"Interpolation based image zooming methods provide a high execution speed and low computational complexity. However, the quality of the zoomed images is unsatisfactory in many cases. The main challenge of super- resolution methods is to create new details to the image. This paper proposes a new algorithm to create new details using a zoom-out-zoom-in strategy. This strategy permits reducing blurring effects by adding the estimated error to the final image. Experimental results for natural images confirm the algorithm's ability to create visually pleasing results."
"J. Andersson, M. Graham, E. Zsoldos, S. Sotiropoulos",61a359b763d169e7c8988e9db401a709fa34bce6,Incorporating outlier detection and replacement into a non-parametric framework for movement and distortion correction of diffusion MR images,NeuroImage,2016,419,
"D. P. Bavirisetti, R. Dhuli",1c9400d35860291be0116c2725d3447e12e25b74,Fusion of Infrared and Visible Sensor Images Based on Anisotropic Diffusion and Karhunen-Loeve Transform,IEEE Sensors Journal,2016,178,"Image fusion is a process of generating a more informative image from a set of source images. Major applications of image fusion are in navigation and military. Here, infrared and visible sensors are used to capture complementary images of the targeted scene. The complementary information of these source images has to be integrated into a single image using some fusion algorithms. The aim of any fusion method is to transfer maximum information from the source images to the fused image with a minimum information loss. It has to minimize the artifacts in the fused image. In this paper, we propose a new edge preserving image fusion method for infrared and visible sensor images. Anisotropic diffusion is used to decompose the source images into approximation and detail layers. Final detail and approximation layers are calculated with the help of Karhunen-Loeve transform and weighted linear superposition, respectively. A fused image is generated from the linear combination of final detail and approximation layers. Performance of the proposed algorithm is assessed with the help of petrovic metrics. The results of the proposed algorithm are compared with the traditional and recent image fusion algorithms. Results reveal that the proposed method outperforms the existing methods."
"J. Treiber, N. White, T. Steed, H. Bartsch, D. Holland, N. Farid, C. McDonald, B. Carter, A. Dale, Clark C. Chen",622b8294a9dc05d197bc776628c6690d47cdef51,Characterization and Correction of Geometric Distortions in 814 Diffusion Weighted Images,PLoS ONE,2016,91,"Introduction Diffusion Weighted Imaging (DWI), which is based on Echo Planar Imaging (EPI) protocols, is becoming increasingly important for neurosurgical applications. However, its use in this context is limited in part by significant spatial distortion inherent to EPI. Method We evaluated an efficient algorithm for EPI distortion correction (EPIC) across 814 DWI scans from 250 brain tumor patients and quantified the magnitude of geometric distortion for whole brain and multiple brain regions. Results Evaluation of the algorithm’s performance revealed significantly higher mutual information between T1-weighted pre-contrast images and corrected b = 0 images than the uncorrected b = 0 images (p < 0.001). The distortion magnitude across all voxels revealed a median EPI distortion effect of 2.1 mm, ranging from 1.2 mm to 5.9 mm, the 5th and 95th percentile, respectively. Regions adjacent to bone-air interfaces, such as the orbitofrontal cortex, temporal poles, and brain stem, were the regions most severely affected by DWI distortion. Conclusion Using EPIC to estimate the degree of distortion in 814 DWI brain tumor images enabled the creation of a topographic atlas of DWI distortion across the brain. The degree of displacement of tumors boundaries in uncorrected images is severe but can be corrected for using EPIC. Our results support the use of distortion correction to ensure accurate and careful application of DWI to neurosurgical practice."
"G. Steenkiste, B. Jeurissen, J. Veraart, A. D. den Dekker, P. Parizel, D. Poot, Jan Sijbers",4b73f2a395ca2cbe41dd16cc83285debd2a439f8,Super‐resolution reconstruction of diffusion parameters from diffusion‐weighted images with different slice orientations,Magnetic Resonance in Medicine,2016,42,"Diffusion MRI is hampered by long acquisition times, low spatial resolution, and a low signal‐to‐noise ratio. Recently, methods have been proposed to improve the trade‐off between spatial resolution, signal‐to‐noise ratio, and acquisition time of diffusion‐weighted images via super‐resolution reconstruction (SRR) techniques. However, during the reconstruction, these SRR methods neglect the q‐space relation between the different diffusion‐weighted images."
"B. Hansen, A. R. Khan, N. Shemesh, T. Lund, R. Sangill, S. Eskildsen, L. Østergaard, S. Jespersen",c211299261252758866addda6169da45c931c2f0,White matter biomarkers from fast protocols using axially symmetric diffusion kurtosis imaging,NMR in Biomedicine,2016,35,"White matter tract integrity (WMTI) can characterize brain microstructure in areas with highly aligned fiber bundles. Several WMTI biomarkers have now been validated against microscopy and provided promising results in studies of brain development and aging, as well as in a number of brain disorders. Currently, WMTI is mostly used in dedicated animal studies and clinical studies of slowly progressing diseases, and has not yet emerged as a routine clinical tool. To this end, a less data intensive experimental method would be beneficial by enabling high resolution validation studies, and ease clinical applications by speeding up data acquisition compared with typical diffusion kurtosis imaging (DKI) protocols utilized as part of WMTI imaging."
"Zhanning Gao, Jianru Xue, Wen-gang Zhou, Shanmin Pang, Q. Tian",16086f4378a7439c2bfd7e41fc1f7ffd443b3df0,Democratic Diffusion Aggregation for Image Retrieval,IEEE transactions on multimedia,2016,32,"Content-based image retrieval is an important research topic in the multimedia field. In large-scale image search using local features, image features are encoded and aggregated into a compact vector to avoid indexing each feature individually. In the aggregation step, sum-aggregation is wildly used in many existing works and demonstrates promising performance. However, it is based on a strong and implicit assumption that the local descriptors of an image are identically and independently distributed in descriptor space and image plane. To address this problem, we propose a new aggregation method named democratic diffusion aggregation (DDA) with weak spatial context embedded. The main idea of our aggregation method is to re-weight the embedded vectors before sum-aggregation by considering the relevance among local descriptors. Different from previous work, by conducting a diffusion process on the improved kernel matrix, we calculate the weighting coefficients more efficiently without any iterative optimization. Besides considering the relevance of local descriptors from different images, we also discuss an efficient query fusion strategy which uses the initial top-ranked image vectors to enhance the retrieval performance. Experimental results show that our aggregation method exhibits much higher efficiency (about × 14 faster) and better retrieval accuracy compared with previous methods, and the query fusion strategy consistently improves the retrieval quality."
"S. Tebini, Zouhair Mbarki, H. Seddik, E. B. Braiek",2ca22262409c742cfe20fff2ff99233e1023ee24,Rapid and efficient image restoration technique based on new adaptive anisotropic diffusion function,Digit. Signal Process.,2016,30,
"Hossein Khodabakhshi Rafsanjani, M. Sedaaghi, S. Saryazdi",e129cd083c25cf23df0c8d33a69fbde98db39776,Efficient diffusion coefficient for image denoising,Computers and Mathematics with Applications,2016,22,
"Tsukasa Yoshida, A. Urikura, Kensei Shirata, Y. Nakaya, S. Terashima, Y. Hosokawa",fc00b802dc5e7975adb4652b11516339c4a105fa,Image quality assessment of single-shot turbo spin echo diffusion-weighted imaging with parallel imaging technique: a phantom study.,British Journal of Radiology,2016,21,"OBJECTIVE
This study aimed to evaluate the image quality and apparent diffusion coefficient (ADC) values of single-shot turbo spin echo (TSE) diffusion-weighted (DW) images obtained using a parallel imaging (PI) technique.


METHODS
All measurements were performed on a 3.0-T whole-body MRI system and 32-channel phased-array coil. Signal-to-noise ratio (SNR) and ADC values were measured with a DW imaging (DWI) phantom comprising granulated sugar and agar. The SNRs were calculated using a subtraction method and compared among TSE-DW images at acceleration factors (AFs) of 1-4. Image blur was visually assessed on TSE-DW images of a pin phantom at AFs of 1-4. The ADC values were calculated using DW images with b = 0 and 1000 s mm(-2). The ADC values of TSE-DW images and echo-planar imaging EPI-DW images were compared.


RESULTS
The SNRs decreased as AFs increased, despite selecting the shortest echo time. A lower AF caused increased image blur in the phase-encoding direction. The ADC values of TSE-DWI tended to be lower than those of EPI-DWI, and AFs of 3 and 4 yielded variable ADC values on TSE-DW images.


CONCLUSION
TSE-DWI with an AF of 3 or 4 yielded reduced SNRs; in addition, the image noise and artefacts associated with PI technique may have affected ADC measurements, despite improving image blur in the phase-encoding direction.


ADVANCES IN KNOWLEDGE
Optimizing the imaging parameters of TSE-DWI is useful for providing good image quality and accurate ADC measurements."
"M. Pizzolato, Rutger Fick, T. Boutelier, R. Deriche",18211c3ea4f90e916d6ac5f4d66329ad25624645,Noise Floor Removal via Phase Correction of Complex Diffusion-Weighted Images: Influence on DTI and q-Space Metrics,International Conference on Medical Image Computing and Computer-Assisted Intervention,2016,17,
"Maryam Seif, Laila-Yasmin Mani, Huanxiang Lu, C. Boesch, M. Reyes, B. Vogt, P. Vermathen",792cc0f0eddf291a8c6967240883a688108597bf,Diffusion tensor imaging of the human kidney: Does image registration permit scanning without respiratory triggering?,Journal of Magnetic Resonance Imaging,2016,14,To investigate if image registration of diffusion tensor imaging (DTI) allows omitting respiratory triggering for both transplanted and native kidneys
"Michael J. Purcell, Manish Kumar, S. Rand",dcc87757de7112c39566fe6c51bbcf2bd9e63792,Holographic imaging through a scattering medium by diffuser-assisted statistical averaging,SPIE OPTO,2016,12,"The ability to image through a scattering or diffusive medium such as tissue or hazy atmosphere is a goal which has garnered extensive attention from the scientific community. Existing imaging methods in this field make use of phase conjugation, time of flight, iterative wave-front shaping or statistical averaging approaches, which tend to be either time consuming or complicated to implement. We introduce a novel and practical way of statistical averaging which makes use of a rotating ground glass diffuser to nullify the adverse effects caused by speckle introduced by a first static diffuser / aberrator. This is a Fourier transform-based, holographic approach which demonstrates the ability to recover detailed images and shows promise for further remarkable improvement. The present experiments were performed with 2D flat images, but this method could be easily adapted for recovery of 3D extended object information. The simplicity of the approach makes it fast, reliable, and potentially scalable as a portable technology. Since imaging through a diffuser has direct applications in biomedicine and defense technologies this method may augment advanced imaging capabilities in many fields."
Huan Han,fbd53a9975665f7afdeb06a45c1507ba1679638d,A variational model with fractional-order regularization term arising in registration of diffusion tensor image,,2016,11,"In this paper, a new variational model with fractional-order regularization term arising in registration of diffusion tensor image(DTI) is presented. Moreover, the existence of its solution is proved to ensure that there is a regular solution for this model. Furthermore, three numerical tests are also performed to show the effectiveness of this model."
"Z. Portakal, S. Shermer, C. Jenkins, E. Spezi, T. Perrett, N. Tunçel, Jonathan Phillips",8f4fa77c0abf23ebd0f50123a37a4927b5c80a6d,Design and characterization of tissue‐mimicking gel phantoms for diffusion kurtosis imaging,Medical Physics (Lancaster),2016,11,"PURPOSE
The aim of this work was to create tissue-mimicking gel phantoms appropriate for diffusion kurtosis imaging (DKI) for quality assurance, protocol optimization, and sequence development.


METHODS
A range of agar, agarose, and polyvinyl alcohol phantoms with concentrations ranging from 1.0% to 3.5%, 0.5% to 3.0%, and 10% to 20%, respectively, and up to 3 g of glass microspheres per 100 ml were created. Diffusion coefficients, excess kurtosis values, and relaxation rates were experimentally determined.


RESULTS
The kurtosis values for the plain gels ranged from 0.05 with 95% confidence interval (CI) of (0.029,0.071) to 0.216(0.185,0.246), well below the kurtosis values reported in the literature for various tissues. The addition of glass microspheres increased the kurtosis of the gels with values up to 0.523(0.465,0.581) observed for gels with the highest concentration of microspheres. Repeat scans of some of the gels after more than 6 months of storage at room temperature indicate changes in the diffusion parameters of less than 10%. The addition of the glass microspheres reduces the apparent diffusion coefficients (ADCs) and increases the longitudinal and transverse relaxation rates, but the values remain comparable to those for plain gels and tissue, with ADCs observed ranging from 818(585,1053) × 10-6  mm2 /s to 2257(2118,2296) × 10-6  mm2 /s, R1 values ranging from 0.34(0.32,0.35) 1/s to 0.51(0.50,0.52) 1/s, and R2 values ranging from 9.69(9.34,10.04) 1/s to 33.07(27.10, 39.04) 1/s.


CONCLUSIONS
Glass microspheres can be used to effectively modify diffusion properties of gel phantoms and achieve a range of kurtosis values comparable to those reported for a variety of tissues."
Minghua Lin,1680fbe23b92b83cdd83e1ac665cb3e5590b3def,On a determinantal inequality arising from diffusion tensor imaging,,2016,10,"In comparing geodesics induced by different metrics, Audenaert formulated the following determinantal inequality 
$$\det(A^2+|BA|)\le \det(A^2+AB),$$ where $A, B$ are $n\times n$ positive semidefinite matrices. We complement his result by proving 
$$\det(A^2+|AB|)\ge \det(A^2+AB).$$ Our proofs feature the fruitful interplay between determinantal inequalities and majorization relations. Some related questions are mentioned."
J. Angulo,9f827f4a9f727026315e0931a2ce614d9925ab93,Generalised morphological image diffusion,,2016,8,
"Jens Sjölund, A. Eklund, E. Özarslan, H. Knutsson",847769ca65ddd0bfb795176127dd0a961e0f821f,Gaussian process regression can turn non-uniform and undersampled diffusion MRI data into diffusion spectrum imaging,IEEE International Symposium on Biomedical Imaging,2016,8,"We propose to use Gaussian process regression to accurately estimate the diffusion MRI signal at arbitrary locations in q-space. By estimating the signal on a grid, we can do synthetic diffusion spectrum imaging: reconstructing the ensemble averaged propagator (EAP) by an inverse Fourier transform. We also propose an alternative reconstruction method guaranteeing a nonnegative EAP that integrates to unity. The reconstruction is validated on data simulated from two Gaussians at various crossing angles. Moreover, we demonstrate on non-uniformly sampled in vivo data that the method is far superior to linear interpolation, and allows a drastic undersampling of the data with only a minor loss of accuracy. We envision the method as a potential replacement for standard diffusion spectrum imaging, in particular when acquistion time is limited."
"A. Araújo, S. Barbeiro, E. Cuesta, Á. Durán",690a450821b25c841f84eadbef03e981c7c2d893,Cross-Diffusion Systems for Image Processing: I. The Linear Case,Journal of Mathematical Imaging and Vision,2016,8,
"Huan Han, Huan-Song Zhou",a4b1ac0aa1bab81f525131c055254cf521957a37,A variational problem arising in registration of diffusion tensor images,,2016,7,
"A. Araújo, S. Barbeiro, E. Cuesta, Á. Durán",b785610e9c28a4cefc27c753be8e754ffacb73a4,Cross-Diffusion Systems for Image Processing: II. The Nonlinear Case,Journal of Mathematical Imaging and Vision,2016,7,
"V. B. Surya Prasath, D. Vorotnikov",20d8817db81d2486f5d895d7f97ae67730be76b9,On time adaptive critical variable exponent vectorial diffusion flows and their applications in image processing I: Analysis,,2016,7,
"Subi Jain, R. K. Ray",93dab4fdab9e13e531a568b099381d6baafb625b,An Alternative Framework of Anisotropic Diffusion for Image Denoising,International Conference on Information and Communicatiaon Technology,2016,6,"This paper deals with an anisotropic diffusion based noise removal technique which utilizes the new diffusion function based on tangent sigmoid function. A local edge indicator function based on local structure tensor is also used in the proposed technique, to reduce the noise and detection of edges in digital images. From the experimental results, we observe that the proposed method is better and near to the other state-of-the-art approaches, in terms of both qualitatively and quantitatively. Numerical tests were performed on various images, which are corrupted by Gaussian noise and results illustrate that the proposed approach is more efficient than existing one."
"Wensen Feng, P. Qiao, Xuanyang Xi, Yunjin Chen",5c1ca0b42ef248af450170cb841a3fb00977d6d5,Image Denoising via Multiscale Nonlinear Diffusion Models,SIAM Journal of Imaging Sciences,2016,5,"Image denoising is a fundamental operation in image processing and holds considerable practical importance for various real-world applications. Arguably several thousands of papers are dedicated to image denoising. In the past decade, sate-of-the-art denoising algorithm have been clearly dominated by non-local patch-based methods, which explicitly exploit patch self-similarity within image. However, in recent two years, discriminatively trained local approaches have started to outperform previous non-local models and have been attracting increasing attentions due to the additional advantage of computational efficiency. Successful approaches include cascade of shrinkage fields (CSF) and trainable nonlinear reaction diffusion (TNRD). These two methods are built on filter response of linear filters of small size using feed forward architectures. Due to the locality inherent in local approaches, the CSF and TNRD model become less effective when noise level is high and consequently introduces some noise artifacts. In order to overcome this problem, in this paper we introduce a multi-scale strategy. To be specific, we build on our newly-developed TNRD model, adopting the multi-scale pyramid image representation to devise a multi-scale nonlinear diffusion process. As expected, all the parameters in the proposed multi-scale diffusion model, including the filters and the influence functions across scales, are learned from training data through a loss based approach. Numerical results on Gaussian and Poisson denoising substantiate that the exploited multi-scale strategy can successfully boost the performance of the original TNRD model with single scale. As a consequence, the resulting multi-scale diffusion models can significantly suppress the typical incorrect features for those noisy images with heavy noise."
"P. Guidotti, Yuanzhen Shao",740af74ae7fefd4fbcc65a26d81d56b584413752,Wellposedness of a nonlocal nonlinear diffusion equation of image processing,,2016,4,
"T. Butler-Yeoman, Marcus Frean, C. Hollitt, D. Hogg, M. Johnston-Hollitt",44d1b2d036394a63754f55240e00cc45864c5183,Detecting Diffuse Sources in Astronomical Images,,2016,4,"We present an algorithm capable of detecting diffuse, dim sources of any size in an astronomical image. These sources often defeat traditional methods for source finding, which expand regions around points of high intensity. Extended sources often have no bright points and are only detectable when viewed as a whole, so a more sophisticated approach is required. Our algorithm operates at all scales simultaneously by considering a tree of nested candidate bounding boxes, and inverts a hierarchical Bayesian generative model to obtain the probability of sources existing at given locations and sizes. This model naturally accommodates the detection of nested sources, and no prior knowledge of the distribution of a source, or even the background, is required. The algorithm scales nearly linear with the number of pixels making it feasible to run on large images, and requires minimal parameter tweaking to be effective. We demonstrate the algorithm on several types of astronomical and artificial images."
"A. Barucci, R. Carpi, M. Esposito, M. Olmastroni, G. Zatelli",49fb1f792e1ea466ed10431e6e079672a840cfa6,Diffusion-Weighted MR imaging: Clinical applications of kurtosis analysis to prostate cancer,,2016,2,"Magnetic resonance imaging technique known as DWI (diffusion-weighted imaging) allows measurement of water diffusivity on a pixel basis for evaluating pathology throughout the body and is now routinely incorporated into many body MRI protocols, mainly in oncology. Indeed water molecules motion reflects the interactions with other molecules, membranes, cells, and in general the interactions with the environment. Microstructural changes as e.g. cellular organization and/or integrity then affect the motion of water molecules, and consequently alter the water diffusion properties measured by DWI. Then DWI technique can be used to extract information about tissue organization at the cellular level indirectly from water motion. In general the signal intensity in DWI can be quantified by using a parameter known as ADC (Apparent Diffusion Coefficient) emphasizing that it is not the real diffusion coefficient, which is a measure of the average water molecular motion. In the simplest models, the distribu- tion of a water molecule diffusing in a certain period of time is considered to have a Gaussian form with its width proportional to the ADC. However, water in biological structures often displays non-Gaussian diffusion behavior, consequently the DWI signal shows a more complex behavior that need to be modeled following different approaches. In this work we explore the possibility to quantify the degree to which water diffusion in biologic tissues is non-Gaussian introducing the AKC parameter (Apparent Kurtosis Coefficient). In this work we have realized DWI non-Gaussian diffusion maps to be used in the clinical routine along with standard ADC maps, giving to the radiologist another tool to explore how much structure inside a voxel is organized. In particular in this work some prostate DWI examples have been analyzed and will be shown."
"T. Bretschneider, Cheng-Jin Du, C. M. Elliott, T. Ranner, B. Stinner",fa6aba3dfce6c62b4f8c95be8859f61f7080db68,Solving reaction-diffusion equations on evolving surfaces defined by biological image data,,2016,2,"We present a computational approach for solving reaction-diffusion equations on evolving surfaces which have been obtained from cell image data. It is based on finite element spaces defined on surface triangulations extracted from time series of 3D images. A model for the transport of material between the subsequent surfaces is required where we postulate a velocity in normal direction. We apply the technique to image data obtained from a spreading neutrophil cell. By simulating FRAP experiments we investigate the impact of the evolving geometry on the recovery. We find that for idealised FRAP conditions, changes in membrane geometry, easily account for differences of $\times 10$ in recovery half-times, which shows that experimentalists must take great care when interpreting membrane photobleaching results. We also numerically solve an activator -- depleted substrate system and report on the effect of the membrane movement on the pattern evolution."
S. Assili,475e2a89715d869e6e15febaa8ba7d583aae3a15,Diffusion and Perfusion Magnetic Resonance Imaging:Fundamentals and Advances,,2016,1,"Over the past few decades, magnetic resonance imaging has been utilized as a powerful imaging modality to evaluate the structure and function of various organs in the human body,such as the brain. Additionally, diffusion and perfusion MR imaging have been increasingly used in neurovascular clinical applications. In diffusion-weighted magnetic resonance imaging, the mobility of water molecules is explored in order to obtain information about the microscopic behavior of the tissues. In contrast, perfusion weighted imaging uses tracers to exploit hemodynamic status, which enables researchers and clinicians to consider this imaging modality as an early biomarker of certain brain diseases. In this review, the fundamentals of physics for diffusion and perfusion MR imaging both of which are highly sensitive to microenvironmental alterations at the cellular level as well as their application in the treatment of aging, Alzheimer's disease, brain tumors and cerebral ischemic injury were discussed."
"H. Cardona, Mauricio A Álvarez, Á. Orozco",665700461f1b92f7bce91440967bbe71ed92b253,A Tucker decomposition process for probabilistic modeling of diffusion magnetic resonance imaging,ArXiv,2016,0,"Diffusion magnetic resonance imaging (dMRI) is an emerging medical technique used for describing water diffusion in an organic tissue. Typically, rank-2 tensors quantify this diffusion. From this quantification, it is possible to calculate relevant scalar measures (i.e. fractional anisotropy and mean diffusivity) employed in clinical diagnosis of neurological diseases. Nonetheless, 2nd-order tensors fail to represent complex tissue structures like crossing fibers. To overcome this limitation, several researchers proposed a diffusion representation with higher order tensors (HOT), specifically 4th and 6th orders. However, the current acquisition protocols of dMRI data allow images with a spatial resolution between 1 $mm^3$ and 2 $mm^3$. This voxel size is much smaller than tissue structures. Therefore, several clinical procedures derived from dMRI may be inaccurate. Interpolation has been used to enhance resolution of dMRI in a tensorial space. Most interpolation methods are valid only for rank-2 tensors and a generalization for HOT data is missing. In this work, we propose a novel stochastic process called Tucker decomposition process (TDP) for performing HOT data interpolation. Our model is based on the Tucker decomposition and Gaussian processes as parameters of the TDP. We test the TDP in 2nd, 4th and 6th rank HOT fields. For rank-2 tensors, we compare against direct interpolation, log-Euclidean approach and Generalized Wishart processes. For rank-4 and rank-6 tensors we compare against direct interpolation. Results obtained show that TDP interpolates accurately the HOT fields and generalizes to any rank."
"Yunjin Chen, T. Pock",eb04068416ade86de63cf9d9939e14d0bc9b96f9,Trainable Nonlinear Reaction Diffusion: A Flexible Framework for Fast and Effective Image Restoration,IEEE Transactions on Pattern Analysis and Machine Intelligence,2015,970,"Image restoration is a long-standing problem in low-level computer vision with many interesting applications. We describe a flexible learning framework based on the concept of nonlinear reaction diffusion models for various image restoration problems. By embodying recent improvements in nonlinear diffusion models, we propose a dynamic nonlinear reaction diffusion model with time-dependent parameters (i.e., linear filters and influence functions). In contrast to previous nonlinear diffusion models, all the parameters, including the filters and the influence functions, are simultaneously learned from training data through a loss based approach. We call this approach TNRD—Trainable Nonlinear Reaction Diffusion. The TNRD approach is applicable for a variety of image restoration tasks by incorporating appropriate reaction force. We demonstrate its capabilities with three representative applications, Gaussian image denoising, single image super resolution and JPEG deblocking. Experiments show that our trained nonlinear diffusion models largely benefit from the training of the parameters and finally lead to the best reported performance on common test datasets for the tested applications. Our trained models preserve the structural simplicity of diffusion models and take only a small number of diffusion steps, thus are highly efficient. Moreover, they are also well-suited for parallel computation on GPUs, which makes the inference procedure extremely fast."
"Yunjin Chen, Wei Yu, T. Pock",177bded5ff0c9a621f29ac1e7d920e8a3ee7bab8,On learning optimized reaction diffusion processes for effective image restoration,Computer Vision and Pattern Recognition,2015,291,"For several decades, image restoration remains an active research topic in low-level computer vision and hence new approaches are constantly emerging. However, many recently proposed algorithms achieve state-of-the-art performance only at the expense of very high computation time, which clearly limits their practical relevance. In this work, we propose a simple but effective approach with both high computational efficiency and high restoration quality. We extend conventional nonlinear reaction diffusion models by several parametrized linear filters as well as several parametrized influence functions. We propose to train the parameters of the filters and the influence functions through a loss based approach. Experiments show that our trained nonlinear reaction diffusion models largely benefit from the training of the parameters and finally lead to the best reported performance on common test datasets for image restoration. Due to their structural simplicity, our trained models are highly efficient and are also well-suited for parallel computation on GPUs."
"Gabriel Ramos-Llordén, G. Vegas-Sánchez-Ferrero, M. Martín-Fernández, C. Alberola-López, S. Aja‐Fernández",867cc4fef3cde9f541ecfa96b9a232b1cf7a9317,Anisotropic Diffusion Filter With Memory Based on Speckle Statistics for Ultrasound Images,IEEE Transactions on Image Processing,2015,123,"Ultrasound (US) imaging exhibits considerable difficulties for medical visual inspection and for development of automatic analysis methods due to speckle, which negatively affects the perception of tissue boundaries and the performance of automatic segmentation methods. With the aim of alleviating the effect of speckle, many filtering techniques are usually considered as a preprocessing step prior to automatic analysis methods or visual inspection. Most of the state-of-the-art filters try to reduce the speckle effect without considering its relevance for the characterization of tissue nature. However, the speckle phenomenon is the inherent response of echo signals in tissues and can provide important features for clinical purposes. This loss of information is even magnified due to the iterative process of some speckle filters, e.g., diffusion filters, which tend to produce over-filtering because of the progressive loss of relevant information for diagnostic purposes during the diffusion process. In this paper, we propose an anisotropic diffusion filter with a probabilistic-driven memory mechanism to overcome the over-filtering problem by following a tissue selective philosophy. In particular, we formulate the memory mechanism as a delay differential equation for the diffusion tensor whose behavior depends on the statistics of the tissues, by accelerating the diffusion process in meaningless regions and including the memory effect in regions where relevant details should be preserved. Results both in synthetic and real US images support the inclusion of the probabilistic memory mechanism for maintaining clinical relevant structures, which are removed by the state-of-the-art filters."
"L. Zhang, Yuansheng Liu, F. Pareschi, Yushu Zhang, Kwok-wo Wong, R. Rovatti, G. Setti",227f6f3b5e96fe991f7cd039729d4197400464d9,On the Security of a Class of Diffusion Mechanisms for Image Encryption,IEEE Transactions on Cybernetics,2015,104,"The need for fast and strong image cryptosystems motivates researchers to develop new techniques to apply traditional cryptographic primitives in order to exploit the intrinsic features of digital images. One of the most popular and mature technique is the use of complex dynamic phenomena, including chaotic orbits and quantum walks, to generate the required key stream. In this paper, under the assumption of plaintext attacks we investigate the security of a classic diffusion mechanism (and of its variants) used as the core cryptographic primitive in some image cryptosystems based on the aforementioned complex dynamic phenomena. We have theoretically found that regardless of the key schedule process, the data complexity for recovering each element of the equivalent secret key from these diffusion mechanisms is only  ${O}$ (1). The proposed analysis is validated by means of numerical examples. Some additional cryptographic applications of this paper are also discussed."
"C. Bhushan, J. Haldar, Soyoung Choi, Anand A. Joshi, D. Shattuck, R. Leahy",d2aa2d38c93d9c769ae1d537d6eddd814f9acd7a,Co-registration and distortion correction of diffusion and anatomical images based on inverse contrast normalization,NeuroImage,2015,73,
"Yuansheng Liu, L. Zhang, Jia Wang, Yushu Zhang, Kwok-wo Wong",60f6f969a9af63b9051128fc0b2afad040f1031b,Chosen-plaintext attack of an image encryption scheme based on modified permutation–diffusion structure,ArXiv,2015,62,
"V. Bhateja, A. Tripathi, Anurag Gupta, A. Lay-Ekuakille",3c26d82a22c978aa71cbe0e8ab43117229dd414a,Speckle suppression in SAR images employing modified anisotropic diffusion filtering in wavelet domain for environment monitoring,,2015,45,
"Xinwei Shi, Xiaodong Ma, Wenchuan Wu, F. Huang, C. Yuan, Hua Guo",42508b744ebdf60d829791df0b4a56376c3d16b7,Parallel imaging and compressed sensing combined framework for accelerating high‐resolution diffusion tensor imaging using inter‐image correlation,Magnetic Resonance in Medicine,2015,44,"Increasing acquisition efficiency is always a challenge in high‐resolution diffusion tensor imaging (DTI), which has low signal‐to‐noise ratio and is sensitive to reconstruction artifacts. In this study, a parallel imaging (PI) and compressed sensing (CS) combined framework is proposed, which features motion error correction, PI calibration, and sparsity model using inter‐image correlation tailored for high‐resolution DTI."
"O. Bernus, A. Radjenovic, M. Trew, I. LeGrice, G. Sands, D. Magee, B. Smaill, S. Gilbert",4a83ab374b911fb64b7ab7c0a1451e048c0eaaf8,Comparison of diffusion tensor imaging by cardiovascular magnetic resonance and gadolinium enhanced 3D image intensity approaches to investigation of structural anisotropy in explanted rat hearts,Journal of Cardiovascular Magnetic Resonance,2015,41,
"Hongjiang Wei, M. Viallon, B. Delattre, K. Moulin, Feng Yang, P. Croisille, Yuemin M. Zhu",1e205d045f61191fd03a8ae444493fd8df10aa3b,Free-Breathing Diffusion Tensor Imaging and Tractography of the Human Heart in Healthy Volunteers Using Wavelet-Based Image Fusion,IEEE Transactions on Medical Imaging,2015,41,"Free-breathing cardiac diffusion tensor imaging (DTI) is a promising but challenging technique for the study of fiber structures of the human heart in vivo. This work proposes a clinically compatible and robust technique to provide three-dimensional (3-D) fiber architecture properties of the human heart. To this end, 10 short-axis slices were acquired across the entire heart using a multiple shifted trigger delay (TD) strategy under free breathing conditions. Interscan motion was first corrected automatically using a nonrigid registration method. Then, two post-processing schemes were optimized and compared: an algorithm based on principal component analysis (PCA) filtering and temporal maximum intensity projection (TMIP), and an algorithm that uses the wavelet-based image fusion (WIF) method. The two methods were applied to the registered diffusion-weighted (DW) images to cope with intrascan motion-induced signal loss. The tensor fields were finally calculated, from which fractional anisotropy (FA), mean diffusivity (MD), and 3-D fiber tracts were derived and compared. The results show that the comparison of the FA values (FAPCATMIP = 0.45 ±0.10, FAWIF = 0.42 ±0.05, P=0.06) showed no significant difference, while the MD values ( MDPCATMIP=0.83 ±0.12×10-3 mm2/s, MDWIF=0.74±0.05×10-3 mm2/s, P=0.028) were significantly different. Improved helix angle variations through the myocardium wall reflecting the rotation characteristic of cardiac fibers were observed with WIF. This study demonstrates that the combination of multiple shifted TD acquisitions and dedicated post-processing makes it feasible to retrieve in vivo cardiac tractographies from free-breathing DTI acquisitions. The substantial improvements were observed using the WIF method instead of the previously published PCATMIP technique."
"V. Zipunnikov, S. Greven, H. Shou, B. Caffo, D. Reich, C. Crainiceanu",f74ac289347e9e754c45c96e024910d6f221d018,Longitudinal High-Dimensional Principal Components Analysis with Application to Diffusion Tensor Imaging of Multiple Sclerosis.,Annals of Applied Statistics,2015,30,"We develop a flexible framework for modeling high-dimensional imaging data observed longitudinally. The approach decomposes the observed variability of repeatedly measured high-dimensional observations into three additive components: a subject-specific imaging random intercept that quantifies the cross-sectional variability, a subject-specific imaging slope that quantifies the dynamic irreversible deformation over multiple realizations, and a subject-visit specific imaging deviation that quantifies exchangeable effects between visits. The proposed method is very fast, scalable to studies including ultra-high dimensional data, and can easily be adapted to and executed on modest computing infrastructures. The method is applied to the longitudinal analysis of diffusion tensor imaging (DTI) data of the corpus callosum of multiple sclerosis (MS) subjects. The study includes 176 subjects observed at 466 visits. For each subject and visit the study contains a registered DTI scan of the corpus callosum at roughly 30,000 voxels."
P. Guidotti,656c49d2fae6a3d97b51797703dbfc74e056d7be,Anisotropic diffusions of image processing from Perona–Malik on,,2015,24,"Many reasons can be cited for the desire to harness the power of nonlinear anisotropic diffusion in image processing. Perona and Malik proposed one of the pioneering models which, while numerically viable, proves mathematically ill-posed. This discrepancy between its analytical properties and those of its numerical implementations spurred a significant amount of research in the past twenty years or so. An overview of the latter is the topic of this article."
"W. Foltz, D. Porter, A. Simeonov, A. Aleong, D. Jaffray, P. Chung, Kathy Han, C. Ménard",d841964ec91228c448db11c97cca8094a706d3e0,Readout-segmented echo-planar diffusion-weighted imaging improves geometric performance for image-guided radiation therapy of pelvic tumors.,Radiotherapy and Oncology,2015,24,
"D. Prandi, A. Remizov, R. Chertovskih, U. Boscain, J. Gauthier",6fbf51a4ca5b22ed72942d0868c31cd02ef09aac,Highly Corrupted Image Inpainting Through Hypoelliptic Diffusion,Journal of Mathematical Imaging and Vision,2015,23,
"Maryam Seif, Huanxiang Lu, C. Boesch, M. Reyes, P. Vermathen",73bebf64aa300b30942183735fae8a568bb2ed0a,Image registration for triggered and non‐triggered DTI of the human kidney: Reduced variability of diffusion parameter estimation,Journal of Magnetic Resonance Imaging,2015,21,"To investigate if non‐rigid image‐registration reduces motion artifacts in triggered and non‐triggered diffusion tensor imaging (DTI) of native kidneys. A secondary aim was to determine, if improvements through registration allow for omitting respiratory‐triggering."
"Laurent Hoeltgen, J. Weickert",0163f906c758d17c7b8c039264d9be01e8a2fc8e,Why Does Non-binary Mask Optimisation Work for Diffusion-Based Image Compression?,Energy Minimization Methods in Computer Vision and Pattern Recognition,2015,19,
"Diwei Zhou, I. Dryden, A. Koloydenko, K. Audenaert, L. Bai",77ff706d082f0479fff4dac1742191c4bf05cc62,"Regularisation, interpolation and visualisation of diffusion tensor images using non-Euclidean statistics",,2015,16,"Practical statistical analysis of diffusion tensor images is considered, and we focus primarily on methods that use metrics based on Euclidean distances between powers of diffusion tensors. First, we describe a family of anisotropy measures based on a scale invariant power-Euclidean metric, which are useful for visualisation. Some properties of the measures are derived and practical considerations are discussed, with some examples. Second, we discuss weighted Procrustes methods for diffusion tensor imaging interpolation and smoothing, and we compare methods based on different metrics on a set of examples as well as analytically. We establish a key relationship between the principal-square-root-Euclidean metric and the size-and-shape Procrustes metric on the space of symmetric positive semi-definite tensors. We explain, both analytically and by experiments, why the size-and-shape Procrustes metric may be preferred in practical tasks of interpolation, extrapolation and smoothing, especially when observed tensors are degenerate or when a moderate degree of tensor swelling is desirable. Third, we introduce regularisation methodology, which is demonstrated to be useful for highlighting features of prior interest and potentially for segmentation. Finally, we compare several metrics in a data set of human brain diffusion-weighted magnetic resonance imaging, and point out similarities between several of the non-Euclidean metrics but important differences with the commonly used Euclidean metric."
"M. Palombo, Silvia Gentili, M. Bozzali, E. Macaluso, S. Capuani",792a3cc9f75b4eff38f38e6e13f44d49cf1f61ad,New insight into the contrast in diffusional kurtosis images: Does it depend on magnetic susceptibility?,Magnetic Resonance in Medicine,2015,15,"In this MRI study, diffusional kurtosis imaging (DKI) and T2* multiecho relaxometry were measured from the white matter (WM) of human brains and correlated with each other, with the aim of investigating the influence of magnetic‐susceptibility (ΔχH2O‐TISSUE) on the contrast."
"V. B. Surya Prasath, J. M. Urbano, D. Vorotnikov",efd6682e38cee2f87f6c5e8ab85122073054c069,Analysis of adaptive forward-backward diffusion flows with applications in image processing,,2015,15,"The nonlinear diffusion model introduced by Perona and Malik (1990 IEEE Trans. Pattern Anal. Mach. Intell. 12 629–39) is well suited to preserve salient edges while restoring noisy images. This model overcomes well-known edge smearing effects of the heat equation by using a gradient dependent diffusion function. Despite providing better denoizing results, the analysis of the PM scheme is difficult due to the forward-backward nature of the diffusion flow. We study a related adaptive forward-backward diffusion equation which uses a mollified inverse gradient term engrafted in the diffusion term of a general nonlinear parabolic equation. We prove a series of existence, uniqueness and regularity results for viscosity, weak and dissipative solutions for such forward-backward diffusion flows. In particular, we introduce a novel functional framework for wellposedness of flows of total variation type. A set of synthetic and real image processing examples are used to illustrate the properties and advantages of the proposed adaptive forward-backward diffusion flows."
"Pascal Peter, J. Weickert",0798b8ac729fce30d3649fb614b52f2719dc2837,Compressing Images with Diffusion- and Exemplar-Based Inpainting,Scale Space and Variational Methods in Computer Vision,2015,14,
"Subi Jain, R. K. Ray, A. Bhavsar",8001300346cee16afaf232eaa23b31889b2e5dc1,Iterative solvers for image denoising with diffusion models: A comparative study,Computers and Mathematics with Applications,2015,13,
"Pascal Peter, J. Weickert, A. Munk, Tatyana Krivobokova, Housen Li",3729096f01fd522d167f2d930c90b9cd7f3474ac,Justifying Tensor-Driven Diffusion from Structure-Adaptive Statistics of Natural Images,Energy Minimization Methods in Computer Vision and Pattern Recognition,2015,12,
"Wei Yu, S. Heber, T. Pock",28c643bca3317caddeab33c89b3931ee27cb3cdc,Learning Reaction-Diffusion Models for Image Inpainting,German Conference on Pattern Recognition,2015,10,
"Cassiano O. Becker, S. Pequito, George J. Pappas, Michael B. Miller, Scott T. Grafton, D. Bassett, V. Preciado",7ec5d44c45c933855093c08a70c24af210030b15,Accurately Predicting Functional Connectivity from Diffusion Imaging,,2015,10,"Understanding the relationship between the dynamics of neural processes and the anatomical substrate of the brain is a central question in neuroscience. On the one hand, modern neuroimaging technologies, such as diffusion tensor imaging, can be used to construct structural graphs representing the architecture of white matter streamlines linking cortical and subcortical structures. On the other hand, temporal patterns of neural activity can be used to construct functional graphs representing temporal correlations between brain regions. Although some studies provide evidence that whole-brain functional connectivity is shaped by the underlying anatomy, the observed relationship between function and structure is weak, and the rules by which anatomy constrains brain dynamics remain elusive. In this article, we introduce a methodology to predict with high accuracy the functional connectivity of a subject at rest from his or her structural graph. Using our methodology, we are able to systematically unveil the role of structural paths in the formation of functional correlations. Furthermore, in our empirical evaluations, we observe that the eigen-modes of the predicted functional connectivity are aligned with activity patterns associated with different cognitive systems. Our work offers the potential to infer properties of brain dynamics in clinical or developmental populations with low tolerance for functional neuroimaging."
"F. Shi, Jian Cheng, Li Wang, P. Yap, D. Shen",4b1c89901ddabf37301e4ae212e54e08052f1c05,Super-Resolution Reconstruction of Diffusion-Weighted Images using 4D Low-Rank and Total Variation,The Workshop,2015,9,
"V. Prčkovska, M. Andorrà, P. Villoslada, E. Martínez-Heras, R. Duits, D. Fortin, P. Rodrigues, M. Descoteaux",2eea30ca7c6c38ec5d0a7b7b6f5f4510da50c540,Contextual Diffusion Image Post-processing Aids Clinical Applications,Visualization and Processing of Higher Order Descriptors for Multi-Valued Data,2015,9,
"Mohammed Khader, A. Hamza",a59bc4c36e5464b2ffb44f6d4416249d378d3e19,A multicomponent approach to nonrigid registration of diffusion tensor images,Applied intelligence (Boston),2015,9,
K. Audenaert,88d5c7aea50f92b15b918f929634abf8d5081deb,A Determinantal Inequality for the Geometric Mean with an Application in Diffusion Tensor Imaging,,2015,9,"We prove that for positive semidefinite matrices $A$ and $B$ the following determinantal inequality holds: \[ \det(I+A\#B)\le \det(I+A^{1/2}B^{1/2}), \] where $A\#B$ is the geometric mean of $A$ and $B$. We apply this inequality to the study of interpolation methods in diffusion tensor imaging."
"Alice P. Bates, Z. Khalid, R. Kennedy",fb11a0cc96e0b5218c216a026b8b7e74164f5436,An optimal dimensionality sampling scheme on the sphere for antipodal signals in diffusion magnetic resonance imaging,"IEEE International Conference on Acoustics, Speech, and Signal Processing",2015,8,"We propose a sampling scheme on the sphere and develop a corresponding spherical harmonic transform (SHT) for the accurate reconstruction of the diffusion signal in diffusion magnetic resonance imaging (dMRI). By exploiting the antipodal symmetry, we design a sampling scheme that requires the optimal number of samples on the sphere, equal to the degrees of freedom required to represent the antipodally symmetric band-limited diffusion signal in the spectral (spherical harmonic) domain. Compared with existing sampling schemes on the sphere that allow for the accurate reconstruction of the diffusion signal, the proposed sampling scheme reduces the number of samples required by a factor of two or more. We analyse the numerical accuracy of the proposed SHT and show through experiments that the proposed sampling allows for the accurate and rotationally invariant computation of the SHT to near machine precision accuracy."
"Henrik G. Jensen, F. Lauze, M. Nielsen, S. Darkner",17c4fe4eb2bc14d6ef826fe17e768462f4f78ed8,Locally Orderless Registration for Diffusion Weighted Images,International Conference on Medical Image Computing and Computer-Assisted Intervention,2015,7,
"Y. Pidopryhora, F. Lockman, J. Dickey, M. Rupen",918c00fa00b31be74335cde00a800671561aec7f,"HIGH-RESOLUTION IMAGES OF DIFFUSE NEUTRAL CLOUDS IN THE MILKY WAY. I. OBSERVATIONS, IMAGING, AND BASIC CLOUD PROPERTIES",,2015,7,"A set of diffuse interstellar clouds in the inner Galaxy within a few hundred parsecs of the Galactic plane has been observed at an angular resolution of ≈1&farcm;0 combining data from the NRAO Green Bank Telescope and the Very Large Array. At the distance of the clouds, the linear resolution ranges from ∼1.9 to ∼2.8 pc. These clouds have been selected to be somewhat outside of the Galactic plane, and thus are not confused with unrelated emission, but in other respects they are a Galactic population. They are located near the tangent points in the inner Galaxy, and thus at a quantifiable distance: 2.3 ≤ R ≤ 6.0 ?> kpc from the Galactic Center and − 1000 ≤ z ≤ + 610 ?> pc from the Galactic plane. These are the first images of the diffuse neutral H i clouds that may constitute a considerable fraction of the interstellar medium (ISM). Peak H i column densities lie in the range NH i = 0.8–2.9 × 1020 cm−2. Cloud diameters vary between about 10 and 100 pc, and their H i mass spans the range from less than a hundred to a few thousands M⊙. The clouds show no morphological consistency of any kind, except that their shapes are highly irregular. One cloud may lie within the hot wind from the nucleus of the Galaxy, and some clouds show evidence of two distinct thermal phases as would be expected from equilibrium models of the ISM."
"J. Moreno, V. B. Surya Prasath, D. Vorotnikov, Hugo Proença, K. Palaniappan",0b13c725b977bdc3dff830a9823d906317a259d2,Adaptive diffusion constrained total variation scheme with application to 'cartoon + texture + edge' image decomposition,ArXiv,2015,7,"We consider an image decomposition model involving a variational (minimization) problem and an evolutionary partial differential equation (PDE). We utilize a linear inhomogenuous diffusion constrained and weighted total variation (TV) scheme for image adaptive decomposition. An adaptive weight along with TV regularization splits a given image into three components representing the geometrical (cartoon), textural (small scale - microtextures), and edges (big scale - macrotextures). We study the wellposedness of the coupled variational-PDE scheme along with an efficient numerical scheme based on Chambolle's dual minimization method. We provide extensive experimental results in cartoon-texture-edges decomposition, and denoising as well compare with other related variational, coupled anisotropic diffusion PDE based methods."
"Yu Jin, J. JáJá, Rong Chen, E. Herskovits",29a04d4ae5bb7bf3e1eb29e42ea51b7e3ea398d7,A data-driven approach to extract connectivity structures from diffusion tensor imaging data,2015 IEEE International Conference on Big Data (Big Data),2015,6,"Diffusion Tensor Imaging (DTI) is an effective tool for the analysis of structural brain connectivity in normal development and in a broad range of brain disorders. However efforts to derive inherent characteristics of structural brain networks have been hampered by the very high dimensionality of the data, relatively small sample sizes, and the lack of widely acceptable connectivity-based regions of interests (ROIs). Typical approaches have focused either on regions defined by standard anatomical atlases that do not incorporate anatomical connectivity, or have been based on voxel-wise analysis, which results in loss of statistical power relative to structure-wise connectivity analysis. In this work, we propose a novel, computationally efficient iterative clustering method to generate connectivity-based whole-brain parcellations that converge to a stable parcellation in a few iterations. Our algorithm is based on a sparse representation of the whole brain connectivity matrix, which reduces the number of edges from around a half billion to a few million while incorporating the necessary spatial constraints. We show that the resulting regions in a sense capture the inherent connectivity information present in the data, and are stable with respect to initialization and the randomization scheme within the algorithm. These parcellations provide consistent structural regions across the subjects of population samples that are homogeneous with respect to anatomic connectivity. Our method also derives connectivity structures that can be used to distinguish between population samples with known different structural connectivity. In particular, new results in structural differences for different population samples such as Females vs Males, Normal Controls vs Schizophrenia, and different age groups in Normal Controls are also shown."
"C. Caiafa, F. Pestilli",e27e2cfad056e097df9b384fd4c956b9b0577869,Sparse multiway decomposition for analysis and modeling of diffusion imaging and tractography,,2015,6,"The number of neuroimaging data sets publicly available is growing at fast rate. The increase in availability and resolution of neuroimaging data requires modern approaches to signal processing for data analysis and results validation. We introduce the application of sparse multiway decomposition methods (Caiafa and Cichocki, 2012) to linearized neuroimaging models. We show that decomposed models are more compact but as accurate as full models and can be successfully used for fast data analysis. We focus as example on a recent model for the evaluation of white matter connectomes (Pestilli et al, 2014). We show that the multiway decomposed model achieves accuracy comparable to the full model, while requiring only a small fraction of the memory and compute time. The approach has implications for a majority of neuroimaging methods using linear approximations to measured signals."
"Yi Wang, Qian Yu, Zhexing Liu, T. Lei, Zhe Guo, Min Qi, Yangyu Fan",2816df930a115026fb87f114a98fb6ae35f91d6a,Evaluation on diffusion tensor image registration algorithms,Multimedia tools and applications,2015,5,
"A. Boroomand, M. Shafiee, F. Khalvati, M. Haider, A. Wong",0a3c6dc8b91128081f123d2e0359c440a7f8391c,"Noise-Compensated, Bias-Corrected Diffusion Weighted Endorectal Magnetic Resonance Imaging via a Stochastically Fully-Connected Joint Conditional Random Field Model",IEEE Transactions on Medical Imaging,2015,5,"Diffusion weighted magnetic resonance imaging (DW-MR) is a powerful tool in imaging-based prostate cancer screening and detection. Endorectal coils are commonly used in DW-MR imaging to improve the signal-to-noise ratio (SNR) of the acquisition, at the expense of significant intensity inhomogeneities (bias field) that worsens as we move away from the endorectal coil. The presence of bias field can have a significant negative impact on the accuracy of different image analysis tasks, as well as prostate tumor localization, thus leading to increased inter- and intra-observer variability. Retrospective bias correction approaches are introduced as a more efficient way of bias correction compared to the prospective methods such that they correct for both of the scanner and anatomy-related bias fields in MR imaging. Previously proposed retrospective bias field correction methods suffer from undesired noise amplification that can reduce the quality of bias-corrected DW-MR image. Here, we propose a unified data reconstruction approach that enables joint compensation of bias field as well as data noise in DW-MR imaging. The proposed noise-compensated, bias-corrected (NCBC) data reconstruction method takes advantage of a novel stochastically fully connected joint conditional random field (SFC-JCRF) model to mitigate the effects of data noise and bias field in the reconstructed MR data. The proposed NCBC reconstruction method was tested on synthetic DW-MR data, physical DW-phantom as well as real DW-MR data all acquired using endorectal MR coil. Both qualitative and quantitative analysis illustrated that the proposed NCBC method can achieve improved image quality when compared to other tested bias correction methods. As such, the proposed NCBC method may have potential as a useful retrospective approach for improving the consistency of image interpretations."
"Subi Jain, R. K. Ray",9a8edd53ea888d342e9d040815f375a504ffece1,A Non-linear Diffusion Based Partial Differential Equation Model for Noise Reduction in Images,,2015,4,
"C. Koay, P. Yeh, J. Ollinger, M. Irfanoglu, C. Pierpaoli, P. Basser, T. Oakes, G. Riedy",ff1d33c06aceca6b8ece78e8f888233cfb36b91c,Tract Orientation and Angular Dispersion Deviation Indicator (TOADDI): A framework for single-subject analysis in diffusion tensor imaging,NeuroImage,2015,2,
"I. Maximov, F. Grinberg, I. Neuner, N. Shah",eb70a4b63d5c0e63917da07566b57ceb4a6912ee,Robust diffusion imaging framework for clinical studies,,2015,2,"Clinical diffusion imaging requires short acquisition times and good image quality to permit its use in various medical applications. In turn, these demands require the development of a robust and efficient post-processing framework in order to guarantee useful and reliable results. However, multiple artefacts abound in in vivo measurements; from either subject such as cardiac pulsation, bulk head motion, respiratory motion and involuntary tics and tremor, or imaging hardware related problems, such as table vibrations, etc. These artefacts can severely degrade the resulting images and render diffusion analysis difficult or impossible. In order to overcome these problems, we developed a robust and efficient framework enabling the use of initially corrupted images from a clinical study. At the heart of this framework is an improved least trimmed squares diffusion tensor estimation algorithm that works well with severely degraded datasets with low signal-to-noise ratio. This approach has been compared with other diffusion imaging post-processing algorithms using simulations and in vivo experiments. Exploiting track-based spatial statistics analysis, we demonstrate that corrupted datasets can be restored and reused in further clinical studies rather than being discarded due to poor quality. The developed robust framework is shown to exhibit a high efficiency and accuracy and can, in principle, be exploited in other MR studies where artefact/outlier suppression is needed."
"P. Akshara, J. S. Paul",b25409e904a17ccf18ac35fe33bd9986ebaeebec,Image enhancement in intensity projected multichannel MRI using spatially adaptive directional anisotropic diffusion,ArXiv,2015,2,"Anisotropic Diffusion is widely used for noise reduction with simultaneous preservation of vascular structures in maximum intensity projected (MIP) angiograms. However, extension to minimum intensity projected (mIP) venograms in Susceptibility Weighted Imaging (SWI) poses difficulties due to spatially varying baseline. Here, we introduce a modified version of the directional anisotropic diffusion which allows us to simultaneously reduce the noise and enhance vascular structures reconstructed using both M/mIP angiograms. This method is based on spatial adaptation of the diffusion function, separately in the directions of the gradient, and along those of the minimum and maximum curvatures. The existing approach of directional anisotropic diffusion uses binary switched diffusion function to ensure diffusion along the direction of maximum curvature stopped near the vessel borders. Here, the choice of a threshold for detecting the upper limit of diffusion becomes difficult in the presence of spatially varying baseline. Also, the approach of using vesselness measure to steer the diffusion process results in structural discontinuities due to junction suppression in mIP. The merits of the proposed method include elimination of the need for an apriori choice of a threshold to detect the vessel, and problems due to junction suppression. The proposed method is also extended to multi-channel phase contrast angiogram."
"A. Gorokh, Yury Korolev, T. Valkonen",a472be7ad3fca7dc598a2f509be8a0b65253c74c,Diffusion Tensor Imaging with Deterministic Error Bounds,Journal of Mathematical Imaging and Vision,2015,1,
Jia Liu,24e62887f57beb541522f8b6d9d16d3c2f76552e,An improved EM algorithm for solving MLE in constrained diffusion kurtosis imaging of human brain,,2015,0,"The displacement distribution of a water molecular is characterized mathematically as Gaussianity without considering potential diffusion barriers and compartments. However, this is not true in real scenario: most biological tissues are comprised of cell membranes, various intracellular and extracellular spaces, and of other compartments, where the water diffusion is referred to have a non-Gaussian distribution. Diffusion kurtosis imaging (DKI), recently considered to be one sensitive biomarker, is an extension of diffusion tensor imaging, which quantifies the degree of non-Gaussianity of the diffusion. This work proposes an efficient scheme of maximum likelihood estimation (MLE) in DKI: we start from the Rician noise model of the signal intensities. By augmenting a Von-Mises distributed latent phase variable, the Rician likelihood is transformed to a tractable joint density without loss of generality. A fast computational method, an expectation-maximization (EM) algorithm for MLE is proposed in DKI. To guarantee the physical relevance of the diffusion kurtosis we apply the ternary quartic (TQ) parametrization to utilize its positivity, which imposes the upper bound to the kurtosis. A Fisher-scoring method is used for achieving fast convergence of the individual diffusion compartments. In addition, we use the barrier method to constrain the lower bound to the kurtosis. The proposed estimation scheme is conducted on both synthetic and real data with an objective of healthy human brain. We compared the method with the other popular ones with promising performance shown in the results."
"I. Oguz, Mahshid Farzinfar, J. Matsui, François Budin, Zhexing Liu, G. Gerig, H. Johnson, M. Styner",23136244a1292d17cb0f2d01b265c4f7bf4fa8b9,DTIPrep: quality control of diffusion-weighted images,Front. Neuroinform.,2014,218,"In the last decade, diffusion MRI (dMRI) studies of the human and animal brain have been used to investigate a multitude of pathologies and drug-related effects in neuroscience research. Study after study identifies white matter (WM) degeneration as a crucial biomarker for all these diseases. The tool of choice for studying WM is dMRI. However, dMRI has inherently low signal-to-noise ratio and its acquisition requires a relatively long scan time; in fact, the high loads required occasionally stress scanner hardware past the point of physical failure. As a result, many types of artifacts implicate the quality of diffusion imagery. Using these complex scans containing artifacts without quality control (QC) can result in considerable error and bias in the subsequent analysis, negatively affecting the results of research studies using them. However, dMRI QC remains an under-recognized issue in the dMRI community as there are no user-friendly tools commonly available to comprehensively address the issue of dMRI QC. As a result, current dMRI studies often perform a poor job at dMRI QC. Thorough QC of dMRI will reduce measurement noise and improve reproducibility, and sensitivity in neuroimaging studies; this will allow researchers to more fully exploit the power of the dMRI technique and will ultimately advance neuroscience. Therefore, in this manuscript, we present our open-source software, DTIPrep, as a unified, user friendly platform for thorough QC of dMRI data. These include artifacts caused by eddy-currents, head motion, bed vibration and pulsation, venetian blind artifacts, as well as slice-wise and gradient-wise intensity inconsistencies. This paper summarizes a basic set of features of DTIPrep described earlier and focuses on newly added capabilities related to directional artifacts and bias analysis."
"D. Alexander, D. Zikic, Jiaying Zhang, Hui Zhang, A. Criminisi",ba477d264f3518d3c9ef8b07cf3da279b99192a0,Image Quality Transfer via Random Forest Regression: Applications in Diffusion MRI,International Conference on Medical Image Computing and Computer-Assisted Intervention,2014,100,
"J. Masson, P. Dionne, Charlotte Salvatico, M. Renner, C. Specht, A. Triller, M. Dahan",36329219f6baa0b1a4f696223fa1682544776759,Mapping the energy and diffusion landscapes of membrane proteins at the cell surface using high-density single-molecule imaging and Bayesian inference: application to the multiscale dynamics of glycine receptors in the neuronal membrane.,Biophysical Journal,2014,88,
"M. Ruschel, T. Knösche, A. Friederici, R. Turner, S. Geyer, A. Anwander",24fd998a2563bec1d11cd3d0af92e4d43d71855b,Connectivity architecture and subdivision of the human inferior parietal cortex revealed by diffusion MRI.,Cerebral Cortex,2014,84,"The human inferior parietal cortex convexity (IPCC) is an important association area, which integrates auditory, visual, and somatosensory information. However, the structural organization of the IPCC is a controversial issue. For example, cytoarchitectonic parcellations reported in the literature range from 2 to 7 areas. Moreover, anatomical descriptions of the human IPCC are often based on experiments in the macaque monkey. In this study, we used diffusion-weighted magnetic resonance imaging combined with probabilistic tractography to quantify the connectivity of the human IPCC, and used this information to parcellate this cortex area. This provides a new structural map of the human IPCC, comprising 3 subareas (inferior parietal cortex anterior, IPC middle, and IPC posterior) of comparable size, in a rostro-caudal arrangement in the left and right hemispheres. Each subarea is characterized by a connectivity fingerprint, and the parcellation is similar to the subdivision reported for the macaque IPCC with 3 areas in a rostro-caudal arrangement (PF, PFG, and PG). However, the present study also reliably demonstrates new structural features in the connectivity pattern of the human IPCC, which are not known to exist in the macaque. This study quantifies intersubject variability by providing a population representation of the subarea arrangement and demonstrates the substantial lateralization of the connectivity patterns of the IPCC."
"F. Lam, S. D. Babacan, J. Haldar, M. Weiner, N. Schuff, Zhi-Pei Liang",b96b92ef485fb4ec0a0cf86f2923509a1c56e5d7,Denoising diffusion‐weighted magnitude MR images using rank and edge constraints,Magnetic Resonance in Medicine,2014,70,To improve signal‐to‐noise ratio for diffusion‐weighted magnetic resonance images.
"A. Rosenkrantz, H. Chandarana, J. Pfeuffer, Michael J. Triolo, M. Shaikh, D. Mossa, C. Geppert",d3c299343fde37315f2dd8440c07861e22ee8dc2,Zoomed echo-planar imaging using parallel transmission: impact on image quality of diffusion-weighted imaging of the prostate at 3T,Abdominal Imaging,2014,67,
"M. Chung, A. Qiu, Seongho Seo, H. K. Vorperian",0089c5cf5a0c1c464975f49b695b3c5e1e1a2edb,"Unified Heat Kernel Regression for Diffusion, Kernel Smoothing and Wavelets on Manifolds and Its Application to Mandible Growth Modeling in CT Images",Medical Image Anal.,2014,55,
"Luam C. Totti, Felipe Almeida Costa, S. Avila, Eduardo Valle, Wagner Meira Jr, Virgílio A. F. Almeida",6ceacd889559cfcf0009e914d47f915167231846,The impact of visual attributes on online image diffusion,Web Science Conference,2014,48,"Little is known on how visual content affects the popularity on social networks, despite images being now ubiquitous on the Web, and currently accounting for a considerable fraction of all content shared. Existing art on image sharing focuses mainly on non-visual attributes. In this work we take a complementary approach, and investigate resharing from a mainly visual perspective. Two sets of visual features are proposed, encoding both aesthetical properties (brightness, contrast, sharpness, etc.), and semantical content (concepts represented by the images). We collected data from a large image-sharing service (Pinterest) and evaluated the predictive power of different features on popularity (number of reshares). We found that visual properties have low predictive power compared that of social cues. However, after factoring-out social influence, visual features show considerable predictive power, especially for images with higher exposure, with over 3:1 accuracy odds when classifying highly exposed images between very popular and unpopular."
"Junxin Chen, Zhiliang Zhu, Hai Yu",aa4f840c4917a610ca5aff7f50f32a61c7707945,A fast chaos-based symmetric image cryptosystem with an improved diffusion scheme,,2014,39,
"R. Inano, N. Oishi, T. Kunieda, Y. Arakawa, Y. Yamao, S. Shibata, T. Kikuchi, H. Fukuyama, S. Miyamoto",f9d79b7d72007a7e66351446c9e9b096a9b8bbea,Voxel-based clustered imaging by multiparameter diffusion tensor images for glioma grading,NeuroImage: Clinical,2014,38,
"Muwei Li, Yuanyuan Qin, F. Gao, Wenzhen Zhu, Xiaohai He",8bbd12eedbeefb507a33f1c4d6370850ee7994a9,Discriminative analysis of multivariate features from structural MRI and diffusion tensor images.,Magnetic Resonance Imaging,2014,37,
"Jiong Zhang, R. Duits, B. H. Romeny",3ee68e754708e8034cbfbc510d2ddcb1538b8e77,"Numerical Approaches for Linear Left-invariant Diffusions on SE(2), their Comparison to Exact Solutions, and their Applications in Retinal Imaging","Numerical Mathematics: Theory, Methods and Applications",2014,32,"Left-invariant PDE-evolutions on the roto-translation groupSE(2)(and their resolvent equations) have been widely studied in the fields of cortical modeling and image analysis. They include hypo-elliptic diffusion (for contour enhancement) proposed by Citti & Sarti, and Petitot, and they include the direction process (for contour completion) proposed by Mumford. This paper presents a thorough study and comparison of the many numerical approaches, which, remarkably, are missing in the literature. Existing numerical approaches can be classified into 3 categories: Finite difference methods, Fourier based methods (equivalent toSE(2)-Fourier methods), and stochastic methods (Monte Carlo simulations). There are also 3 types of exact solutions to the PDE-evolutions that were derived explicitly (in the spatial Fourier domain) in previous works by Duits and van Almsick in 2005. Here we provide an overview of these 3 types of exact solutions and explain how they relate to each of the 3 numerical approaches. We compute relative errors of all numerical approaches to the exact solutions, and the Fourier based methods show us the best performance with smallest relative errors. We also provide an improvement of Mathematica algorithms for evaluating Mathieu-functions, crucial in implementations of the exact solutions. Furthermore, we include an asymptotical analysis of the singularities within the kernels and we propose a probabilistic extension of underlying stochastic processes that overcomes the singular behavior in the origin of time-integrated kernels. Finally, we show retinal imaging applications of combining left-invariant PDE-evolutions with invertible orientation scores."
"V. B. Surya Prasath, D. Vorotnikov",6dc7a027f52ecc55c3d7fc4b9a73e47916ec224c,Weighted and well-balanced anisotropic diffusion scheme for image denoising and restoration,,2014,29,
"C. E. Han, L. Peraza, John-Paul Taylor, Marcus Kaiser",50a1baba2305cdc30bd9e9bc34125f6904c31bf4,Predicting age across human lifespan based on structural connectivity from diffusion tensor imaging,2014 IEEE Biomedical Circuits and Systems Conference (BioCAS) Proceedings,2014,22,"Predicting brain maturity using noninvasive magnetic resonance images (MRI) can distinguish different age groups and help to assess neurodevelopmental disorders. However, group-wise differences are often less informative for assessing features of individuals. Here, we propose a simple method to predict the age of an individual subject solely based on structural connectivity data from diffusion tensor imaging (DTI). Our simple predictor computes a weighted sum of connection strengths of an individual, where weights are the importance of that connection for an observed feature-age in this case. The weights are simply determined through correlations between connection strength and age; thus the proposed predictor requires no parameter tuning. We tested this approach using DTI data from 201 healthy subjects aged 4 to 85 years. After determining importance in a training dataset, our predicted ages in the test dataset showed a strong correlation (r = 0.79) with real age deviating by, on average, only about 9 years."
"J. Cho, E. Kim, Jinna Kim, Seung Koo Lee, S. H. Kim, Kyu-Sung Lee, Jong-Hee Chang",b49c501a35222d4b3e8334670741848b06b7c25d,"Clinical Use of Diffusion Tensor Image-Merged Functional Neuronavigation for Brain Tumor Surgeries: Review of Preoperative, Intraoperative, and Postoperative Data for 123 Cases",Yonsei medical journal,2014,20,"Purpose To achieve maximal safe resection during brain tumor surgery, functional image-merged neuronavigation is widely used. We retrospectively reviewed our cases in which diffusion tensor image (DTI)-merged functional neuronavigation was performed during surgery. Materials and Methods Between November 2008 and May 2010, 123 patients underwent surgery utilizing DTI-merged neuronavigation. Anatomical magnetic resonance images (MRI) were obtained preoperatively and fused with DTI of major white matter tracts, such as the corticospinal tract, optic radiation, or arcuate fasciculus. We used this fused image for functional neuronavigation during brain tumor surgery of eloquent areas. We checked the DTI images together with postoperative MRI images and evaluated the integrity of white matter tracts. Results A single white matter tract was inspected in 78 patients, and two or more white matter tracts were checked in 45 patients. Among the 123 patients, a grossly total resection was achieved in 90 patients (73.2%), subtotal resection in 29 patients (23.6%), and partial resection in 4 patients (3.3%). Postoperative neurologic outcomes, compared with preoperative function, included the following: 100 patients (81.3%) displayed improvement of neurologic symptoms or no change, 7 patients (5.7%) experienced postoperative permanent neurologic deterioration (additional or aggravated neurologic symptoms), and 16 patients (13.0%) demonstrated transient worsening. Conclusion DTI-merged functional neuronavigation could be a useful tool in brain tumor surgery for maximal safe resection. However, there are still limitations, including white matter tract shift, during surgery and in DTI itself. Further studies should be conducted to overcome these limitations."
"L. Zhang, Kwok-wo Wong, Yushu Zhang, Qiuzhen Lin",845bfa94266931495ec2f69e919e8dc92c3dfcfe,Joint quantization and diffusion for compressed sensing measurements of natural images,International Symposium on Circuits and Systems,2014,18,"Recent research advances have revealed the computational secrecy of the compressed sensing (CS) paradigm. Perfect secrecy can also be achieved by normalizing the CS measurement vector. However, these findings are established on real-valued measurements while digital devices can only store the samples at a finite precision. Based on the distribution of measurements of natural images sensed by structurally random ensemble, a joint quantization and diffusion approach for the real-valued measurements is suggested. In this way, a nonlinear cryptographic diffusion is intrinsically imposed on the CS quantization process and the overall security level is thus enhanced. It is shown that the proposed scheme is able to resist known-plaintext attack while the original CS scheme without quantization cannot."
"P. Yap, H. An, Yasheng Chen, D. Shen",3c9c09a94d3868d4a90fc3ab38e01c956d17ae9d,Fiber-driven resolution enhancement of diffusion-weighted images,NeuroImage,2014,16,
"U. Boscain, J. Gauthier, D. Prandi, A. Remizov",2b9e2cdef267f8e206edb435414d34084b9bcb82,Image reconstruction via non-isotropic diffusion in Dubins/Reed-Shepp-like control systems,IEEE Conference on Decision and Control,2014,14,"We compare the image inpainting results of two models of geometry of vision obtained through control theoretic considerations (the semi-discrete versions of the Citti-Petitot-Sarti and Mumford Elastica models). The main feature described by these models is the lifting of 2D images to the 3D group of translations and discrete rotations on the plane SE(2,N), done by the primary visual cortex. Corrupted images are then reconstructed by minimizing the energy necessary to activate neurons corresponding to the missing regions. This minimization procedure, which gives rise to Dubins/Reed-Shepp-like optimal control problems in the case of corrupted curves, is described by an hypoelliptic diffusion on SE(2,N). We present two numerical algorithms for the resolution of the diffusion equation in both models and then compare the results."
"M. Ahmad, H. Al-Sharari, M. Nizam",0c042eaf88ec7769ee2426b49a157859318fad1d,Security Improvement of an Image Encryption Based on mPixel-Chaotic-Shuffle and Pixel-Chaotic-Diffusion,ArXiv,2014,12,"In this paper, we propose to improve the security performance of a recently proposed color image encryption algorithm which is based on multi-chaotic systems. The existing cryptosystem employed a pixel-chaotic-shuffle mechanism to encrypt images, in which the generation of shuffling sequences are independent to the plain-image/cipher-image. As a result, it fails to the chosen-plaintext and known-plaintext attacks. Moreover, the statistical features of the cryptosystem are not up to the standard. Therefore, the security improvements are framed to make the above attacks infeasible and enhance the statistical features as well. It is achieved by modifying the pixel-chaotic-shuffle mechanism and adding a new pixel-chaotic-diffusion mechanism to it. The keys for diffusion of pixels are extracted from the same chaotic sequences generated in the previous stage. The simulation analyses and studies are performed to demonstrate that the updated version of cryptosystem has better statistical features and resistant to the chosen-plaintext and known-plaintext attacks than the existing algorithm."
"S. Powell, S. Arridge, T. Leung",0a5250795861be146e085c5a023a1974ba40f1dc,Gradient-Based Quantitative Image Reconstruction in Ultrasound-Modulated Optical Tomography: First Harmonic Measurement Type in a Linearised Diffusion Formulation,IEEE Transactions on Medical Imaging,2014,10,"Ultrasound-modulated optical tomography is an emerging biomedical imaging modality which uses the spatially localised acoustically-driven modulation of coherent light as a probe of the structure and optical properties of biological tissues. In this work we begin by providing an overview of forward modelling methods, before deriving a linearised diffusion-style model which calculates the first-harmonic modulated flux measured on the boundary of a given domain. We derive and examine the correlation measurement density functions of the model which describe the sensitivity of the modality to perturbations in the optical parameters of interest. Finally, we employ said functions in the development of an adjoint-assisted gradient based image reconstruction method, which ameliorates the computational burden and memory requirements of a traditional Newton-based optimisation approach. We validate our work by performing reconstructions of optical absorption and scattering in two- and three-dimensions using simulated measurements with 1% proportional Gaussian noise, and demonstrate the successful recovery of the parameters to within ±5% of their true values when the resolution of the ultrasound raster probing the domain is sufficient to delineate perturbing inclusions."
"Jingyue Wang, Weizhang Huang",66d1b59d39b752dfa7584c2c755908166a128671,Image Segmentation With Eigenfunctions of an Anisotropic Diffusion Operator,IEEE Transactions on Image Processing,2014,7,"We propose the eigenvalue problem of an anisotropic diffusion operator for image segmentation. The diffusion matrix is defined based on the input image. The eigenfunctions and the projection of the input image in some eigenspace capture key features of the input image. An important property of the model is that for many input images, the first few eigenfunctions are close to being piecewise constant, which makes them useful as the basis for a variety of applications, such as image segmentation and edge detection. The eigenvalue problem is shown to be related to the algebraic eigenvalue problems resulting from several commonly used discrete spectral clustering models. The relation provides a better understanding and helps developing more efficient numerical implementation and rigorous numerical analysis for discrete spectral segmentation methods. The new continuous model is also different from energy-minimization methods such as active contour models in that no initial guess is required for in the current model. A numerical implementation based on a finite-element method with an anisotropic mesh adaptation strategy is presented. It is shown that the numerical scheme gives much more accurate results on eigenfunctions than uniform meshes. Several interesting features of the model are examined in numerical examples, and possible applications are discussed."
"Yu-Qian Yang, Cheng-Yi Zhang",2e2968194a97564a642a4e7323f8abdabf5cc0d2,Kernel Based Telegraph-Diffusion Equation for Image Noise Removal,,2014,6,"The second-order partial differential equations have good performances on noise smoothing and edge preservation. However, for low signal-to-noise ratio (SNR) images, the discrimination between edges and noise is a challenging problem. In this paper, the authors propose a kernel based telegraph-diffusion equation (KTDE) for noise removal. In this method, a kernelized gradient operator is introduced in the second-order telegraph-diffusion equation (TDE), which leads to more effective noise removal capability. Experiment results show that this method outperforms several anisotropic diffusion methods and the TDE method for noise removal and edge preservation."
"V. B. Surya Prasath, R. Delhibabu",5fe666f0fd652d21f2eeed8d0995c9d58ded94b9,Automatic Contrast Parameter Estimation in Anisotropic Diffusion for Image Restoration,"International Joint Conference on the Analysis of Images, Social Networks and Texts",2014,5,
V. Barbu,373f1b731e2348b3339cb192e601b6278fbc22e7,Nonlinear Diffusion equations in image processing,,2014,4,"One surveys here a few nonlinear di usion models in image restoration and denoising with main emphasis on that described by nonlinear parabolic equations of gradient type. The well-posedness of the corresponding Cauchy problem as well as stability of the derived nite di erence scheme is studied from perspectives of nonlinear semigroup theory. As a matter of fact, most of denoising PDE procedures existing in literature though apparently are e cient at experimental level, are however mathematically ill posed and our e ort here is to put them on more rigorous mathematical basis."
"Dario Gasbarra, Jia Liu, Juha Railavo",32fd01f1200518129f592b69ddd18946e3c9d805,Data augmentation in Rician noise model and Bayesian Diffusion Tensor Imaging,,2014,4,"Mapping white matter tracts is an essential step towards understanding brain function. Diffusion Magnetic Resonance Imaging (dMRI) is the only noninvasive technique which can detect in vivo anisotropies in the 3-dimensional diffusion of water molecules, which correspond to nervous fibers in the living brain. In this process, spectral data from the displacement distribution of water molecules is collected by a magnetic resonance scanner. From the statistical point of view, inverting the Fourier transform from such sparse and noisy spectral measurements leads to a non-linear regression problem. Diffusion tensor imaging (DTI) is the simplest modeling approach postulating a Gaussian displacement distribution at each volume element (voxel). Typically the inference is based on a linearized log-normal regression model that can fit the spectral data at low frequencies. However such approximation fails to fit the high frequency measurements which contain information about the details of the displacement distribution but have a low signal to noise ratio. In this paper, we directly work with the Rice noise model and cover the full range of $b$-values. Using data augmentation to represent the likelihood, we reduce the non-linear regression problem to the framework of generalized linear models. Then we construct a Bayesian hierarchical model in order to perform simultaneously estimation and regularization of the tensor field. Finally the Bayesian paradigm is implemented by using Markov chain Monte Carlo."
Neda Pourali,46487b2a22dd8ce57606518fc7a8574f4071fad4,Web image annotation by diffusion maps manifold learning algorithm,IEEE Annual Symposium on Foundations of Computer Science,2014,0,"Automatic image annotation is one of the most challenging problems in machine vision areas. The goal of this task is to predict number of keywords automatically for images captured in real data. Many methods are based on visual features in order to calculate similarities between image samples. But the computation cost of these approaches is very high. These methods require many training samples to be stored in memory. To lessen this burden, a number of techniques have been developed to reduce the number of features in a dataset. Manifold learning is a popular approach to nonlinear dimensionality reduction. In this paper, we investigate Diffusion maps manifold learning method for web image auto-annotation task. Diffusion maps manifold learning method is used to reduce the dimension of some visual features. Extensive experiments and analysis on NUS-WIDE-LITE web image dataset with different visual features show how this manifold learning dimensionality reduction method can be applied effectively to image annotation."
"E. I. Khadikova, M. Montagnese, F. D. Haan, P. Loosdrecht",3aba11c1c0fa5276c0fd588e43f4ecd4d6840dbd,Modelling Dynamical Fluorescent Micro Thermal Imaging of the Heat Diffusion in the La5Ca9Cu24O41 Spin Ladder Compound,,2014,0,"The dynamical fluorescent microthermal imaging (FMI) experiment has been used to investigate the phonon-magnon interaction in the 1D Heisenberg antiferromagnet La5Ca9Cu24O41. This material shows highly anisotropic heat conductivity due to the efficient magnetic heat transport along the spin ladders in the compound. To extract information on the phonon-magnon interaction we modelled the dynamic heat transport experiment using a two temperature model approach, taking both the crystal as well as the PMMA/EuTTA fluorescent heat imaging layer into account. The simulations are carried out by the finite element method using COMSOL Multiphysics Heat Transfer Module. The results of the numerical calculations are expected to be used for the data analysis of the experimental studies."
"F. Yeh, T. Verstynen",875811dbd44157309f6dcecf017dce8795cddd1e,Increasing the Analytical Accessibility of Multishell and Diffusion Spectrum Imaging Data Using Generalized Q-Sampling Conversion,,2014,0,"Many diffusion MRI researchers, including the Human Connectome Project (HCP), acquire data using multishell (e.g., WU-Minn consortium) and diffusion spectrum imaging (DSI) schemes (e.g., USC-Harvard consortium). However, these data sets are not readily accessible to high angular resolution diffusion imaging (HARDI) analysis methods that are popular in connectomics analysis. Here we introduce a scheme conversion approach that transforms multishell and DSI data into their corresponding HARDI representations, thereby empowering HARDI-based analytical methods to make use of data acquired using non-HARDI approaches. This method was evaluated on both phantom and in-vivo human data sets by acquiring multishell, DSI, and HARDI data simultaneously, and comparing the converted HARDI, from non-HARDI methods, with the original HARDI data. Analysis on the phantom shows that the converted HARDI from DSI and multishell data strongly predicts the original HARDI (correlation coefficient > 0.9). Our in-vivo study shows that the converted HARDI can be reconstructed by constrained spherical deconvolution, and the fiber orientation distributions are consistent with those from the original HARDI. We further illustrate that our scheme conversion method can be applied to HCP data, and the converted HARDI do not appear to sacrifice angular resolution. Thus this novel approach can benefit all HARDI-based analysis approaches, allowing greater analytical accessibility to non-HARDI data, including data from the HCP."
"Zaixu Cui, Suyu Zhong, Pengfei Xu, Yong He, G. Gong",1be97fec0a3507e4a6da29c0b5bd8b9d7ed22aed,PANDA: a pipeline toolbox for analyzing brain diffusion images,Frontiers in Human Neuroscience,2013,510,"Diffusion magnetic resonance imaging (dMRI) is widely used in both scientific research and clinical practice in in-vivo studies of the human brain. While a number of post-processing packages have been developed, fully automated processing of dMRI datasets remains challenging. Here, we developed a MATLAB toolbox named “Pipeline for Analyzing braiN Diffusion imAges” (PANDA) for fully automated processing of brain diffusion images. The processing modules of a few established packages, including FMRIB Software Library (FSL), Pipeline System for Octave and Matlab (PSOM), Diffusion Toolkit and MRIcron, were employed in PANDA. Using any number of raw dMRI datasets from different subjects, in either DICOM or NIfTI format, PANDA can automatically perform a series of steps to process DICOM/NIfTI to diffusion metrics [e.g., fractional anisotropy (FA) and mean diffusivity (MD)] that are ready for statistical analysis at the voxel-level, the atlas-level and the Tract-Based Spatial Statistics (TBSS)-level and can finish the construction of anatomical brain networks for all subjects. In particular, PANDA can process different subjects in parallel, using multiple cores either in a single computer or in a distributed computing environment, thus greatly reducing the time cost when dealing with a large number of datasets. In addition, PANDA has a friendly graphical user interface (GUI), allowing the user to be interactive and to adjust the input/output settings, as well as the processing parameters. As an open-source package, PANDA is freely available at http://www.nitrc.org/projects/panda/. This novel toolbox is expected to substantially simplify the image processing of dMRI datasets and facilitate human structural connectome studies."
"J. Manjón, P. Coupé, L. Concha, A. Buades, D. Collins, M. Robles",cd1292c3bcc0e512c7a1b6fa2ac256215aab1255,Diffusion Weighted Image Denoising Using Overcomplete Local PCA,PLoS ONE,2013,301,"Diffusion Weighted Images (DWI) normally shows a low Signal to Noise Ratio (SNR) due to the presence of noise from the measurement process that complicates and biases the estimation of quantitative diffusion parameters. In this paper, a new denoising methodology is proposed that takes into consideration the multicomponent nature of multi-directional DWI datasets such as those employed in diffusion imaging. This new filter reduces random noise in multicomponent DWI by locally shrinking less significant Principal Components using an overcomplete approach. The proposed method is compared with state-of-the-art methods using synthetic and real clinical MR images, showing improved performance in terms of denoising quality and estimation of diffusion parameters."
"Chourmouzios Tsiotsios, M. Petrou",bb5c6819755e93afefa4d07daa37b55336bbc55b,On the choice of the parameters for anisotropic diffusion in image processing,Pattern Recognition,2013,202,
"S. Sotiropoulos, S. Moeller, S. Jbabdi, J. Xu, J. Andersson, E. Auerbach, E. Yacoub, D. Feinberg, K. Setsompop, L. Wald, Timothy Edward John Behrens, K. Uğurbil, C. Lenglet",8ece878bb0f2a4cfebb7c9996f29aa5aa3a0bf01,Effects of image reconstruction on fiber orientation mapping from multichannel diffusion MRI: Reducing the noise floor using SENSE,Magnetic Resonance in Medicine,2013,172,To examine the effects of the reconstruction algorithm of magnitude images from multichannel diffusion MRI on fiber orientation estimation.
"Sol Lim, C. E. Han, P. Uhlhaas, Marcus Kaiser",ef7ea92b3f337fa480c8cd681cab5ffbaa119088,Preferential Detachment During Human Brain Development: Age- and Sex-Specific Structural Connectivity in Diffusion Tensor Imaging (DTI) Data,Cerebral Cortex,2013,124,"Human brain maturation is characterized by the prolonged development of structural and functional properties of large-scale networks that extends into adulthood. However, it is not clearly understood which features change and which remain stable over time. Here, we examined structural connectivity based on diffusion tensor imaging (DTI) in 121 participants between 4 and 40 years of age. DTI data were analyzed for small-world parameters, modularity, and the number of fiber tracts at the level of streamlines. First, our findings showed that the number of fiber tracts, small-world topology, and modular organization remained largely stable despite a substantial overall decrease in the number of streamlines with age. Second, this decrease mainly affected fiber tracts that had a large number of streamlines, were short, within modules and within hemispheres; such connections were affected significantly more often than would be expected given their number of occurrences in the network. Third, streamline loss occurred earlier in females than in males. In summary, our findings suggest that core properties of structural brain connectivity, such as the small-world and modular organization, remain stable during brain maturation by focusing streamline loss to specific types of fiber tracts."
"P. Coupé, J. Manjón, Maxime Chamberland, M. Descoteaux, B. Hiba",f39aea5445727bab9879f0b20c50fcb7563ee96a,Collaborative patch-based super-resolution for diffusion-weighted images,NeuroImage,2013,93,
"A. Rosenkrantz, N. Hindman, R. Lim, K. Das, J. Babb, T. Mussi, S. Taneja",bb6a658d4b176c06bb5a8b95915c9faa24cfbe61,Diffusion‐weighted imaging of the prostate: Comparison of b1000 and b2000 image sets for index lesion detection,Journal of Magnetic Resonance Imaging,2013,88,"To compare tumor detection on acquired diffusion‐weighted (DW) images and apparent diffusion coefficient (ADC) maps, obtained using b‐values of 1000 s/mm2 and 2000 s/mm2, using radical prostatectomy as the reference."
"M. Engström, S. Skare",074b3e67273e3c0ad786351f85f369695c57f567,Diffusion‐weighted 3D multislab echo planar imaging for high signal‐to‐noise ratio efficiency and isotropic image resolution,Magnetic Resonance in Medicine,2013,61,"To acquire isotropic high‐resolution, signal‐to‐noise ratio (SNR) efficient, 3D encoded diffusion‐weighted MRI data."
"U. Boscain, R. Chertovskih, J. Gauthier, A. Remizov",fe805723b3263337e965e8268e668b73d3e9b095,Hypoelliptic Diffusion and Human Vision: A Semidiscrete New Twist,SIAM Journal of Imaging Sciences,2013,49,"This paper presents a semidiscrete alternative to the theory of neurogeometry of vision, due to Citti, Petitot, and Sarti. We propose a new ingredient, namely, working on the group of translations and discrete rotations $SE(2,N)$. The theoretical side of our study relates the stochastic nature of the problem with the Moore group structure of $SE(2,N)$. Harmonic analysis over this group leads to very simple finite dimensional reductions. We then apply these ideas to the inpainting problem which is reduced to the integration of a completely parallelizable finite set of Mathieu-type diffusions (indexed by the dual of $SE(2,N)$ in place of the points of the Fourier plane, which is a drastic reduction). The integration of the the Mathieu equations can be performed by standard numerical methods for elliptic diffusions and leads to a very simple and efficient class of inpainting algorithms. We illustrate the performances of the method on a series of deeply corrupted images."
"Wook Lee, B. Park, Kyungsook Han",eb281e10e2dafa0fcdac6c8529a6cebb8160162f,Classification of diffusion tensor images for the early detection of Alzheimer's disease,Comput. Biol. Medicine,2013,47,
"Yuanquan Wang, Wenqi Ren, Huaibin Wang",1f7e9becf58b33eee59415bdd090dd9907ec2895,Anisotropic second and fourth order diffusion models based on Convolutional Virtual Electric Field for image denoising,Computers and Mathematics with Applications,2013,37,
"C. Gerin, J. Pallud, C. Deroulers, P. Varlet, C. Oppenheim, F. Roux, F. Chrétien, Stephen R. Thomas, B. Grammaticos, M. Badoual",7d7e72eadb8da6333682b23db486f423f062e2c4,Quantitative characterization of the imaging limits of diffuse low-grade oligodendrogliomas.,Neuro-Oncology,2013,36,"BACKGROUND
Supratentorial diffuse low-grade gliomas in adults extend beyond maximal visible MRI-defined abnormalities, and a gap exists between the imaging signal changes and the actual tumor margins. Direct quantitative comparisons between imaging and histological analyses are lacking to date. However, they are of the utmost importance if one wishes to develop realistic models for diffuse glioma growth.


METHODS
In this study, we quantitatively compared the cell concentration and the edema fraction from human histological biopsy samples (BSs) performed inside and outside imaging abnormalities during serial imaging-based stereotactic biopsy of diffuse low-grade gliomas.


RESULTS
The cell concentration was significantly higher in BSs located inside (1189 ± 378 cell/mm(2)) than outside (740 ± 124 cell/mm(2)) MRI-defined abnormalities (P = .0003). The edema fraction was significantly higher in BSs located inside (mean, 45% ± 23%) than outside (mean, 5 %± 9%) MRI-defined abnormalities (P < .0001). At borders of the MRI-defined abnormalities, 20% of the tissue surface area was occupied by edema and only 3% by tumor cells. The cycling cell concentration was significantly higher in BSs located inside (10 ± 12 cell/mm(2)), compared with outside (0.5 ± 0.9 cell/mm(2)), MRI-defined abnormalities (P = .0001).


CONCLUSIONS
We showed that the margins of T2-weighted signal changes are mainly correlated with the edema fraction. In 62.5% of patients, the cycling tumor cell fraction (defined as the ratio of the cycling tumor cell concentration to the total number of tumor cells) was higher at the limits of the MRI-defined abnormalities than closer to the center of the tumor. In the remaining patients, the cycling tumor cell fraction increased towards the center of the tumor."
"P. Guidotti, Yunho Kim, J. Lambers",3fb713e930191b539d8c19c1c8d0fb639cd96b09,Image Restoration with a New Class of Forward-Backward-Forward Diffusion Equations of Perona-Malik Type with Applications to Satellite Image Enhancement,SIAM Journal of Imaging Sciences,2013,25,"A new class of anisotropic diffusion models is proposed for image processing which can be viewed either as a novel kind of regularization of the classical Perona--Malik model or, as advocated by the authors, as a new independent model. The models are diffusive in nature and are characterized by the presence of both forward and backward regimes. In contrast to the Perona--Malik model, in the proposed model the backward regime is confined to a bounded region, and gradients are only allowed to grow up to a large but tunable size, thus effectively preventing indiscriminate singularity formation, i.e., staircasing. Extensive numerical experiments demonstrate that the method is a viable denoising/deblurring tool. The method is significantly faster than competing state-of-the-art methods and appears to be particularly effective for simultaneous denoising and deblurring. An application to satellite image enhancement is also presented."
"B. Scherrer, M. Taquet, S. Warfield",0dae9db6a06650d92723df72c7d2e170eef6747f,Reliable Selection of the Number of Fascicles in Diffusion Images by Estimation of the Generalization Error,Information Processing in Medical Imaging,2013,19,
"Harbinder Singh, Vinay Kumar, S. Bhooshan",5432cbff2afb4a78e22bb435d07ff74c5b293a70,Anisotropic Diffusion for Details Enhancement in Multi-Exposure Image Fusion,ArXiv,2013,18,"We develop a multiexposure image fusion method based on texture features, which exploits the edge preserving and intraregion smoothing property of nonlinear diffusion filters based on partial differential equations (PDE). With the captured multiexposure image series, we first decompose images into base layers and detail layers to extract sharp details and fine details, respectively. The magnitude of the gradient of the image intensity is utilized to encourage smoothness at homogeneous regions in preference to inhomogeneous regions. Then, we have considered texture features of the base layer to generate a mask (i.e., decision mask) that guides the fusion of base layers in multiresolution fashion. Finally, well-exposed fused image is obtained that combines fused base layer and the detail layers at each scale across all the input exposures. Proposed algorithm skipping complex High Dynamic Range Image (HDRI) generation and tone mapping steps to produce detail preserving image for display on standard dynamic range display devices. Moreover, our technique is effective for blending flash/no-flash image pair and multifocus images, that is, images focused on different targets."
"U. Boscain, R. Chertovskih, J. Gauthier, A. Remizov",62ad32b287adaebc61201de504f01396e4d6593c,Hypoelliptic diffusion and human vision: a semi-discrete new twist on the Petitot theory,,2013,15,"This paper is devoted to present an algorithm implementing the theory of neurogeometry of vision, described by Jean Petitot in his book. We propose a new ingredient, namely working on the group of translations and discrete rotations SE(2,N). We focus on the theoretical and numerical aspects of integration of an hypoelliptic diffusion equation on this group. Our main tool is the generalized Fourier transform. We provide a complete numerical algorithm, fully parallellizable. The main objective is the validation of the neurobiological model."
"D. Alexander, T. Dyrby",3ea6ecf67006b1263b2c934b1f646ae7e058efce,Diffusion imaging with stimulated echoes: signal models and experiment design,,2013,11,"Purpose: Stimulated echo acquisition mode (STEAM) diffusion MRI can be advantageous over pulsed-gradient spin-echo (PGSE) for diffusion times that are long compared to $\ttwo$. It is important therefore for biomedical diffusion imaging applications at 7T and above where $\ttwo$ is short. However, imaging gradients in the STEAM sequence contribute much greater diffusion weighting than in PGSE, but are often ignored during post-processing. We demonstrate here that this can severely bias parameter estimates. 
Method: We present models for the STEAM signal for free and restricted diffusion that account for crusher and slice-select (butterfly) gradients to avoid such bias. The butterfly gradients also disrupt experiment design, typically by skewing gradient-vectors towards the slice direction. We propose a simple compensation to the diffusion gradient vector specified to the scanner that counterbalances the butterfly gradients to preserve the intended experiment design. 
Results: High-field data fixed from a monkey brain experiments demonstrate the need for both the compensation during acquisition and correct modelling during post-processing for both diffusion tensor imaging and ActiveAx axon-diameter index mapping. Simulations support the results and indicate a similar need in in-vivo human applications. 
Conclusion: Correct modelling and compensation are important for practical applications of STEAM diffusion MRI."
"Pei Zhang, M. Niethammer, D. Shen, P. Yap",247e8156571be36b644c521b73e146431335083e,Large Deformation Diffeomorphic Registration of Diffusion-Weighted Images with Explicit Orientation Optimization,International Conference on Medical Image Computing and Computer-Assisted Intervention,2013,10,
"V. B. Surya Prasath, J. Moreno, K. Palaniappan",7db71074e89e2ffd8964b5828904a9612eca3a5d,Color image denoising by chromatic edges based vector valued diffusion,ArXiv,2013,8,In this letter we propose to denoise digital color images via an improved geometric diffusion scheme. By introducing edges detected from all three color channels into the diffusion the proposed scheme avoids color smearing artifacts. Vector valued diffusion is used to control the smoothing and the geometry of color images are taken into consideration. Color edge strength function computed from different planes is introduced and it stops the diffusion spread across chromatic edges. Experimental results indicate that the scheme achieves good denoising with edge preservation when compared to other related schemes.
"Diwei Zhou, I. Dryden, A. Koloydenko, L. Bai",90105d0802c3b592d54cf3cd20f699de0275c319,Procrustes analysis for diffusion tensor image processing,,2013,7,"There is an increasing need to develop processing tools for diffusion tensor image data with the consideration of the non-Euclidean nature of the tensor space. In this paper Procrustes analysis, a non-Euclidean shape analysis tool under similarity transformations (rotation, scaling and translation), is proposed to redefine sample statistics of diffusion tensors. A new anisotropy measure Procrustes Anisotropy (PA) is defined with the full ordinary Procrustes analysis. Comparisons are made with other anisotropy measures including Fractional Anisotropy and Geodesic Anisotropy. The partial generalized Procrustes analysis is extended to a weighted generalized Procrustes framework for averaging sample tensors with different fractions of contributions to the mean tensor. Applications of Procrustes methods to diffusion tensor interpolation and smoothing are compared with Euclidean, Log-Euclidean and Riemannian methods."
"V. B. Surya Prasath, J. Moreno",195d315506242650515b11d3133ba7cc4f776fd9,Feature preserving anisotropic diffusion for image restoration,"National Conference on Computer Vision, Pattern Recognition, Image Processing, and Graphics",2013,6,"Anisotropic diffusion based schemes are widely used in image smoothing and noise removal. Typically, the partial differential equation (PDE) used is based on computing image gradients or isotropically smoothed version of the gradient image. To improve the denoising capability of such nonlinear anisotropic diffusion schemes, we introduce a multi-direction based discretization along with a selection strategy for choosing the best direction of possible edge pixels. This strategy avoids the directionality based bias which can over-smooth features that are not aligned with the coordinate axis. The proposed hybrid discretization scheme helps in preserving multi-scale features present in the images via selective smoothing of the PDE. Experimental results indicate such an adaptive modification provides improved restoration results on noisy images."
"Jia Du, A. P. Hosseinbor, M. Chung, B. Bendlin, Gaurav Suryawanshi, A. Alexander, A. Qiu",88d67a9bf52e5340277b671191d5b3cb96591d12,Diffeomorphic Metric Mapping and Probabilistic Atlas Generation of Hybrid Diffusion Imaging based on BFOR Signal Basis,Medical Image Anal.,2013,6,
V. Rossetto,221a442b0fa22a43d318f67bfb2b14e7663fa259,Local time in diffusive media and applications to imaging.,"Physical review. E, Statistical, nonlinear, and soft matter physics",2013,6,"Local time is the measure of how much time a random walk has visited a given position. In multiple scattering media, where waves are diffuse, local time measures the sensitivity of the waves to the local medium's properties. Local variations of absorption, velocity, and scattering between two measurements yield variations in the wave field. These variations are proportional to the local time of the volume where the change happened and the amplitude of variation. The wave field variations are measured using correlations and can be used as input in a inversion algorithm to produce variation maps. The present article gives the expression of the local time in dimensions one, two, and three and an expression of its fluctuations, in order to perform such inversions and estimate their accuracy."
"F. Laun, Lars Müller, T. Kuder",10d69d68513374322822bf2ec4673402d374a52d,NMR-based diffusion lattice imaging.,Physical Review E,2013,4,"Nuclear magnetic resonance (NMR) diffusion experiments are widely employed as they yield information about structures hindering the diffusion process, e.g., about cell membranes. While it has been shown in recent articles that these experiments can be used to determine the shape of closed pores averaged over a volume of interest, it is still an open question how much information can be gained in open well-connected systems. In this theoretical work, it is shown that the full structure information of connected periodic systems is accessible. To this end, the so-called ""SEquential Rephasing by Pulsed field-gradient Encoding N Time intervals"" (SERPENT) sequence is used, which employs several diffusion encoding gradient pulses with different amplitudes. Two two-dimensional solid matrices that are surrounded by an NMR-visible medium are considered: a hexagonal lattice of cylinders and a rectangular lattice of isosceles triangles."
"M. Bauer, S. Barbieri, J. Klein, J. Egger, D. Kuhnt, Bernd Freisleben, H. Hahn, C. Nimsky",962f1e552dd32208fb0791b4d6729205b578cfc6,A Ray-based Approach for Boundary Estimation of Fiber Bundles Derived from Diffusion Tensor Imaging,ArXiv,2013,2,"Diffusion Tensor Imaging (DTI) is a non-invasive imaging technique that allows estimation of the location of white matter tracts in-vivo, based on the measurement of water diffusion properties. For each voxel, a second-order tensor can be calculated by using diffusion-weighted sequences (DWI) that are sensitive to the random motion of water molecules. Given at least 6 diffusion-weighted images with different gradients and one unweighted image, the coefficients of the symmetric diffusion tensor matrix can be calculated. Deriving the eigensystem of the tensor, the eigenvectors and eigenvalues can be calculated to describe the three main directions of diffusion and its magnitude. Using DTI data, fiber bundles can be determined, to gain information about eloquent brain structures. Especially in neurosurgery, information about location and dimension of eloquent structures like the corticospinal tract or the visual pathways is of major interest. Therefore, the fiber bundle boundary has to be determined. In this paper, a novel ray-based approach for boundary estimation of tubular structures is presented."
"A. Yahya, Jieqing Tan",f69f0af15269cd275b6462c3f40fd3f5527db969,A Model of Image Denoising Based on the Fusion of Anisotropic Diffusion and Total Variation Models,,2013,1,"In this paper, a new denoising technique for images corrupted with additive salt and pepper noise and white Gaussian noise is proposed. The technique used here is to combine the anisotropic diffusion (PM) model and total variation (TV) model. The new technique utilizes both advantages of PM model and TV model, while avoiding the disadvantages of both of them. To evaluate our algorithm several experiments have been conducted. The experimental results affirm the high performance of our model."
"Jia Du, A. Goh, A. Qiu",cc85d09c52d29c36990bf226469f79b948b88369,Bayesian Estimation of White Matter Atlas from High Angular Resolution Diffusion Imaging,ArXiv,2013,1,"We present a Bayesian probabilistic model to estimate the brain white matter atlas from high angular resolution diffusion imaging (HARDI) data. This model incorporates a shape prior of the white matter anatomy and the likelihood of individual observed HARDI datasets. We first assume that the atlas is generated from a known hyperatlas through a flow of diffeomorphisms and its shape prior can be constructed based on the framework of large deformation diffeomorphic metric mapping (LDDMM). LDDMM characterizes a nonlinear diffeomorphic shape space in a linear space of initial momentum uniquely determining diffeomorphic geodesic flows from the hyperatlas. Therefore, the shape prior of the HARDI atlas can be modeled using a centered Gaussian random field (GRF) model of the initial momentum. In order to construct the likelihood of observed HARDI datasets, it is necessary to study the diffeomorphic transformation of individual observations relative to the atlas and the probabilistic distribution of orientation distribution functions (ODFs). To this end, we construct the likelihood related to the transformation using the same construction as discussed for the shape prior of the atlas. The probabilistic distribution of ODFs is then constructed based on the ODF Riemannian manifold. We assume that the observed ODFs are generated by an exponential map of random tangent vectors at the deformed atlas ODF. Hence, the likelihood of the ODFs can be modeled using a GRF of their tangent vectors in the ODF Riemannian manifold. We solve for the maximum a posteriori using the Expectation-Maximization algorithm and derive the corresponding update equations. Finally, we illustrate the HARDI atlas constructed based on a Chinese aging cohort of 94 adults and compare it with that generated by averaging the coefficients of spherical harmonics of the ODF across subjects."
"S. Nishiyama, K. Yasui, T. Nagata, T. Yoshikawa, H. Uchiyama, M. Tamura",613a3889fe14950bd2efa6581f9d01da0858c38b,The origin of the Galactic center diffuse X-ray emission investigated by near-infrared imaging and polarimetric observations,Proceedings of the International Astronomical Union,2013,0,"Abstract The origin of the Galactic center diffuse X-ray emission (GCDX) is still under intense investigation. We have found a clear excess in a longitudinal GCDX profile over a stellar number density profile in the nuclear bulge region, suggesting a significant contribution of diffuse, interstellar hot plasma to the GCDX. We have estimated that contributions of an old stellar population to the GCDX are ∼50% and ∼20% in the nuclear stellar disk and nuclear star cluster, respectively. Our near-infrared polarimetric observations show that the GCDX region is permeated by a large scale, toroidal magnetic field. Together with observed magnetic field strengths in nearly energy equipartition, the interstellar hot plasma could be confined by the toroidal magnetic field."
"M. Irfanoglu, L. Walker, J. Sarlls, S. Marenco, C. Pierpaoli",688696084c58b453e6ff81079b464174c407ecb5,Effects of image distortions originating from susceptibility variations and concomitant fields on diffusion MRI tractography results,NeuroImage,2012,195,
"J. Leconte, G. Chabrier",ecef4d4b42987b0c6579c229834709ff1d22253b,A new vision of giant planet interiors: Impact of double diffusive convection,,2012,182,"While conventional interior models for Jupiter and Saturn are based on the simplistic assumption of a solid core surrounded by a homogeneous gaseous envelope, we have derived new models with an inhomogeneous distribution of heavy elements within these planets. Such a compositional gradient hampers large-scale convection that turns into double-diffusive convection, yielding an inner thermal profile that departs from the traditionally assumed adiabatic interior and affecting these planets heat content and cooling history. To address this problem, we have developed an analytical approach to describe layered double-diffusive convection and apply this formalism to solar system gaseous giant planet interiors. These models satisfy all observational constraints and yield values for the metal enrichment of our gaseous giants that are up to 30% to 60% higher than previously thought. The models also constrain the size of the convective layers within the planets. Because the heavy elements tend to be redistributed within the gaseous envelope, the models predict smaller than usual central cores inside Saturn and Jupiter, with possibly no core for the latter. These models open a new window and raise new challenges to our understanding of the internal structure of giant (solar and extrasolar) planets, in particular on how to determine their heavy material content, a key diagnostic for planet formation theories."
"Benyamin Norouzi, S. Mirzakuchaki, Seyed Mohammad Seyedzadeh, M. Mosavi",4f82e79c2b2bdf6217061829ce4cb0c032d856b2,"A simple, sensitive and secure image encryption algorithm based on hyper-chaotic system with only one round diffusion process",Multimedia tools and applications,2012,162,
"B. Scherrer, A. Gholipour, S. Warfield",a6b711839a3c4acdd2d027a2b0812ad694f19fba,Super-resolution reconstruction to increase the spatial resolution of diffusion weighted images from orthogonal anisotropic acquisitions,Medical Image Anal.,2012,125,
"L. Ruthotto, H. Kugel, J. Olesch, B. Fischer, J. Modersitzki, M. Burger, C. Wolters",160fe791abf44df9e3839f27207caeac2827d64a,Diffeomorphic susceptibility artifact correction of diffusion-weighted magnetic resonance images,Physics in Medicine and Biology,2012,102,"Diffusion-weighted magnetic resonance imaging is a key investigation technique in modern neuroscience. In clinical settings, diffusion-weighted imaging and its extension to diffusion tensor imaging (DTI) are usually performed applying the technique of echo-planar imaging (EPI). EPI is the commonly available ultrafast acquisition technique for single-shot acquisition with spatial encoding in a Cartesian system. A drawback of these sequences is their high sensitivity against small perturbations of the magnetic field, caused, e.g., by differences in magnetic susceptibility of soft tissue, bone and air. The resulting magnetic field inhomogeneities thus cause geometrical distortions and intensity modulations in diffusion-weighted images. This complicates the fusion with anatomical T1- or T2-weighted MR images obtained with conventional spin- or gradient-echo images and negligible distortion. In order to limit the degradation of diffusion-weighted MR data, we present here a variational approach based on a reference scan pair with reversed polarity of the phase- and frequency-encoding gradients and hence reversed distortion. The key novelty is a tailored nonlinear regularization functional to obtain smooth and diffeomorphic transformations. We incorporate the physical distortion model into a variational image registration framework and derive an accurate and fast correction algorithm. We evaluate the applicability of our approach to distorted DTI brain scans of six healthy volunteers. For all datasets, the automatic correction algorithm considerably reduced the image degradation. We show that, after correction, fusion with T1- or T2-weighted images can be obtained by a simple rigid registration. Furthermore, we demonstrate the improvement due to the novel regularization scheme. Most importantly, we show that it provides meaningful, i.e. diffeomorphic, geometric transformations, independent of the actual choice of the regularization parameters."
"Bo Wang, Z. Tu",9791196cb6f24b79e25006e735146496c0d43857,Affinity learning via self-diffusion for image segmentation and clustering,2012 IEEE Conference on Computer Vision and Pattern Recognition,2012,60,"Computing a faithful affinity map is essential to the clustering and segmentation tasks. In this paper, we propose a graph-based affinity (metric) learning method and show its application to image clustering and segmentation. Our method, self-diffusion (SD), performs a diffusion process by propagating the similarity mass along the intrinsic manifold of data points. Theoretical analysis is given to the SD algorithm and we provide a way of deriving the critical time stamp t. Our method therefore has nearly no parameter tuning and leads to significantly improved affinity maps, which help to greatly enhance the quality of clustering. In addition, we show that much improved image segmentation results can be obtained by combining SD with e.g. the normalized cuts algorithm. The proposed method can be used to deliver robust affinity maps for a range of problems."
"Hengchao Li, Ping-Zhi Fan, M. Khan",51a921cac10ae04d87509707c6e1c4c0c6ced701,Context-adaptive anisotropic diffusion for image denoising,,2012,31,"To mitigate smoothing of image features in anisotropic diffusion filtering, a novel scheme called context-adaptive anisotropic diffusion is proposed for image denoising via a weighted diffusivity function, which encodes the impact of contextual discontinuities and can adaptively control the smoothing speed for improving the capability of feature preservation along with noise removal. Experimental results validate the effectiveness of the proposed method."
"T. Kuder, F. Laun",6fb24ea136eaccfc22e93606282b462e4573ba44,NMR‐based diffusion pore imaging by double wave vector measurements,Magnetic Resonance in Medicine,2012,19,"One main interest of nuclear magnetic resonance (NMR) diffusion experiments is the investigation of boundaries such as cell membranes hindering the diffusion process. NMR diffusion measurements allow collecting the signal from the whole sample. This mainly eliminates the problem of vanishing signal at increasing resolution. It has been a longstanding question if, in principle, the exact shape of closed pores can be determined by NMR diffusion measurements. In this work, we present a method using short diffusion gradient pulses only, which is able to reveal the shape of arbitrary closed pores without relying on a priori knowledge. In comparison to former approaches, the method has reduced demands on relaxation times due to faster convergence to the diffusion long‐time limit and allows for a more flexible NMR sequence design, because, e.g., stimulated echoes can be used. Magn Reson Med 70:836–841, 2013. © 2012 Wiley Periodicals, Inc."
"V. B. Surya Prasath, Arindama Singh",e34eff9bc825b6aa58fd71e72369f1a3760c98ed,An Adaptive Diffusion Scheme for Image Restoration and Selective Smoothing,International Journal of Image and Graphics,2012,18,"Anisotropic partial differential equation (PDE)-based image restoration schemes employ a local edge indicator function typically based on gradients. In this paper, an alternative pixel-wise adaptive diffusion scheme is proposed. It uses a spatial function giving better edge information to the diffusion process. It avoids the over-locality problem of gradient-based schemes and preserves discontinuities coherently. The scheme satisfies scale space axioms for a multiscale diffusion scheme; and it uses a well-posed regularized total variation (TV) scheme along with Perona-Malik type functions. Median-based weight function is used to handle the impulse noise case. Numerical results show promise of such an adaptive approach on real noisy images."
"D. Paget, F. Cadiz, A. Rowe, F. Moreau, S. Arscott, E. Peytavit",ec6f938da388663dc13a1e05cb4d95a2bbc4ded5,Imaging ambipolar diffusion of photocarriers in GaAs thin films,,2012,17,"Images of the steady-state luminescence of passivated GaAs self-standing films under excitation by a tightly-focussed laser are analyzed as a function of light excitation power. While unipolar diffusion of photoelectrons is dominant at very low light excitation power, an increased power results in a decrease of the diffusion constant near the center of the image due to the onset of ambipolar diffusion. The results are in agreement with a numerical solution of the diffusion equations and with a physical analysis of the luminescence intensity at the centre of the image, which permits the determination of the ambipolar diffusion constant as a function of electron concentration."
"B. Park, Wook Lee, Kyungsook Han",6e65c49ca89c06f78a9c74f03e3d0ece5e054c7f,Modeling the interactions of Alzheimer-related genes from the whole brain microarray data and diffusion tensor images of human brain,BMC Bioinformatics,2012,15,
"Zemin Ren, Chuanjiang He, Meng Li",cc823fbc5068410ea7dddbffb8fde382ae63b3d1,Fractional-order bidirectional diffusion for image up-sampling,J. Electronic Imaging,2012,10,"Following the recently proposed total variation (TV) up-sampling method, we present a novel image up-sampling algorithm based on fractional-order bidirectional diffusion. For the bidirectional diffusion, the forward diffusion occurs on the light side of edge, while the backward diffusion proceeds on the dark side. This bidirectional diffusion can reduce the edge width and avoid the appearances of false edge or texture and block effects. Moreover, the fractional-order derivative is used to avoid strong contrast near the edge in the interpolated images. The experiments show that, unlike the TV up-sampling (TVUP) method, the proposed algorithm does not suffer from the drift of edges, block effect in the smooth regions, false edges, and false texture."
"F. Laun, T. Kuder",2d0635be9f1779198bf61dd15ab2527acbcbdd5e,Diffusion pore imaging with generalized temporal gradient profiles.,Magnetic Resonance Imaging,2012,9,
"Pei Zhang, M. Niethammer, D. Shen, P. Yap",9ea4136d6eaac995291db71ed288468eaee4dd72,Large Deformation Diffeomorphic Registration of Diffusion-Weighted Images,International Conference on Medical Image Computing and Computer-Assisted Intervention,2012,8,
"P. Yap, D. Shen",94d9bda663de0726b47f35043389f13ff67fb990,Resolution Enhancement of Diffusion-Weighted Images by Local Fiber Profiling,International Conference on Medical Image Computing and Computer-Assisted Intervention,2012,4,
"J. Sakamoto, Yoshinori Sasaki, M. Otonari-Yamamoto, K. Nishikawa, T. Sano",ea0544841fab3397e90b9683248f53dccaebe7b5,Diffusion-weighted imaging of the head and neck with HASTE: influence of imaging parameters on image quality,Oral Radiology/Springer,2012,4,
"A. Shabani, J. Zelek, David A Clausi",ddde73cf6397edd0b443cd322df5b740080b5f0d,Regularized Gradient Kernel Anisotropic Diffusion for Better Image Filtering,2012 Ninth Conference on Computer and Robot Vision,2012,3,"This paper proposes an extension to anisotropic diffusion filtering for a better preservation of semantically meaningful structures such as edges in an image in its smoothing/denoising process. The problem of separation of the gradients due to edges and the gradients due to noise is formulated as a nonlinearly separable classification problem. More specifically, the spatially-regularized image gradient is mapped to a higher dimensional Reproducing Kernel Hilbert Space (RKHS) in which the gradients of the edges from those of noise can be readily separated. This proper discrimination of edges prevents the filter from blurring the edges, while smoothing the image. Compared to the existing anisotropic filters, the proposed method improves the denoising and smoothing of an image on both synthetic and real images."
"R. Giot, C. Charrier, M. Descoteaux",61878853f5a21357eb47183899c20a114665c912,Local water diffusion phenomenon clustering from high angular resolution diffusion imaging (HARDI),International Conference on Pattern Recognition,2012,0,"The understanding of neurodegenerative diseases undoubtedly passes through the study of human brain white matter fiber tracts. To date, diffusion magnetic resonance imaging (dMRI) is the unique technique to obtain information about the neural architecture of the human brain, thus permitting the study of white matter connections and their integrity. However, a remaining challenge of the dMRI community is to better characterize complex fiber crossing configurations, where diffusion tensor imaging (DTI) is limited but high angular resolution diffusion imaging (HARDI) now brings solutions. This paper investigates the development of both identification and classification process of the local water diffusion phenomenon based on HARDI data to automatically detect imaging voxels where there are single and crossing fiber bundle populations. The technique is based on knowledge extraction processes and is validated on a dMRI phantom dataset with ground truth."
"Bruno Brandoli Machado, W. Gonçalves, O. Bruno",b22d7835eda81685f604ae3018477f7e7550d72b,Image decomposition with anisotropic diffusion applied to leaf-texture analysis,ArXiv,2012,0,"Texture analysis is an important field of investigation that has received a great deal of interest from computer vision community. In this paper, we propose a novel approach for texture modeling based on partial differential equation (PDE). Each image $f$ is decomposed into a family of derived sub-images. $f$ is split into the $u$ component, obtained with anisotropic diffusion, and the $v$ component which is calculated by the difference between the original image and the $u$ component. After enhancing the texture attribute $v$ of the image, Gabor features are computed as descriptors. We validate the proposed approach on two texture datasets with high variability. We also evaluate our approach on an important real-world application: leaf-texture analysis. Experimental results indicate that our approach can be used to produce higher classification rates and can be successfully employed for different texture applications."
"B. Turkbey, V. Shah, Y. Pang, M. Bernardo, Sheng Xu, J. Kruecker, J. Locklin, A. Baccala, A. Rastinehad, M. Merino, J. Shih, B. Wood, P. Pinto, P. Choyke",1b4a5d3815ff9894f2d14bcbcc4d0d6f939e42d6,Is apparent diffusion coefficient associated with clinical risk scores for prostate cancers that are visible on 3-T MR images?,Radiology,2011,335,"PURPOSE
To investigate whether apparent diffusion coefficients (ADCs) derived from diffusion-weighted (DW) magnetic resonance (MR) imaging at 3 T correlate with the clinical risk of prostate cancer in patients with tumors that are visible on MR images, with MR imaging/transrectal ultrasonography (US) fusion-guided biopsy as a reference.


MATERIALS AND METHODS
Forty-eight consecutive patients (median age, 60 years; median serum prostate-specific antigen value, 6.3 ng/mL) who underwent DW imaging during 3-T MR imaging with an endorectal coil were included in this retrospective institutional review board-approved study, and informed consent was obtained from each patient. Patients underwent targeted MR imaging/transrectal US fusion-guided prostate biopsy. Mean ADCs of cancerous target tumors were correlated with Gleason and D'Amico clinical risk scores. The true risk group rate and predictive value of the mean ADC for classifying a tumor by its D'Amico clinical risk score was determined by using linear discriminant and receiver operating characteristic analyses.


RESULTS
A significant negative correlation was found between mean ADCs of tumors in the peripheral zone and their Gleason scores (P = .003; Spearman ρ = -0.60) and D'Amico clinical risk scores (P < .0001; Spearman ρ = -0.69). ADC was found to distinguish tumors in the peripheral zone with intermediate to high clinical risk from those with low clinical risk with a correct classification rate of 0.73.


CONCLUSION
There is a significant negative correlation between ADCs and Gleason and D'Amico clinical risk scores. ADCs may therefore be useful in predicting the aggressiveness of prostate cancer.


SUPPLEMENTAL MATERIAL
http://radiology.rsna.org/lookup/suppl/doi:10.1148/radiol.10100667/-/DC1."
Mohammad Reza Hajiaboli,49cdb6f40ce905f5fffe9ce2db35f4a9cd78767b,An Anisotropic Fourth-Order Diffusion Filter for Image Noise Removal,International Journal of Computer Vision,2011,139,
"R. Duits, E. Franken",7e59c348bd510799675d67b8d2aa5ce5f7d4e07a,Left-Invariant Diffusions on the Space of Positions and Orientations and their Application to Crossing-Preserving Smoothing of HARDI images,International Journal of Computer Vision,2011,96,
"G. Kumar, K. Bagan, N. Sriraam",dcb093fec9aecb93c562628234a44b87aee4189c,Image Encryption Based on Diffusion and Multiple Chaotic Maps,ArXiv,2011,83,"In the recent world, security is a prime important issue, and encryption is one of the best alternative way to ensure security. More over, there are many image encryption schemes have been proposed, each one of them has its own strength and weakness. This paper presents a new algorithm for the image encryption/decryption scheme. This paper is devoted to provide a secured image encryption technique using multiple chaotic based circular mapping. In this paper, first, a pair of sub keys is given by using chaotic logistic maps. Second, the image is encrypted using logistic map sub key and in its transformation leads to diffusion process. Third, sub keys are generated by four different chaotic maps. Based on the initial conditions, each map may produce various random numbers from various orbits of the maps. Among those random numbers, a particular number and from a particular orbit are selected as a key for the encryption algorithm. Based on the key, a binary sequence is generated to control the encryption algorithm. The input image of 2-D is transformed into a 1- D array by using two different scanning pattern (raster and Zigzag ) and then divided into various sub blocks. Then the position permutation and value permutation is applied to each binary matrix based on multiple chaos maps. Finally the receiver uses the same sub keys to decrypt the encrypted images. The salient features of the proposed image encryption method are loss-less, good peak signal –to noise ratio (PSNR), Symmetric key encryption, less cross correlation, very large number of secret keys, and key-dependent pixel value replacement."
"Markus Mainberger, Andrés Bruhn, J. Weickert, S. Forchhammer",1a4558db489d122d21d38f952fdc633fda301321,Edge-based compression of cartoon-like images with homogeneous diffusion,Pattern Recognition,2011,77,
"M. Janev, S. Pilipovic, T. Atanacković, R. Obradovic, N. Ralević",d32fd1e3242035c64b338a2c5325cd91c359c0a6,Fully fractional anisotropic diffusion for image denoising,Mathematical and computer modelling,2011,62,
"A. Rosenkrantz, L. Mannelli, X. Kong, Ben E. Niver, Douglas S. Berkman, J. Babb, J. Melamed, S. Taneja",15c79f222433c38d6c426b7156ef39b2c8bf0d52,Prostate cancer: Utility of fusion of T2‐weighted and high b‐value diffusion‐weighted images for peripheral zone tumor detection and localization,Journal of Magnetic Resonance Imaging,2011,59,To retrospectively assess the utility of fusion of T2‐weighted images (T2WI) and high b‐value diffusion‐weighted images (DWI) for prostate cancer detection and localization.
"P. Bazin, Chuyang Ye, J. Bogovic, N. Shiee, D. Reich, Jerry L Prince, D. Pham",a14401e3e65143da5ec9d7bdbf5b9efa91debd9b,Direct segmentation of the major white matter tracts in diffusion tensor images,NeuroImage,2011,57,
"P. Guidotti, K. Longo",25c40a16830d47a18ae182ed9438c1cb8e6f577c,Two Enhanced Fourth Order Diffusion Models for Image Denoising,Journal of Mathematical Imaging and Vision,2011,52,
"A. Goh, C. Lenglet, P. Thompson, R. Vidal",5390a8910a8da41c05cfdb075f8e77fc9bd9ecd8,A nonparametric Riemannian framework for processing high angular resolution diffusion images and its applications to ODF-based morphometry,NeuroImage,2011,51,
"A. Rosenkrantz, X. Kong, B. Niver, D. S. Berkman, J. Melamed, J. Babb, S. Taneja",23bd8320c19b27c007c5aea15aead18ee4b72a13,Prostate cancer: comparison of tumor visibility on trace diffusion-weighted images and the apparent diffusion coefficient map.,AJR. American journal of roentgenology,2011,44,"OBJECTIVE
The purpose of our study was to compare the visibility of prostate cancer on trace diffusion-weighted (DW) images and the apparent diffusion coefficient (ADC) map.


MATERIALS AND METHODS
In this retrospective study, 45 patients with prostate cancer underwent preoperative MRI, including DW imaging (DWI) (b values 0, 500, and 1,000 s/mm(2)). A single observer reviewed the images in conjunction with tumor maps constructed from prostatectomy. For 132 peripheral zone (PZ) tumor foci, the visibility and contrast relative to benign PZ were recorded for T2-weighted imaging, trace DWI b500 images, trace DWI b1,000 images, and ADC maps. Trace DWI b1,000 images and ADC maps were compared in terms of Gleason score, size, normalized T2 signal intensity, ADC, and normalized ADC of visible tumors.


RESULTS
For each image set, the percentage of visible tumor foci and contrast relative to benign PZ were as follows: T2-weighted imaging, 80.3% and 0.411; trace DWI b500, 26.5% and 0.131; trace DWI b1,000, 46.2% and 0.119; and ADC maps, 62.1% and 0.309. Forty-seven tumor foci were visible on both trace DWI b1,000 images and ADC maps, 14 only on trace DWI b1,000 images, 35 only on ADC maps, and 36 on neither image set. There was no significant difference in Gleason score, size, normalized T2 signal intensity, ADC, or normalized ADC between tumors visible only on trace DWI b1,000 images and those visible only on ADC maps.


CONCLUSION
Given a greater proportion of tumors visible on the ADC map than trace DWI and greater contrast relative to benign PZ on the ADC map, we suggest that, when performing DWI of the prostate, careful attention be given to the ADC map for tumor identification."
"T. Tarvainen, V. Kolehmainen, S. Arridge, J. Kaipio",fb8ec749720f3d533d3d1204b482480fc7c88121,Image reconstruction in diffuse optical tomography using the coupled radiative transport–diffusion model,,2011,40,
"Zhichang Guo, Jingxue Yin, Qiang Liu",5b7c2de00c48c6f63878b66c83cca42a209b2fb6,On a reaction-diffusion system applied to image decomposition and restoration,Mathematical and computer modelling,2011,33,
"X. Geng, T. Ross, Hong Gu, W. Shin, W. Zhan, Y. Chao, Ching-Po Lin, N. Schuff, Yihong Yang",ca98a7157903afa64bdd1f356464263269592819,Diffeomorphic Image Registration of Diffusion MRI Using Spherical Harmonics,IEEE Transactions on Medical Imaging,2011,29,"Nonrigid registration of diffusion magnetic resonance imaging (MRI) is crucial for group analyses and building white matter and fiber tract atlases. Most current diffusion MRI registration techniques are limited to the alignment of diffusion tensor imaging (DTI) data. We propose a novel diffeomorphic registration method for high angular resolution diffusion images by mapping their orientation distribution functions (ODFs). ODFs can be reconstructed using q-ball imaging (QBI) techniques and represented by spherical harmonics (SHs) to resolve intra-voxel fiber crossings. The registration is based on optimizing a diffeomorphic demons cost function. Unlike scalar images, deforming ODF maps requires ODF reorientation to maintain its consistency with the local fiber orientations. Our method simultaneously reorients the ODFs by computing a Wigner rotation matrix at each voxel, and applies it to the SH coefficients during registration. Rotation of the coefficients avoids the estimation of principal directions, which has no analytical solution and is time consuming. The proposed method was validated on both simulated and real data sets with various metrics, which include the distance between the estimated and simulated transformation fields, the standard deviation of the general fractional anisotropy and the directional consistency of the deformed and reference images. The registration performance using SHs with different maximum orders were compared using these metrics. Results show that the diffeomorphic registration improved the affine alignment, and registration using SHs with higher order SHs further improved the registration accuracy by reducing the shape difference and improving the directional consistency of the registered and reference ODF maps."
"P. Guidotti, K. Longo",d4b4fb5180ee42db1fe1c79f260c1b5a274bb637,Well-posedness for a class of fourth order diffusions for image processing,,2011,21,
"Jing-Ming Guo, J. Tsai",dc294edfa6a5e3dd16eaf2ea4744375069c65211,Data-Hiding in Halftone Images Using Adaptive Noise-Balanced Error Diffusion,IEEE Multimedia,2011,16,The paper discusses a data-hiding approach that embeds a secret pattern into two or more halftone images using adaptive noise balanced error diffusion.
"J. Calder, A. Mansouri, A. Yezzi",c73c5b7d8cf59114832e38958e0451430ce634ff,New Possibilities in Image Diffusion and Sharpening via High-Order Sobolev Gradient Flows,Journal of Mathematical Imaging and Vision,2011,13,
"Xiaoli Sun, Min Li, Weiqiang Zhang",eef0efc17092d0fae2a829560d2574d9b423c0b1,An improved image denoising model based on the directed diffusion equation,Computers and Mathematics with Applications,2011,10,
"J. I. Gonzalez, P. Thompson, Aishan Zhao, Z. Tu",fe4e0a7ebc262a9bf9a4c068999d3951e0c72c3d,Modeling diffusion-weighted MRI as a spatially variant gaussian mixture: application to image denoising.,Medical Physics (Lancaster),2011,7,"PURPOSE
This work describes a spatially variant mixture model constrained by a Markov random field to model high angular resolution diffusion imaging (HARDI) data. Mixture models suit HARDI well because the attenuation by diffusion is inherently a mixture. The goal is to create a general model that can be used in different applications. This study focuses on image denoising and segmentation (primarily the former).


METHODS
HARDI signal attenuation data are used to train a Gaussian mixture model in which the mean vectors and covariance matrices are assumed to be independent of spatial locations, whereas the mixture weights are allowed to vary at different lattice positions. Spatial smoothness of the data is ensured by imposing a Markov random field prior on the mixture weights. The model is trained in an unsupervised fashion using the expectation maximization algorithm. The number of mixture components is determined using the minimum message length criterion from information theory. Once the model has been trained, it can be fitted to a noisy diffusion MRI volume by maximizing the posterior probability of the underlying noiseless data in a Bayesian framework, recovering a denoised version of the image. Moreover, the fitted probability maps of the mixture components can be used as features for posterior image segmentation.


RESULTS
The model-based denoising algorithm proposed here was compared on real data with three other approaches that are commonly used in the literature: Gaussian filtering, anisotropic diffusion, and Rician-adapted nonlocal means. The comparison shows that, at low signal-to-noise ratio, when these methods falter, our algorithm considerably outperforms them. When tractography is performed on the model-fitted data rather than on the noisy measurements, the quality of the output improves substantially. Finally, ventricle and caudate nucleus segmentation experiments also show the potential usefulness of the mixture probability maps for classification tasks.


CONCLUSIONS
The presented spatially variant mixture model for diffusion MRI provides excellent denoising results at low signal-to-noise ratios. This makes it possible to restore data acquired with a fast (i.e., noisy) pulse sequence to acceptable noise levels. This is the case in diffusion MRI, where a large number of diffusion-weighted volumes have to be acquired under clinical time constraints."
"Yuanfang Guo, O. Au, Lu Fang, K. Tang",2f797061b3249ac8ed03edc41d875ab52071014a,Data Hiding in Halftone Images by Dual Conjugate Error Diffusion,,2011,6,"In this paper, we propose a new halftone watermarking method named Data Hiding by Dual Conjugate Error Diffusion (DHDCED) based on Data Hiding by Conjugate Error Diffusion (DHCED). Unlike DHCED, The proposed method will embed a binary secret pattern into two or more error diffused halftone images by modifying each of them. When the two halftone images are overlaid, the secret pattern will be revealed. From the results we can observe that the proposed method not only improves the perceptibility of the embedded secret pattern but also improves the contrast of the revealed hidden pattern."
"J. I. Gonzalez, P. Thompson, Aishan Zhao, Z. Tu",def4eef954fd74baea65bbe58591f0e919ba0a7c,Modeling diffusion-weighted MRI as a spatially variant Gaussian mixture: Application to image denoising.,Medical Physics (Lancaster),2011,5,"PURPOSE
This work describes a spatially variant mixture model constrained by a Markov random field to model high angular resolution diffusion imaging (HARDI) data. Mixture models suit HARDI well because the attenuation by diffusion is inherently a mixture. The goal is to create a general model that can be used in different applications. This study focuses on image denoising and segmentation (primarily the former).


METHODS
HARDI signal attenuation data are used to train a Gaussian mixture model in which the mean vectors and covariance matrices are assumed to be independent of spatial locations, whereas the mixture weights are allowed to vary at different lattice positions. Spatial smoothness of the data is ensured by imposing a Markov random field prior on the mixture weights. The model is trained in an unsupervised fashion using the expectation maximization algorithm. The number of mixture components is determined using the minimum message length criterion from information theory. Once the model has been trained, it can be fitted to a noisy diffusion MRI volume by maximizing the posterior probability of the underlying noiseless data in a Bayesian framework, recovering a denoised version of the image. Moreover, the fitted probability maps of the mixture components can be used as features for posterior image segmentation.


RESULTS
The model-based denoising algorithm proposed here was compared on real data with three other approaches that are commonly used in the literature: Gaussian filtering, anisotropic diffusion, and Rician-adapted nonlocal means. The comparison shows that, at low signal-to-noise ratio, when these methods falter, our algorithm considerably outperforms them. When tractography is performed on the model-fitted data rather than on the noisy measurements, the quality of the output improves substantially. Finally, ventricle and caudate nucleus segmentation experiments also show the potential usefulness of the mixture probability maps for classification tasks.


CONCLUSIONS
The presented spatially variant mixture model for diffusion MRI provides excellent denoising results at low signal-to-noise ratios. This makes it possible to restore data acquired with a fast (i.e., noisy) pulse sequence to acceptable noise levels. This is the case in diffusion MRI, where a large number of diffusion-weighted volumes have to be acquired under clinical time constraints."
"Rhouma Rhouma, E. Solak, S. Belghith",8cd2a49ffae0d13190bb89e64235284318993ad3,Cryptanalysis of a new substitution–diffusion based image cipher,,2010,188,
M. Zwiers,46ecaa4e3ee26cd22c3c9973317b516baf31cd18,Patching cardiac and head motion artefacts in diffusion-weighted images,NeuroImage,2010,124,
"N. Toussaint, Maxime Sermesant, C. Stoeck, S. Kozerke, P. Batchelor",8ef549f320438ce0579ec8d0290d46c82f83f2be,In vivo Human 3D Cardiac Fibre Architecture: Reconstruction Using Curvilinear Interpolation of Diffusion Tensor Images,International Conference on Medical Image Computing and Computer-Assisted Intervention,2010,82,
"Juyong Zhang, Jianmin Zheng, Jianfei Cai",544e0a29b8d07979502067ceadd5e8980c4504ca,A diffusion approach to seeded image segmentation,2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition,2010,78,"Seeded image segmentation is a popular type of supervised image segmentation in computer vision and image processing. Previous methods of seeded image segmentation treat the image as a weighted graph and minimize an energy function on the graph to produce a segmentation. In this paper, we propose to conduct the seeded image segmentation according to the result of a heat diffusion process in which the seeded pixels are considered to be the heat sources and the heat diffuses on the image starting from the sources. After the diffusion reaches a stable state, the image is segmented based on the pixel temperatures. It is also shown that our proposed framework includes the RandomWalk algorithm for image segmentation as a special case which diffuses only along the two coordinate axes. To better control diffusion, we propose to incorporate the attributes (such as the geometric structure) of the image into the diffusion process, yielding an anisotropic diffusion method for image segmentation. The experiments show that the proposed anisotropic diffusion method usually produces better segmentation results. In particular, when the method is tested using the groundtruth dataset of Microsoft Research Cambridge (MSRC), an error rate of 4.42% can be achieved, which is lower than the reported error rates of other state-of-the-art algorithms."
"U. Boscain, J. Duplaix, J. Gauthier, Francesco Rossi",5ded63b0f5c80f5778dd03e561e8532bcaf7db8c,Anthropomorphic Image Reconstruction via Hypoelliptic Diffusion,SIAM Journal of Control and Optimization,2010,54,"In this paper we study a model of geometry of vision due to Petitot, Citti, and Sarti. One of the main features of this model is that the primary visual cortex V1 lifts an image from $\mathbb{R}^2$ to the bundle of directions of the plane. Neurons are grouped into orientation columns, each of them corresponding to a point of this bundle. In this model a corrupted image is reconstructed by minimizing the energy necessary for the activation of the orientation columns corresponding to regions in which the image is corrupted. The minimization process intrinsically defines a hypoelliptic heat equation on the bundle of directions of the plane. In the original model, directions are considered both with and without orientation, giving rise, respectively, to a problem on the group of rototranslations of the plane $SE(2)$ or on the projective tangent bundle of the plane $PT\mathbb{R}^2$. We provide a mathematical proof of several important facts for this model. We first prove that the model is mathematically consis..."
"A. Roussos, P. Maragos",24c9da7a4c7e55d78142c7b175b6f08abee63ac8,Tensor-based image diffusions derived from generalizations of the Total Variation and Beltrami Functionals,2010 IEEE International Conference on Image Processing,2010,40,"We introduce a novel functional for vector-valued images that generalizes several variational methods, such as the Total Variation and Beltrami Functionals. This functional is based on the structure tensor that describes the geometry of image structures within the neighborhood of each point. We first generalize the Beltrami functional based on the image patches and using embeddings in high dimensional spaces. Proceeding to the most general form of the proposed functional, we prove that its minimization leads to a nonlinear anisotropic diffusion that is regularized, in the sense that its diffusion tensor contains convolutions with a kernel. Using this result we propose two novel diffusion methods, the Generalized Beltrami Flow and the Tensor Total Variation. These methods combine the advantages of the variational approaches with those of the tensor-based diffusion approaches."
"M. Trigo, J. Chen, V. Vishwanath, Y. Sheu, T. Graber, R. Henning, D. Reis",6247599e1be499b9999000fb207191c8d8c74653,Imaging nonequilibrium atomic vibrations with x-ray diffuse scattering.,"Physical review. B, Condensed matter and materials physics",2010,38,We use picosecond x-ray diffuse scattering to image the nonequilibrium vibrations in the lattice following ultrafast laser excitation. We present images of nonequilibrium phonons in InP and InSb throughout the Brillouin zone which remain out of equilibrium up to nanoseconds. The results are analyzed using a Born model that helps identify the phonon branches contributing to the observed features in the time-resolved diffuse scattering. In InP this analysis shows a delayed increase in the transverse-acoustic (TA) phonon population along high-symmetry directions accompanied by a decrease in the longitudinal-acoustic phonons. In InSb the increase in TA phonon population is less directional.
"V. B. Surya Prasath, Arindama Singh",40258af7501be43ce9aca81cb14df0b7edd430ae,Well-Posed Inhomogeneous Nonlinear Diffusion Scheme for Digital Image Denoising,Journal of Applied Mathematics,2010,34,"We study an inhomogeneous partial differential equation which includes a separate edge detection part to control smoothing in and around possible discontinuities, under the framework of 
anisotropic diffusion. By incorporating edges found at multiple scales 
via an adaptive edge detector-based indicator function, the proposed 
scheme removes noise while respecting salient boundaries. We create 
a smooth transition region around probable edges found and reduce 
the diffusion rate near it by a gradient-based diffusion coefficient. In 
contrast to the previous anisotropic diffusion schemes, we prove the 
well-posedness of our scheme in the space of bounded variation. The 
proposed scheme is general in the sense that it can be used with any 
of the existing diffusion equations. Numerical simulations on noisy 
images show the advantages of our scheme when compared to other 
related schemes."
"V. B. Surya Prasath, Arindama Singh",64ab863853f583590d035b087ffb14f3443ea6f9,Multispectral image denoising by well-posed anisotropic diffusion scheme with channel coupling,,2010,29,A novel way to denoise multispectral images is proposed via an anisotropic diffusion based partial differential equation (PDE). A coupling term is added to the divergence term and it facilitates the modelling of interchannel relations in multidimensional image data. A total variation function is used to model the intrachannel smoothing and gives a piecewise smooth result with edge preservation. The coupling term uses weights computed from different bands of the input image and balances the interchannel information in the diffusion process. It aligns edges from different channels and stops the diffusion transfer using the weights. Well-posedness of the PDE is proved in the space of bounded variation functions. Comparison with the previous approaches is provided to demonstrate the advantages of the proposed scheme. The simulation results show that the proposed scheme effectively removes noise and preserves the main features of multispectral image data by taking channel coupling into consideration.
"J. Andersson, S. Skare",e650ab3209c00227c4be78ac895a7f9f3e903e5d,Image Distortion and Its Correction in Diffusion MRI,,2010,26,
"Qing Xu, A. Anderson, J. Gore, Z. Ding",5f4e1d59005956404628ad67fb1c5ee1382057e3,Efficient anisotropic filtering of diffusion tensor images.,Magnetic Resonance Imaging,2010,14,
"P. Rodrigues, A. Jalba, P. Fillard, A. Vilanova, ter B.M. Haar Romenij",f223b76d9796b50fa167853c5c8858321eea2260,A multi-resolution watershed-based approach for the segmentation of diffusion tensor images,,2010,9,"The analysis and visualisation of Di usion Tensor Images (DTI) is still a challenge since it is multi-valued and exploratory in nature: tensors, ber tracts, bundles. This quickly leads to clutter problems in visualisation but also in analysis. In this paper, a new framework for the multi-resolution analysis of DTI is proposed. Based on fast and greedy watersheds operating on a multi-scale representation of a DTI image, a hierarchical depiction of a DTI image is determined conveying a global-to-local view of the brous structure of the analysed tissue. The multi-resolution watershed transform provides a coarse to ne partitioning of the data based on the (in)homogeneity of the gradient eld. With a transversal cross scale linking of the basins (regions), a hierarchical representation is established. This framework besides providing a novel hierarchical way to analyse DTI data, allows a simple and interactive segmentation tool where different bundles can be segmented at di erent resolutions. We present preliminary experimental results supporting the validity of the proposed method."
"K. Jacobs, D. Steck",8a9cf380516e7c9f2d93e499f744e8dd6408fe57,"Engineering quantum states, nonlinear measurements and anomalous diffusion by imaging",,2010,3,"We show that well-separated quantum superposition states, measurements of strongly nonlinear observables and quantum dynamics driven by anomalous diffusion can all be achieved for single atoms or molecules by imaging spontaneous photons that they emit via resonance florescence. To generate anomalous diffusion we introduce continuous measurements driven by Lévy processes and prove a number of results regarding their properties. In particular, we present strong evidence that the only stable Lévy density that can realize a strictly continuous measurement is the Gaussian."
"S. Olhede, Brandon Whitcher",76d960ebf17d5545f7d501997769290f16494def,Nonparametric tests of structure for high angular resolution diffusion imaging in Q-space,Annals of Applied Statistics,2010,1,"High angular resolution diffusion imaging data is the observed characteristic function for the local diffusion of water molecules in tissue. This data is used to infer structural information in brain imaging. Nonparametric scalar measures are proposed to summarize such data, and to locally characterize spatial features of the diffusion probability density function (PDF), relying on the geometry of the characteristic function. Summary statistics are defined so that their distributions are, to first-order, both independent of nuisance parameters and also analytically tractable. The dominant direction of the diffusion at a spatial location (voxel) is determined, and a new set of axes are introduced in Fourier space. Variation quantified in these axes determines the local spatial properties of the diffusion density. Nonparametric hypothesis tests for determining whether the diffusion is unimodal, isotropic or multi-modal are proposed. More subtle characteristics of white-matter microstructure, such as the degree of anisotropy of the PDF and symmetry compared with a variety of asymmetric PDF alternatives, may be ascertained directly in the Fourier domain without parametric assumptions on the form of the diffusion PDF. We simulate a set of diffusion processes and characterize their local properties using the newly introduced summaries. We show how complex white-matter structures across multiple voxels exhibit clear ellipsoidal and asymmetric structure in simulation, and assess the performance of the statistics in clinically-acquired magnetic resonance imaging data."
C.K.Bhat,29713cd4ead120ebd24cb1d0963eaca54335e1d8,Search for diffuse cosmic gamma-ray flux using Fractal and Wavelet analysis from Galactic region using single imaging Cerenkov telescopes,,2010,0,
"Vinod Patidar, N. K. Pareek, K. Sud",bfbb934dbe79b1af08aa12ee24c0f7c703c0379e,A new substitution–diffusion based image cipher using chaotic standard and logistic maps,,2009,373,
"I. Dryden, A. Koloydenko, Diwei Zhou",0a15503913d0c6d493a812033f98ef04da39b317,"Non-Euclidean statistics for covariance matrices, with applications to diffusion tensor imaging",,2009,342,"The statistical analysis of covariance matrices occurs in m any important applications, e.g. in diffusion tensor imaging or longitudinal data analysis. We consider the situation where it is of interest to estimate an average covariance matrix, describe its anisotropy and to carry out principal geodesic analysis of covariance matrices. In medical image analysis a particular type of covariance matrix arises in diffusion weighted imaging called a diffusion tensor. The diffusion tensor is a 3 × 3 covariance matrix which is estimated at each voxel in the brain, and is obtained by fittin g a physically-motivated model on measurements from the Fourier transform of the molecule displacement density (Basser et al., 1994). A strongly anisotropic diffusion tensor indicates a strong direction of white matter fibre tracts, and plots of measures of anisotropy are very useful t o neurologists. A measure that is very commonly used in diffusion tensor imaging is Fractional Anisotropy"
"H. Lim, Jeong Kon Kim, Kyung Ah Kim, K. Cho",d7dfff6b877e75fbdf5e13bf6f6cc12473136d50,Prostate cancer: apparent diffusion coefficient map with T2-weighted images for detection--a multireader study.,Radiology,2009,262,"PURPOSE
To retrospectively assess the incremental value of an apparent diffusion coefficient (ADC) map combined with T2-weighted magnetic resonance (MR) images compared with T2-weighted images alone for prostate cancer detection by using a pathologic map as the reference standard.


MATERIALS AND METHODS
This retrospective study was approved by the institutional review board; informed consent was waived. The study included 52 patients (mean age, 65 years +/- 5 [standard deviation]; range, 48-76 years) who underwent endorectal MR imaging and step-section histologic examination. Three readers with varying experience levels reviewed T2-weighted images alone, the ADC map alone, and T2-weighted images and ADC maps. The prostate was divided into 12 segments. The probability of prostate cancer in each segment on MR images was recorded with a five-point scale. Areas under the receiver operating characteristic curve (AUCs) were compared by using the Z test; sensitivity and specificity were determined with the Z test after adjusting for data clustering.


RESULTS
AUC of T2-weighted and ADC data (reader 1, 0.90; reader 2, 0.88; reader 3, 0.76) was greater than that of T2-weighted images (reader 1, 0.79; reader 2, 0.75; reader 3, 0.66) for all readers (P < .0001 in all comparisons). AUC of T2-weighted and ADC data was greater for readers 1 and 2 than for reader 3 (P < .001). Sensitivity of T2-weighted and ADC data (reader 1, 88%; reader 2, 81%; and reader 3, 78%) was greater than that of T2-weighted images (reader 1, 74%; reader 2, 67%; reader 3, 67%) for all readers (P = .01 for reader 1; P = .02 for readers 2 and 3). Specificity of T2-weighted and ADC data was greater than that of T2-weighted images for reader 1 (88% vs 79%, P = .03) and reader 2 (89% vs 77%, P < .001).


CONCLUSION
The addition of an ADC map to T2-weighted images can improve the diagnostic performance of MR imaging in prostate cancer detection."
"Chengqing Li, S. Li, K. Lo",d49536578625a50407d4b2cc1d664c03216e2c3f,Breaking a modified substitution-diffusion image cipher based on chaotic standard and logistic maps,ArXiv,2009,124,
"E. Bollt, R. Chartrand, S. Esedoglu, Pete Schultz, K. Vixie",b1e00f5457184550f035aae6ae9ce51aa2019cbc,Graduated adaptive image denoising: local compromise between total variation and isotropic diffusion,Advances in Computational Mathematics,2009,82,
"Ran Tao, P. Fletcher, Samuel Gerber, R. Whitaker",1707cd3b4b7bbe9332a3334a484be7aecd4b1de1,A Variational Image-Based Approach to the Correction of Susceptibility Artifacts in the Alignment of Diffusion Weighted and Structural MRI,Information Processing in Medical Imaging,2009,53,
"Markus Mainberger, J. Weickert",daf2b3c91f9c2380ef9a937bba44672119e3d7c6,Edge-Based Image Compression with Homogeneous Diffusion,International Conference on Computer Analysis of Images and Patterns,2009,45,
P. Guidotti,0b29bba31ed74d0906f0b4f02f8ff6f78bb17ff0,A new nonlocal nonlinear diffusion of image processing,,2009,38,
"A. Goh, C. Lenglet, P. Thompson, R. Vidal",f0b6981bc0147e17bea12d58acae2e51727782f0,A nonparametric Riemannian framework for processing high angular resolution diffusion images (HARDI),2009 IEEE Conference on Computer Vision and Pattern Recognition,2009,37,"High angular resolution diffusion imaging has become an important magnetic resonance technique for in vivo imaging. Most current research in this field focuses on developing methods for computing the orientation distribution function (ODF), which is the probability distribution function of water molecule diffusion along any angle on the sphere. In this paper, we present a Riemannian framework to carry out computations on an ODF field. The proposed framework does not require that the ODFs be represented by any fixed parameterization, such as a mixture of von Mises-Fisher distributions or a spherical harmonic expansion. Instead, we use a non-parametric representation of the ODF, and exploit the fact that under the square-root re-parameterization, the space of ODFs forms a Riemannian manifold, namely the unit Hilbert sphere. Specifically, we use Riemannian operations to perform various geometric data processing algorithms, such as interpolation, convolution and linear and nonlinear filtering. We illustrate these concepts with numerical experiments on synthetic and real datasets."
"I. Eckstein, D. Shattuck, J. Stein, K. Mcmahon, G. Zubicaray, M. Wright, P. Thompson, A. Toga",519275612ac6b766e9e72b0322b6536ab313d038,Active fibers: Matching deformable tract templates to diffusion tensor images,NeuroImage,2009,23,
"W. Santos, F. D. Assis, R. E. D. Souza, Plínio B. Santos Filho, Fernando Buarque de Lima-Neto",2768b346fa2ac2c82141125bb28d67da67feb5a4,Dialectical multispectral classification of diffusion-weighted magnetic resonance images as an alternative to apparent diffusion coefficients maps to perform anatomical analysis,Comput. Medical Imaging Graph.,2009,15,
"Hai Li, Z. Xue, Lei Guo, Stephen T. C. Wong",88b5ecfe6d3e8e0eb2e5eb9eb22acac5d1bdd63e,Simultaneous Consideration of Spatial Deformation and Tensor Orientation in Diffusion Tensor Image Registration Using Local Fast Marching Patterns,Information Processing in Medical Imaging,2009,12,
"R. Duits, E. Franken",600ae0d9fa4a2ea1211fd01f3b662edb29e7f735,Left-invariant diffusions on R^3 x S^2 and their application to crossing-preserving smoothing on HARDI-images,,2009,8,"In previous work we studied linear and nonlinear left-invariant diffusion equations on the 2D Euclidean motion group SE(2), for the purpose of crossing-preserving coherence-enhancing diffusion on 2D images. In this article we study left-invariant diffusion on the 3D Euclidean motion group SE(3) and its application to crossing-preserving smoothing of high angular resolution diffusion imaging (HARDI), which is a recent magnetic resonance imaging (MRI) technique for imaging water diffusion processes in fibrous tissues such as brain white matter and muscles. The linear left-invariant (convection-)diffusions are forward Kolmogorov equations of Brownian motions on the space R3 o S2 of positions and orientations embedded in SE(3) and can be solved by R3 o S2-convolution with the corresponding Green’s functions. We provide analytic approximation formulae and explicit sharp Gaussian estimates for these Green’s functions. In our design and analysis for appropriate (non-linear) convection-diffusions on HARDI-data we put emphasis on the underlying differential geometry on SE(3). We write our left-invariant diffusions in covariant derivatives on SE(3) using the Cartan-connection. This Cartan-connection has constant curvature and constant torsion, and so have the exponential curves which are the auto-parallels along which our left-invariant diffusion takes place. We provide experiments of our crossing-preserving Euclidean-invariant diffusions on artificial HARDI-data containing crossing-fibers."
V. B. Surya Prasath,ead09aa2f1cbc7bc898c4291b99cfe733fcfec96,Color Image Segmentation Based on Vectorial Multiscale Diffusion with Inter-scale Linking,Pattern Recognition and Machine Intelligence,2009,8,
"Emmanuel Caruyer, R. Deriche",d684c61750c3ef5a538301c8927045caed1e9522,Adaptive Design of Sampling Directions in Diffusion Tensor MRI and Validation on Human Brain Images,,2009,3,"Diffusion tensor reconstruction is made possible through the acquisition of several diffusion weighted images, each corresponding to a given sampling direction in the Q-space. In this study, we address the question of sampling efficiency, and show that in case we have some prior knowledge on the diffusion characteristics, we may be able to adapt the sampling directions for better reconstruction of the diffusion tensor. The prior is a tensor distribution function, estimated over a given region of interest, possibly on several subjects. We formulate an energy related to error on tensor reconstruction, and calculate analytical gradient expression for efficient minimization. We validate our approach on a set of 5199 tensors taken within the corpus callosum of the human brain, and show improvement by an order of 10% on the MSE of the reconstructed tensor."
"I. Galić, J. Weickert, M. Welk, Andrés Bruhn, A. Belyaev, H. Seidel",adacb4f6d66cdb100fa0eef1bacc375379714883,Image Compression with Anisotropic Diffusion,Journal of Mathematical Imaging and Vision,2008,155,
"M. Chiang, A. Leow, A. Klunder, R. Dutton, M. Barysheva, S. Rose, K. Mcmahon, G. Zubicaray, A. Toga, P. Thompson",78b025410c4056fb2f3551ffd23d93484c248949,Fluid Registration of Diffusion Tensor Images Using Information Theory,IEEE Transactions on Medical Imaging,2008,125,"We apply an information-theoretic cost metric, the symmetrized Kullback-Leibler (sKL) divergence, or J-divergence, to fluid registration of diffusion tensor images. The difference between diffusion tensors is quantified based on the sKL-divergence of their associated probability density functions (PDFs). Three-dimensional DTI data from 34 subjects were fluidly registered to an optimized target image. To allow large image deformations but preserve image topology, we regularized the flow with a large-deformation diffeomorphic mapping based on the kinematics of a Navier-Stokes fluid. A driving force was developed to minimize the J-divergence between the deforming source and target diffusion functions, while reorienting the flowing tensors to preserve fiber topography. In initial experiments, we showed that the sKL-divergence based on full diffusion PDFs is adaptable to higher-order diffusion models, such as high angular resolution diffusion imaging (HARDI). The sKL-divergence was sensitive to subtle differences between two diffusivity profiles, showing promise for nonlinear registration applications and multisubject statistical analysis of HARDI data."
B. Damon,4d0e26dafb1d643832f7ac8c5ab1fbc8e63f2844,Effects of image noise in muscle diffusion tensor (DT)‐MRI assessed using numerical simulations,Magnetic Resonance in Medicine,2008,101,"Diffusion tensor (DT)‐MRI studies of skeletal muscle provide information about muscle architecture, microstructure, and damage. However, the effects of noise, the diffusion weighting (b)‐value, and partial volume artifacts on the estimation of the diffusion tensor (D) are unknown. This study investigated these issues using Monte Carlo simulations of 3 × 9 voxel regions of interest (ROIs) containing muscle, adipose tissue, and intermediate degrees of muscle volume fractions (fM). A total of 1000 simulations were performed for each of eight b‐values and 11 SNR levels. The dependencies of the eigenvalues (λ1–3), mean diffusivity (λ), and fractional anisotropy (FA), and the angular deviation of the first eigenvector from its true value (α) were observed. For moderate b‐values (b = 435–725 s/mm2) and fM = 1, an accuracy of 5% was obtained for λ1–3, λ, and FA with an SNR of 25. An accuracy of 1% was obtained for λ1–3, λ, and FA with fM = 1 and SNR = 50. For regions with fM = 8/9, 5% accuracy was obtained with SNR = 40. For α, SNRs of ≥25 and ≥45 were required for ±4.5° uncertainty with fM = 1 and fM = 0.5, respectively; SNR ≥ 60 was required for ±9° uncertainty in single muscle voxels. These findings may influence the design and interpretation of DT‐MRI studies of muscle microstructure, damage, and architecture. Magn Reson Med 60:934–944, 2008. © 2008 Wiley‐Liss, Inc."
"Hao Huang, C. Ceritoglu, Xin Li, A. Qiu, M. Miller, P. V. van Zijl, S. Mori",55dd59682de70b9f9e86b90275370ec41ed6e2c8,Correction of B0 susceptibility induced distortion in diffusion-weighted images using large-deformation diffeomorphic metric mapping.,Magnetic Resonance Imaging,2008,96,
"Jinzhong Yang, D. Shen, C. Davatzikos, R. Verma",3cb7c39b9f369959fc669523a9fddce1e061e751,Diffusion Tensor Image Registration Using Tensor Geometry and Orientation Features,International Conference on Medical Image Computing and Computer-Assisted Intervention,2008,84,
"G. Plonka-Hoch, Jianwei Ma",d15419a5657dd974774a0ef9142011cd47cd6c12,Nonlinear Regularized Reaction-Diffusion Filters for Denoising of Images With Textures,IEEE Transactions on Image Processing,2008,75,"Denoising is always a challenging problem in natural imaging and geophysical data processing. In this paper, we consider the denoising of texture images using a nonlinear reaction-diffusion equation and directional wavelet frames. In our model, a curvelet shrinkage is used for regularization of the diffusion process to preserve important features in the diffusion smoothing and a wave atom shrinkage is used as the reaction in order to preserve and enhance interesting oriented textures. We derive a digital reaction-diffusion filter that lives on graphs and show convergence of the corresponding iteration process. Experimental results and comparisons show very good performance of the proposed model for texture-preserving denoising."
"S. Sotiropoulos, Li-Lai Bai, P. Morgan, D. Auer, C. Constantinescu, C. Tench",5a06559c2159e20ba61310133236865956137b55,A regularized two‐tensor model fit to low angular resolution diffusion images using basis directions,Journal of Magnetic Resonance Imaging,2008,41,To resolve and regularize orientation estimates for two crossing fibers from images acquired with conventional diffusion tensor imaging (DTI) sampling schemes.
"G. Sanguinetti, G. Citti, A. Sarti",0044c85a7520aa1712e58c0b1dad223f9eaebad9,Image Completion Using a Diffusion Driven Mean Curvature Flowin A Sub-Riemannian Space,International Conference on Computer Vision Theory and Applications,2008,33,"Dipartimento di Elettronica, Informatica e Sistemistica, Universita di Bologna, Bologna, Italy`citti@dm.unibo.itKeywords: Perceptual completion.Abstract: In this paper we present an implementation of a perceptual completion model performed in the three dimen-sional space of position and orientation of level lines of an image. We show that the space is equipped witha natural subriemannian metric. This model allows to perform disocclusion representing both the occludingand occluded objects simultaneously in the space. The completion is accomplished by computing minimalsurfaces with respect to the non Euclidean metric of the space. The minimality is achieved via diffusion drivenmean curvature ﬂow. Results are presented in a number of cognitive relevant cases."
"A. Goh, R. Vidal",0d29d396e2248b34bf259ef18e9a6393f963eecb,Segmenting Fiber Bundles in Diffusion Tensor Images,European Conference on Computer Vision,2008,15,
"L. Florack, Evgeniya Balmashnova",63919fe691098b3102df173b7dd3ae6b0596de57,Decomposition of High Angular Resolution Diffusion Images into a Sum of Self-Similar Polynomials on the Sphere,,2008,14,"On an extruder for extruding foodstuffs a cutting means consisting of rotatable blades (36, 38, 40, 41) is provided. With the aid of these blades an extruded strand emerging from the nozzle (12) can be cut off or structured at the surface. The cutting blades are driven synchronously."
"Chia-Feng Lu, Po-Shan Wang, Yen-Chun Chou, Hsiao-Chien Li, Bing-Wen Soong, Yu-Te Wu",8c123c8c65dd91e7fae97aa2daf3e83c5fa99546,Segmentation of diffusion-weighted brain images using expectation maximization algorithm initialized by hierarchical clustering,Annual International Conference of the IEEE Engineering in Medicine and Biology Society,2008,10,"Tissue segmentation based on diffusion-weighted images (DWI) provides complementary information of tissue contrast to the structural MRI for facilitating the tissue segmentation. In the previous literatures, DWI-based brain tissue segmentation was carried out using the parametric images, such as fractional anisotropy (FA) and apparent diffusion coefficient (ADC). However, the information of directions of neural fibers was very limited in the parametric images. To fully utilize the directional information, we propose a novel method to perform tissue segmentation directly on the DWI raw image data. Specifically, a hierarchical clustering (HC) technique was first applied on the down-sampled data to initialize the model parameters for each tissue cluster followed by automatic segmentation using the expectation maximization (EM) algorithm. The whole brain DWI raw data of five normal subjects were analyzed. The results demonstrated that HC-EM is effective in multi-tissue classification on DWI raw data."
"V. B. Surya Prasath, Arindama Singh",99a2d02c905982ce8b5e5efef6b7a35771a90551,Edge Detectors Based Anisotropic Diffusion for Enhancement of Digital Images,"2008 Sixth Indian Conference on Computer Vision, Graphics & Image Processing",2008,9,Using the edge detection techniques we propose a new enhancement scheme for noisy digital images. This uses inhomogeneous anisotropic diffusion scheme via the edge indicator provided by well known edge detection methods. Addition of a fidelity term facilitates the proposed scheme to remove the noise while preserving edges. This method is general in the sense that it can be incorporated into any of the nonlinear anisotropic diffusion methods. Numerical results show the promise of this hybrid technique on real and noisy images.
"K. Krajsek, M. Menzel, M. Zwanger, H. Scharr",205a5b1e283e7e78ccb9aeeed6982ca9732ed8fe,Riemannian Anisotropic Diffusion for Tensor Valued Images,European Conference on Computer Vision,2008,6,
"F. Kahraman, C. D. Mendi, M. Gokmen",7399677d953b7dbd81d505bc6d9fb1e600ef3428,Image frame fusion using 3D anisotropic diffusion,International Symposium on Computer and Information Sciences,2008,4,"In this paper, a modified 3D anisotropic diffusion method is proposed to improve the multi-frame image fusion performance. Multi frame image sequence is considered to be composed of aligned and warped images. The goal of this approach is to obtain a restored image from the aligned and warped image sequence, where alignment error and Gaussian noise are reduced. The proposed method consists of medium band stack filter and tree-structured 3D diffusion filter."
"Daniel Gallichan, J. Scholz, A. Bartsch, Timothy Edward John Behrens, M. Robson, K. Miller",ee3b77a6af5b16b84fb0533b760f2ec9b8bfd889,Addressing a Systematic Vibration Artefact in Diffusion-weighted MR Images,,2008,3,"Introduction: The large gradient lobes employed in diffusion-weighted imaging are known to cause vibrations of the patient table. These vibrations can affect the diffusion-weighted signal, as demonstrated by changes in the measured apparent diffusion coefficient in a phantom with and without mechanical contact to the patient table [1]. Here we identify an artefact in-vivo that is caused by the gradient-induced table vibrations which can lead to severe disruption of the quantitative diffusion measures derived in diffusion tensor imaging (DTI). It is not clear to what extent other systems may be affected, but the same artefact has been observed in multiple sites using common protocols. We suggest a method to improve the analysis of data corrupted in this manner, as well as suggesting how to adjust the sequence parameters to avoid the acquisition of corrupted data. The Artefact: Figure 1a shows an example of a diffusion-weighted image affected by the vibration artefact. Imaging was performed on a clinical 3T system using a typical protocol: 2 mm isotropic resolution EPI, 192x192 mm FOV, 65 slices, TE/TR = 94 ms/9300 ms, b = 1000 s/mm in the left-right direction (using the twice-refocused spin-echo (TRSE) to reduce eddy-current related distortions [2]) and 3⁄4 partial Fourier imaging with phase encoding in the anterior-posterior (AP) direction. Typically a large region of the occipital lobe, often close to the mid-line, demonstrates marked signal loss when the x-component (i.e. left-right) of the diffusion-gradient direction is large. We see clear artefact in most subjects scanned using this protocol, although the exact location of the signal-loss is variable. The artefact arises due to the presence of mechanical shear-waves oscillating in the left-right direction which propagate through the brain when the head is in strong mechanical contact with the patient-table. Motion in the diffusion-encoding direction that occurs during the diffusion-encoding gradients will lead to phase offsets. If neighbouring voxels move different amounts this will lead to a phase ramp in the image, which in turn leads to a displacement of the k-space centre. Fig. 1b clearly shows the strong phase ramps present in the occipital region of the affected slice, and the corresponding k-space image (Fig. 1c) demonstrates the defocusing of the signal echo. The use of a 3⁄4 partial Fourier acquisition means that the phase ramp need only be π/2 per voxel in the AP direction before the signal echo is not acquired and the signal drops dramatically. Figure 2 shows how the signal in an area affected by the artefact varies with the xcomponent of the diffusion-gradient direction during 2 averages of a 60-direction acquisition. Also shown for comparison is the signal in an area selected to approximate a pure left-right running white-matter tract (in the splenium). Whereas the signal in the splenium decreases continuously, within the area of the artefact the signal remains constant until the x-component of the diffusion-gradient direction reaches ~0.75, whereupon the signal decreases sharply. The directional dependence of the artefact naturally leads to errors in the diffusion-tensor fitting process, with areas of artefact being falsely interpreted as having a high fractional-anisotropy (FA) corresponding to a tract in the left-right direction. This artefactually high FA can be observed in Fig. 3. The artefact can also hinder clinical diffusion-weighted imaging if the area of suspected pathology lies within the region affected by the artefact. Correcting for the Artefact: Whilst the acquisition of uncorrupted data is preferable, inevitably there are many datasets that were acquired prior to the recognition and characterisation of the artefact. We have found that the reliability of measures such as FA can be vastly improved by including an empirically-derived approximation to the artefact curve shown in Fig. 2 as a co-regressor in the diffusion-tensor fit. The improvement in the tensor fit is demonstrated in Fig. 3, where the large region of erroneous red is almost completely corrected. Avoiding the Artefact: Based on our experimental observations, we have identified several aspects of the protocol that affect the artefact. The system vibrations we observe appear to behave similarly to previous measurements using a laser interferometer [3], with a resonance ~20-25 Hz and a decay constant of ~200 ms. The vibrations do not peak until after the diffusion gradients which cause them, meaning that a single measurement is not affected, but when measurements are repeated (for example, over several slices) the vibrations from the previous diffusion-weighting gradients are still present at the time of the current diffusion weighting. Extending the time between consecutive acquisitions to allow the vibrations to decay reduces the artefact, as can be seen in the bottom row of Fig. 1, where the TR was doubled. Doubling the TR, however, also means doubling the overall acquisition time, which is not acceptable for routine use. The simplest approach to acquire data unaffected by the artefact is to use a full k-space acquisition. The phase ramps in the images will still remain, but will need to be twice as strong to cause signal drop-out. The primary motivation for using partial k-space acquisition is to reduce the TE. To achieve a short TE with full k-space, parallel acceleration (e.g. GRAPPA x2) can be used. This will lead to a slightly reduced SNR, but this is partially compensated by the increase in SNR efficiency due to the shorter TR. Artefact-free images were successfully acquired on our system with identical parameters to the above acquisition, but full k-space, GRAPPA x2, TE = 93 ms and TR = 8200 ms. Removing any subject restraints (padding) that directly contact the side of the head reduces, but does not remove, the artefact. This is expected, as the vibrations causing the problem are in the left-right direction, so tighter mechanical coupling in this direction between the head and the vibrating structure leads to larger effects. Ultimately the artefact may be avoided entirely by consideration of these low-frequency vibrations in the hardware design – an approach which manufacturers are beginning to pursue. Discussion: Vibrations are typically strong on all systems when high b-value diffusion-weighting is performed, so some degree of phase variation across the image should be expected. Whilst this may not in all cases lead to the gross drop-out artefact we observe here, strong phase variations have been shown to lead to errors in partial k-space reconstruction methods [4]. Regions of rapidly changing phase can also affect algorithms that combine data from multiple coils, as they may rely on approximating the high-resolution phase from low resolution data. We are currently also investigating the possibility that the gradient-induced may be utilised as a mechanical driver for MR elastography experiments. [1] A Ogura et al, Jap. J. Rad. Tech. 62 (4) 565-9 (2006); [2] TG Reese et al, MRM 49 (1) 177-82 (2003); [3] J Hiltunen et al, NeuroImage 32 (1) 93-103 (2006); [4] MD Robson and DA Porter, MRI 23 (9) 899-905 (2005)"
"Jian Bai, Xiangchu Feng",ae82ac4b7537018092c1b3ffd48882dbb0b22f4e,Fractional-Order Anisotropic Diffusion for Image Denoising,IEEE Transactions on Image Processing,2007,455,"This paper introduces a new class of fractional-order anisotropic diffusion equations for noise removal. These equations are Euler-Lagrange equations of a cost functional which is an increasing function of the absolute value of the fractional derivative of the image intensity function, so the proposed equations can be seen as generalizations of second-order and fourth-order anisotropic diffusion equations. We use the discrete Fourier transform to implement the numerical algorithm and give an iterative scheme in the frequency domain. It is one important aspect of the algorithm that it considers the input image as a periodic image. To overcome this problem, we use a folded algorithm by extending the image symmetrically about its borders. Finally, we list various numerical results on denoising real images. Experiments show that the proposed fractional-order anisotropic diffusion equations yield good visual effects and better signal-to-noise ratio."
"Hui Zhang, B. Avants, Paul Yushkevich, J. Woo, Sumei Wang, L. McCluskey, L. Elman, E. Melhem, J. Gee",c8bac9a0373963922d00917f53b8da9a87073b07,High-Dimensional Spatial Normalization of Diffusion Tensor Images Improves the Detection of White Matter Differences: An Example Study Using Amyotrophic Lateral Sclerosis,IEEE Transactions on Medical Imaging,2007,229,"Spatial normalization of diffusion tensor images plays a key role in voxel-based analysis of white matter (WM) group differences. Currently, it has been achieved using low-dimensional registration methods in the large majority of clinical studies. This paper aims to motivate the use of high-dimensional normalization approaches by generating evidence of their impact on the findings of such studies. Using an ongoing amyotrophic lateral sclerosis (ALS) study, we evaluated three normalization methods representing the current range of available approaches: low-dimensional normalization using the fractional anisotropy (FA), high-dimensional normalization using the FA, and high-dimensional normalization using full tensor information. Each method was assessed in terms of its ability to detect significant differences between ALS patients and controls. Our findings suggest that inadequate normalization with low-dimensional approaches can result in insufficient removal of shape differences which in turn can confound FA differences in a complex manner, and that utilizing high-dimensional normalization can both significantly minimize the confounding effect of shape differences to FA differences and provide a more complete description of WM differences in terms of both size and tissue architecture differences. We also found that high-dimensional approaches, by leveraging full tensor features instead of tensor-derived indices, can further improve the alignment of WM tracts."
"W. Hecke, A. Leemans, E. D'Agostino, S. D. Backer, E. Vandervliet, P. Parizel, Jan Sijbers",a9338667a5f49218de7f7dfc85c9963f7b5e8dff,Nonrigid Coregistration of Diffusion Tensor Images Using a Viscous Fluid Model and Mutual Information,IEEE Transactions on Medical Imaging,2007,112,"In this paper, a nonrigid coregistration algorithm based on a viscous fluid model is proposed that has been optimized for diffusion tensor images (DTI), in which image correspondence is measured by the mutual information criterion. Several coregistration strategies are introduced and evaluated both on simulated data and on brain intersubject DTI data. Two tensor reorientation methods have been incorporated and quantitatively evaluated. Simulation as well as experimental results show that the proposed viscous fluid model can provide a high coregistration accuracy, although the tensor reorientation was observed to be highly sensitive to the local deformation field. Nevertheless, this coregistration method has demonstrated to significantly improve spatial alignment compared to affine image matching."
"Hui Zhang, Paul Yushkevich, D. Rueckert, J. Gee",8be2a4775784cac2caa8cbfb97a2eadbb7ec100f,Unbiased White Matter Atlas Construction Using Diffusion Tensor Images,International Conference on Medical Image Computing and Computer-Assisted Intervention,2007,77,
"Vijayakumar Chinnadurai, Gharpure Damayanti, R. Pant, C. Sreedhar",6aea6b7d884c64b9201da94a1f981b4305ef15d6,Segmentation and grading of brain tumors on apparent diffusion coefficient images using self-organizing maps,Comput. Medical Imaging Graph.,2007,76,
"G. Hamarneh, J. Hradsky",179f0d36579ad94f57ca87f323e3a79bbb5d063a,Bilateral Filtering of Diffusion Tensor Magnetic Resonance Images,IEEE Transactions on Image Processing,2007,57,"We extend the well-known scalar image bilateral filtering technique to diffusion tensor magnetic resonance images (DTMRI). The scalar version of bilateral image filtering is extended to perform edge-preserving smoothing of DT field data. The bilateral DT filtering is performed in the log-Euclidean framework which guarantees valid output tensors. Smoothing is achieved by weighted averaging of neighboring tensors. Analogous to bilateral filtering of scalar images, the weights are chosen to be inversely proportional to two distance measures: The geometrical Euclidean distance between the spatial locations of tensors and the dissimilarity of tensors. We describe the noniterative DT smoothing equation in closed form and show how interpolation of DT data is treated as a special case of bilateral filtering where only spatial distance is used. We evaluate different DT tensor dissimilarity metrics including the log-Euclidean, the similarity-invariant log-Euclidean, the square root of the J-divergence, and the distance scaled mutual diffusion coefficient. We present qualitative and quantitative smoothing and interpolation results and show their effect on segmentation, for both synthetic DT field data, as well as real cardiac and brain DTMRI data."
"Yi Wang, Liangpei Zhang, Pingxiang Li",fceca8d72d881748e4e4774cf15acfe20d857df4,Local Variance-Controlled Forward-and-Backward Diffusion for Image Enhancement and Noise Reduction,IEEE Transactions on Image Processing,2007,40,"In order to improve signal-to-noise ratio (SNR) and contrast-to-noise ratio, this paper introduces a local variance-controlled forward-and-backward (LVCFAB) diffusion algorithm for edge enhancement and noise reduction. In our algorithm, an alternative FAB diffusion algorithm is proposed. The results for the alternative FAB algorithm show better algorithm behavior than other existing diffusion FAB approaches. Furthermore, two distinct discontinuity measures and the alternative FAB diffusion are incorporated into a LVCFAB diffusion algorithm, where the joint use of the two measures leads to a complementary effect for preserving edge features in digital images. This LVC mechanism adaptively modifies the degree of diffusion at any image location and is dependent on both local gradient and inhomogeneity. Qualitative experiments, based on general digital images and magnetic resonance images, show significant improvements when the LVCFAB diffusion algorithm is used versus the existing anisotropic diffusion and the previous FAB diffusion algorithms for enhancing edge features and improving image contrast. Quantitative analyses, based on peak SNR, confirm the superiority of the proposed LVCFAB diffusion algorithm."
"D. Tschumperlé, R. Deriche",32502fefe26ad0f4a38eb787d2c42189f17026c3,Anisotropic Diffusion Partial Differential Equations for Multichannel Image Regularization: Framework and Applications,,2007,25,
"W. Moon, Min Hee Lee, E. Chung",a54986fbe55721cac1ba8688fa446038cde48e93,Diffusion-Weighted Imaging with Sensitivity Encoding (SENSE) for Detecting Cranial Bone Marrow Metastases: Comparison with T1-Weighted Images,Korean Journal of Radiology,2007,23,"Objective This study was designed to determine whether diffusion-weighted imaging (DWI) with sensitivity encoding (SENSE) could detect bone marrow involvement in patients with cranial bone marrow (CBM) metastases. DWI results obtained were compared with T1-weighted imaging (T1WI) findings. Materials and Methods DWI with sensitivity encoding (SENSE; b value = 1,000) was performed consecutively in 13 patients with CBM metastases diagnosed pathologically and radiologically. CBM lesions were dichotomized according to the involved site, i.e., skull base or calvarium. Two radiologists qualitatively evaluated the relative conspicuousness of CBM lesions and image qualities in B0 and in isotropic DWI and in T1WI. According to region of interest analysis of normal and pathologic marrow for these three sequences, absolute signal difference percentages (SD%) were calculated to quantitatively analyze lesion contrast. Results All 20 lesions in 13 patients with CBM metastases revealed abnormal DWI signals in areas corresponding to T1WI abnormalities. Both skull base and calvarial lesions provided better lesion conspicuousness than T1WI and B0 images. Although the image quality of DWI was less satisfactory than that of T1WI, relatively good image qualities were obtained. Quantitatively, B0 images (SD%, 82.1 ±7.9%) showed better lesion contrast than isotropic DWI (SD%, 71.4 ±13.7%) and T1WI (SD%, 65.7 ±9.3%) images. Conclusion For scan times of less than 30 seconds, DWI with SENSE was able to detect bone marrow involvement, and was superior to T1WI in terms of lesion conspicuity. DWI with SENSE may be helpful for the detection of cranial bone/bone marrow metastases when used in conjunction with conventional MR sequences."
"O. Faugeras, C. Lenglet, T. Papadopoulo, R. Deriche",c80094de50ff3c8c75852e2b06cf0ec077fc81ff,Non Rigid Registration of Diffusion Tensor Images,,2007,18,We propose a novel variational framework for the dense non-rigid registration of Diffusion Tensor Images (DTI). Our approach relies on the differential geometrical properties of the Riemannian manifold of multivariate normal distributions endowed with the metric derived from the Fisher information matrix. The availability of closed form expressions for the geodesics and the Christoffel symbols allows us to define statistical quantities and to perform the parallel transport of tangent vectors in this space. We propose a matching energy that aims to minimize the difference in the local statistical content (means and covariance matrices) of two DT images through a gradient descent procedure. The result of the algorithm is a dense vector field that can be used to wrap the source image into the target image. This article is essentially a mathematical study of the registration problem. Some numerical experiments are provided as a proof of concept.
"Hui Zhang, Paul Yushkevich, D. Alexander, J. Gee",2d848bda67f51009a5bf6e468f3a16a1b2b7f0da,Deformable registration of diffusion tensor MR images with explicit orientation optimization,Medical Image Anal.,2006,417,
"D. Ennis, G. Kindlmann",7dc66004cc01361d0fc17ed3b4e48e35e2e180f3,Orthogonal tensor invariants and the analysis of diffusion tensor magnetic resonance images,Magnetic Resonance in Medicine,2006,271,"This paper outlines the mathematical development and application of two analytically orthogonal tensor invariants sets. Diffusion tensors can be mathematically decomposed into shape and orientation information, determined by the eigenvalues and eigenvectors, respectively. The developments herein orthogonally decompose the tensor shape using a set of three orthogonal invariants that characterize the magnitude of isotropy, the magnitude of anisotropy, and the mode of anisotropy. The mode of anisotropy is useful for resolving whether a region of anisotropy is linear anisotropic, orthotropic, or planar anisotropic. Both tensor trace and fractional anisotropy are members of an orthogonal invariant set, but they do not belong to the same set. It is proven that tensor trace and fractional anisotropy are not mutually orthogonal measures of the diffusive process. The results are applied to the analysis and visualization of diffusion tensor magnetic resonance images of the brain in a healthy volunteer. The theoretical developments provide a method for generating scalar maps of the diffusion tensor data, including novel fractional anisotropy maps that are color encoded for the mode of anisotropy and directionally encoded colormaps of only linearly anisotropic structures, rather than of high fractional anisotropy structures. Magn Reson Med, 2006. © 2005 Wiley‐Liss, Inc."
"S. Price, R. Jena, N. Burnet, P. Hutchinson, A. Dean, A. Pena, J. Pickard, T. Carpenter, J. Gillard",474e285b01cb9412811706dd54351b1599d31580,Improved delineation of glioma margins and regions of infiltration with the use of diffusion tensor imaging: an image-guided biopsy study.,AJNR. American journal of neuroradiology,2006,206,"BACKGROUND AND PURPOSE
The efficacy of radiation therapy, the mainstay of treatment for malignant gliomas, is limited by our inability to accurately determine tumor margins. As a result, despite recent advances, the prognosis remains appalling. Because gliomas preferentially infiltrate along white matter tracks, methods that show white matter disruption should improve this delineation. In this study, results of histologic examination from samples obtained from image-guided brain biopsies were correlated with diffusion tensor images.


METHODS
Twenty patients requiring image-guided biopsies for presumed gliomas were imaged preoperatively. Patients underwent image-guided biopsies with multiple biopsies taken along a single track that went into normal-appearing brain. Regions of interest were determined from the sites of the biopsies, and diffusion tensor imaging findings were compared with glioma histology.


RESULTS
Using diffusion tissue signatures, it was possible to differentiate gross tumor (reduction of the anisotropic component, q > 12% from contralateral region), from tumor infiltration (increase in the isotropic component, p > 10% from contralateral region). This technique has a sensitivity of 98% and specificity of 81%. T2-weighted abnormalities failed to identify the margin in half of all specimens.


CONCLUSION
Diffusion tensor imaging can better delineate the tumor margin in gliomas. Such techniques can improve the delineation of the radiation therapy target volume for gliomas and potentially can direct local therapies for tumor infiltration."
"J. Zhuang, J. Hrabe, A. Kangarlu, Dongrong Xu, R. Bansal, Craig A. Branch, B. Peterson",f3f9c2a2e1dccca4807fc7d4f84208daea8fce93,Correction of eddy‐current distortions in diffusion tensor images using the known directions and strengths of diffusion gradients,Journal of Magnetic Resonance Imaging,2006,105,To correct eddy‐current artifacts in diffusion tensor (DT) images without the need to obtain auxiliary scans for the sole purpose of correction.
"Yan Cao, M. Miller, S. Mori, R. Winslow, L. Younes",dcb971b01a134e9f320cba1cd9ee3b7a6a31f8f2,Diffeomorphic Matching of Diffusion Tensor Images,2006 Conference on Computer Vision and Pattern Recognition Workshop (CVPRW'06),2006,85,"This paper proposes a method to match diffusion tensor magnetic resonance images (DT-MRI) through the large deformation diffeomorphic metric mapping of tensor fields on the image volume, resulting in optimizing for geodesics on the space of diffeomorphisms connecting two diffusion tensor images. A coarse to fine multi-resolution and multikernel- width scheme is detailed, to reduce both ambiguities and computation load. This is illustrated by numerical experiments on DT-MRI brain and images."
"D. Atkinson, S. Counsell, J. Hajnal, P. Batchelor, D. Hill, David J. Larkman",2ee7a9befa0af9531b227dcd821c6120292d79fe,Nonlinear phase correction of navigated multi‐coil diffusion images,Magnetic Resonance in Medicine,2006,57,"Cardiac pulsatility causes a nonrigid motion of the brain. In multi‐shot diffusion imaging this leads to spatially varying phase changes that must be corrected. A conjugate gradient based reconstruction is presented that includes phase changes measured using two‐dimensional navigator echoes, coil sensitivity information, navigator‐determined weightings, and data from multiple coils and averages."
Vincent Arsigny,81df3dac1f7679b5cd5ff45606cd94d3c8886959,Processing Data in Lie Groups : An Algebraic Approach. Application to Non-Linear Registration and Diffusion Tensor MRI. (Traitement de données dans les groupes de Lie : une approche algébrique. Application au recalage non-linéaire et à l'imagerie du tenseur de diffusion),,2006,46,"Recently, the need for rigorous frameworks for the processing of non-linear data has grown considerably in medical imaging. In this thesis, we propose several general frameworks to process various types of non-linear data, which all belong to Lie groups. To this end, we rely on the algebraic properties of these spaces. Thus, we propose a general processing framework for symmetric and positive-definite matrices, named Log-Euclidean, very simple to use and which has excellent theoretical properties. It is particularly well-adapted to the processing of diffusion tensor MRI. We also propose several frameworks, called polyaffine, to parameterize locally rigid or affine transformations, in a way that guarantees their invertibility. Their use is illustrated in the case of the locally rigid registration of histological slices and of the locally affine 3D registration of MRIs of the human brain. This led us to propose two general frameworks for computing statistics in finite-dimensional Lie groups: first the Log-Euclidean one, which generalizes our work on tensors, and second a framework based on the novel notion of bi-invariant mean, whose properties generalize to Lie groups those of the arithmetic mean. Finally, we generalize our Log-Euclidean framework to diffeomorphic geometrical transformations, which opens the way to a general and consistent framework for statistics in computational anatomy."
"HongGen Luo, Limin Zhu, H. Ding",55f758ba14c3cd71a091908cee41bebd6661d05b,Coupled anisotropic diffusion for image selective smoothing,Signal Processing,2006,40,
"X. Tao, James V. Miller",fe18d607e9fe3aae96c74bd5ee3ae6ddcb4cc33f,A Method for Registering Diffusion Weighted Magnetic Resonance Images,International Conference on Medical Image Computing and Computer-Assisted Intervention,2006,22,
"J. Gee, D. Alexander",10a0e60d960521861629359755d5d88434f5c0ff,Diffusion-Tensor Image Registration,Visualization and Processing of Tensor Fields,2006,20,
"D. Lafreniére, R. Doyon, D. Nadeau, É. Artigau, C. Marois, M. Beaulieu",efd9b0b1c484a0aefb60ae42ec1e065008be1d4c,Improving the Speckle Noise Attenuation of Simultaneous Spectral Differential Imaging with a Focal Plane Holographic Diffuser,SPIE Astronomical Telescopes + Instrumentation,2006,17,"Direct exoplanet detection is limited by speckle noise in the point-spread function (PSF) of the central star. This noise can be reduced by subtracting PSF images obtained simultaneously in adjacent narrow spectral bands using a multichannel camera (MCC), but only to a limit imposed by differential optical aberrations in the MCC. To alleviate this problem, we suggest the introduction of a holographic diffuser at the focal plane of the MCC to convert the PSF image into an incoherent illumination scene that is then re-imaged with the MCC. The re-imaging is equivalent to a convolution of the scene with the PSF of each spectral channel of the camera. Optical aberrations in the MCC affect only the convolution kernel of each channel and not the PSF globally, resulting in better-correlated images. We report laboratory measurements with a dual-channel prototype (1.575 and 1.625 μm) to validate this approach. A speckle noise suppression factor of 12-14 was achieved, an improvement by a factor ~5 over that obtained without the holographic diffuser. Simulations of exoplanet populations for three representative target samples show that the increase in speckle noise attenuation achieved in the laboratory would roughly double the number of planets that could be detected with current adaptive optics systems on 8 m telescopes."
"A. Goh, R. Vidal",08970cff411dc6af3af23bd33b60d238a1d787a5,Algebraic Methods for Direct and Feature Based Registration of Diffusion Tensor Images,European Conference on Computer Vision,2006,15,
"M. Cheikh, H. Nghiêm, D. Ettori, E. Tinet, S. Avrillier, J. Tualle",d6bd46e972792f3d911c67ab4b36b8c9c69bbb6e,Time-resolved diffusing wave spectroscopy applied to dynamic heterogeneity imaging.,Optics Letters,2006,11,"We report what is to our knowledge the first observation of a time-resolved diffusing wave spectroscopy (DWS) signal recorded by transillumination through a thick turbid medium: the DWS signal is measured for a fixed photon transit time, which opens the possibility of improving the spatial resolution. This technique could find biomedical applications, especially in mammography."
"J. Frandsen, A. Hobolth, L. Ostergaard, P. Vestergaard-Poulsen, E. B. Vedel Jensen",295318b36422387142582a198179f1f25bdd9f2a,Bayesian regularization of diffusion tensor images.,Biostatistics,2006,9,"Diffusion tensor imaging (DTI) is a powerful tool in the study of the course of nerve fiber bundles in the human brain. Using DTI, the local fiber orientation in each image voxel can be described by a diffusion tensor which is constructed from local measurements of diffusion coefficients along several directions. The measured diffusion coefficients and thereby the diffusion tensors are subject to noise, leading to possibly flawed representations of the 3-dimensional (3D) fiber bundles. In this paper, we develop a Bayesian procedure for regularizing the diffusion tensor field, fully utilizing the available 3D information of fiber orientation. The use of the procedure is exemplified on synthetic and in vivo data."
"O. Clatz, Maxime Sermesant, P. Bondiau, H. Delingette, S. Warfield, G. Malandain, N. Ayache",89bd45ae38a4742659fb2572cb2844c5ee8ca7f7,Realistic simulation of the 3-D growth of brain tumors in MR images coupling diffusion with biomechanical deformation,IEEE Transactions on Medical Imaging,2005,349,"We propose a new model to simulate the three-dimensional (3-D) growth of glioblastomas multiforma (GBMs), the most aggressive glial tumors. The GBM speed of growth depends on the invaded tissue: faster in white than in gray matter, it is stopped by the dura or the ventricles. These different structures are introduced into the model using an atlas matching technique. The atlas includes both the segmentations of anatomical structures and diffusion information in white matter fibers. We use the finite element method (FEM) to simulate the invasion of the GBM in the brain parenchyma and its mechanical interaction with the invaded structures (mass effect). Depending on the considered tissue, the former effect is modeled with a reaction-diffusion or a Gompertz equation, while the latter is based on a linear elastic brain constitutive equation. In addition, we propose a new coupling equation taking into account the mechanical influence of the tumor cells on the invaded tissues. The tumor growth simulation is assessed by comparing the in-silico GBM growth with the real growth observed on two magnetic resonance images (MRIs) of a patient acquired with 6 mo difference. Results show the feasibility of this new conceptual approach and justifies its further evaluation."
"Z. Ding, J. Gore, A. Anderson",f7b9fdaa703ea80c74a657aa6ad5346449fd9444,Reduction of noise in diffusion tensor images using anisotropic smoothing,Magnetic Resonance in Medicine,2005,106,"To improve the accuracy of tissue structural and architectural characterization with diffusion tensor imaging, a novel smoothing technique is developed for reducing noise in diffusion tensor images. The technique extends the traditional anisotropic diffusion filtering method by allowing isotropic smoothing within homogeneous regions and anisotropic smoothing along structure boundaries. This is particularly useful for smoothing diffusion tensor images in which direction information contained in the tensor needs to be restored following noise corruption and preserved around tissue boundaries. The effectiveness of this technique is quantitatively studied with experiments on simulated and human in vivo diffusion tensor data. Illustrative results demonstrate that the anisotropic smoothing technique developed can significantly reduce the impact of noise on the direction as well as anisotropy measures of the diffusion tensor images. Magn Reson Med 53:485–490, 2005. © 2005 Wiley‐Liss, Inc."
"Hui Zhang, Paul Yushkevich, J. Gee",db9828ee0ca8a167965a99c1150dc3caf1aec7e2,Deformable Registration of Diffusion Tensor MR Images with Explicit Orientation Optimization,International Conference on Medical Image Computing and Computer-Assisted Intervention,2005,93,
"S. Ardekani, U. Sinha",97bec66079fa746896cca6c1c95dfd37db209abd,Geometric distortion correction of high‐resolution 3 T diffusion tensor brain images,Magnetic Resonance in Medicine,2005,87,"Diffusion‐weighted images based on echo planar sequences suffer from distortions due to field inhomogeneities from susceptibility differences as well as from eddy currents arising from diffusion gradients. In this paper, a novel approach using nonlinear warping based on optic flow to correct distortions of baseline and diffusion weighted echo planar images (EPI) acquired at 3 T is presented. The distortion correction was estimated by warping the echo planar images to the anatomically correct T2‐weighted fast spin echo images (T2‐FSE). A global histogram intensity matching of the T2‐FSE precedes the base line EPI image distortion correction. A local intensity‐matching algorithm was used to transform labeled T2‐FSE regions to match intensities of diffusion‐weighted EPI images prior to distortion correction of these images. Evaluation was performed using three methods: (i) visual comparison of overlaid contours, (ii) a global mutual information index, and (iii) a local distance measure between homologous points. Visual assessment and the global index demonstrated a decrease in geometrical distortion and the distance measure showed that distortions are reduced to a subvoxel level. In conclusion, the warping algorithm is effective in reducing geometric distortions, enabling generation of anatomically correct diffusion tensor images at 3 T. Magn Reson Med, 2005. © 2005 Wiley‐Liss, Inc."
"R. Nunes, P. Jezzard, S. Clare",0ee632d6d5bd888a25954d88f175a3c53289e851,Investigations on the efficiency of cardiac-gated methods for the acquisition of diffusion-weighted images.,"Journal of magnetic resonance (San Diego, Calif. 1997 : Print)",2005,82,
"A. Leemans, Jan Sijbers, S. D. Backer, E. Vandervliet, P. Parizel",abf2806e64e5c3c9359490f951e5d631c0fba9ab,Affine Coregistration of Diffusion Tensor Magnetic Resonance Images Using Mutual Information,Advanced Concepts for Intelligent Vision Systems Conference,2005,51,
"Abdelmounim Belahmidi, A. Chambolle",9fc5b7b75fce05d349ad7b34801da9177e45100e,Time-delay regularization of anisotropic diffusion and image processing,,2005,31,"We study a time-delay regularization of the anisotropic diffusion model for image denoising of Perona and Malik (IEEE Trans. Pattern Anal. Mach. Intell 12 (1990) 629-639), which has been proposed by Nitzberg and Shiota (IEEE Trans. Pattern Anal. Mach. Intell 14 (1998) 826-835). In the two-dimensional case, we show the convergence of a numerical approximation and the existence of a weak solution. Finally, we show some experiments on images."
"Yangming Ou, C. C. Wyatt",6e49b32117d1c2502dbbfe24d254893abb0010ec,Visualization of Diffusion Tensor Imaging data and Image Correction of Distortion Induced by Patient Motion and Magnetic Field Eddy Current,,2005,8,"PCT No. PCT/DE97/00521 Sec. 371 Date Sep. 17, 1998 Sec. 102(e) Date Sep. 17, 1998 PCT Filed Mar. 14, 1997 PCT Pub. No. WO97/35794 PCT Pub. Date Oct. 2, 1997A device for conveying sheets in a sheet-processing machine uses a processing cylinder having a circumferential speed. Conveyor belts cooperate with the cylinder for transporting sheets with the belts arranged between the processing cylinder and a chain conveyor with a gripper system. A ratio between the transportation speed of the processing cylinder can be changed by use of a drive of the conveyor belts in order to vary the distance between successive sheets."
"Guy Gilboa, N. Sochen, Y. Zeevi",9415bd105bce707969ba4e02dfe4559f48f944d9,Image enhancement and denoising by complex diffusion processes,IEEE Transactions on Pattern Analysis and Machine Intelligence,2004,476,"The linear and nonlinear scale spaces, generated by the inherently real-valued diffusion equation, are generalized to complex diffusion processes, by incorporating the free Schrodinger equation. A fundamental solution for the linear case of the complex diffusion equation is developed. Analysis of its behavior shows that the generalized diffusion process combines properties of both forward and inverse diffusion. We prove that the imaginary part is a smoothed second derivative, scaled by time, when the complex diffusion coefficient approaches the real axis. Based on this observation, we develop two examples of nonlinear complex processes, useful in image processing: a regularized shock filter for image enhancement and a ramp preserving denoising process."
"N. Bodammer, J. Kaufmann, M. Kanowski, C. Tempelmann",27bd6d6e24ca6ce0ba3546c2ece842d701734ea7,Eddy current correction in diffusion‐weighted imaging using pairs of images acquired with opposite diffusion gradient polarity,Magnetic Resonance in Medicine,2004,149,"In echo‐planar‐based diffusion‐weighted imaging (DWI) and diffusion tensor imaging (DTI), the evaluation of diffusion parameters such as apparent diffusion coefficients and anisotropy indices is affected by image distortions that arise from residual eddy currents produced by the diffusion‐sensitizing gradients. Correction methods that coregister diffusion‐weighted and non‐diffusion‐weighted images suffer from the different contrast properties inherent in these image types. Here, a postprocessing correction scheme is introduced that makes use of the inverse characteristics of distortions generated by gradients with reversed polarity. In this approach, only diffusion‐weighted images with identical contrast are included for correction. That is, non‐diffusion‐weighted images are not needed as a reference for registration. Furthermore, the acquisition of an additional dataset with moderate diffusion‐weighting as suggested by Haselgrove and Moore (Magn Reson Med 1996;36:960–964) is not required. With phantom data it is shown that the theoretically expected symmetry of distortions is preserved in the images to a very high degree, demonstrating the practicality of the new method. Results from human brain images are also presented. Magn Reson Med 51:188–193, 2004. © 2003 Wiley‐Liss, Inc."
"O. Coulon, D. Alexander, S. Arridge",4195930360006cf1b820b370ac5e1e288e0d9bcd,Diffusion tensor magnetic resonance image regularization,Medical Image Anal.,2004,115,
"Hui Zhang, Paul Yushkevich, J. Gee",f47fcf08c04b9e698ebed5b61a230e9e052eeb4f,Registration of diffusion tensor images,"Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2004. CVPR 2004.",2004,41,This paper presents a novel affine registration algorithm for diffusion tensor images. The proposed metric derived from the standpoint of diffusion profiles not only has concrete physical underpinning but also can be extended for comparing higher-order diffusion models. The non-translational part of the affine transformation is parametrized in the spirit of the Polar Decomposition Theorem. The registration objective function and its derivatives are derived analytically by combining this parametrization scheme with finite strain tensor reorientation. The affine algorithm is embeded in a multi-resolution piecewise affine framework for non-rigid registration.
"Stacey Levine, J. Stanich, Yunmei Chen",406c0c4a2fc69f4dd24b69e17c22f8b71d909ff8,Image Restoration via Nonstandard Diffusion,,2004,38,"We present a functional of nonstandard growth for which the corresponding minimization problem provides a model for image denoising, enhancement, and restoration. The diffusion resulting from the proposed model is a combination of isotropic and anisotropic diffusion. Isotropic diffusion is used at locations with low gradient and total variation based diffusion is used along likely edges. At all other locations, the type of anisotropy varies according to the local image information. Experimental results illustrate the effectiveness of the model in removing noise and retaining sharp edges while avoiding the ’staircasing effect’. Existence and uniqueness of the proposed model are also established."
S. Fu,b0978d17bfcbee8def4b8024a200d52de82d8469,Data Hiding in Halftone Images by Stochastic Error Diffusion,,2004,37,"In this paper, we propose a novel method called DHSED to hide binary visual patterns in two error diffused halftone images. While one halftone image is only a regular error diffused image, stochastic error diffusion is applied to the other image to generate special stochastic characteristics with respect to the first image such that the visual pattern would appear when the two halftone images are overlaid Simulation results show that the two halftone images have good visual quality, and the hidden pattern appears with “normal ’I and “lower-than-normal” intensity when the two halftone images are overlaid. 1.1 ntroduction Image data hiding is the hiding or embedding of invisible data in an image without affecting its perceptual quality such that the hidden data can be extracted with some procedure. The study of data hiding techniques is commonly called steganography [2]. Major applications of data hiding include the embedding of secret messages and data. In particular, the embedded data can be the metadata in MPEG7 applications. In recent years, two important subclasses of data hiding methods are fragile watermarks and robust watermarks. Fragile watermarks [l] are designed to be broken easily by common image processing operations. The broken watermark serves as an indication of alteration of the original image and is useful for authentication. Major applications include tampering detection of images placed on the World Wide Web and authentication of images received from questionable sources. Robust watermarks [ l ] are required to remain in the watermarked image even after it has been attacked by attackers or processed by common image processing operations such as filtering, requantization, scaling, cropping, etc. Major applications include copyright protection, distribution and copy control, etc. In this paper, we are concem about datahiding for halftone images. Halftone images contain only 2 tones and are generated by a procedure called halftoning from multi-tone images. Although there are only 2 tones, halftone images look like the original multi-tone images when viewed from a distance. Halftone images are widely used in the printing of books, magazines, newspapers and in computer printers. It is often desirable to hide visual pattems within the printed halftone images such that the hidden pattems can be viewed when some appropriate image is overlaid. Some visual pattern examples include short messages with large font size, logos, graphics or clip arts which can be used for authentication, and conveying secret messages or product related information. However, there are still some existing techniques for halftone image data hiding. They can be divided into two classes. One class of techniques embed invisible digital data into halftone images such that the data can be read by scanning the halftone images and applying some extraction algorithms on the scanned image. Some used two different dithering matrices for the ordered dithering halftone generation [5] such that the different statistical properties due to the two dithering matrices can be detected in the future. Some embedded data in the angular orientation of circularly asymmetric halftone dot pattems that were written into the halftone cells of digital halftone images [6]. Some hid data at pseudo-random locations in ordered dithered and error difised images by self toggling or pair toggling [7, 81 of the halftone values. Some hid data in error diffused images using error diffusion to mitigate the distortion due to the data hiding, resulting in good visual quality [7, 91. In these techniques, although the hidden data can be images also, the algorithms do not provide for viewing the hidden images directly on the halftone images. A second class of halftone image watermarking techniques embed hidden visual pattems into two or more halftone images such that when the two images are overlaid, the hidden image can be viewed directly on the halftone images. The hidden data must be visual pattems and they are meant to be visually inspected on the halftone images. Some used stochastic screen pattems [ 101 and conjugate halftone screens [l 11 to embed the hidden pattems in ordered dithered halftone images. Due to the conjugate properties, when the two ordered dithered images are overlapped, the hidden visual pattems appeared as dark pattems on the halftone image. However, we are 0-7803-7041 -4/01/$10.00 02001 IEEE 1965 not aware of any existing methods for error diffused images. In section 2, we propose a novel algorithm called Data Hiding by Stochastic Error Diffusion (DHSED) to embed hidden visual patterns in two or more mor diffused halftone images such that the hidden patterns can be visually inspected when the images are overlaid. In Section 3, simulation results are shown. 2. Data Hiding by Stochastic Error Diffusion (DHSED) In this section, we propose a novel algorithm called Data Hiding by Stochastic Error Diffusion (DHSED) to hide invisible watermarking data or patterns in two related error diffused halftone images such that the hidden patterns can be visually detected when the images are overlaid. DHSED uses two M x N halftone images, Yo and Y, , to hide some binary image H which can be visually detected by overlaying Yo and Y, . Let X be the original M x N multi-tone image from which Yo and Y, are obtained. We will use x ( i , j ) and y i ( i , j ) to represent the pixels at location ( i , j ) of X and Yi respectively. In ‘general, all quantities associated with Yi would have a subscript i. The hidden binary pattern H i s assumed to have the same size M x N as yo and y, . In the case that the desirable hidden patterns have size smaller than M x N , they can be enlarged and padded to M X N. The black pixels in H can carry meaningful foreground patterns such as text, logo, graphics or clip arts while the white pixels can carry the background. Neither the foreground nor background patterns should contain very fine features because DHSED tends not to be effective in retaining fine features. The first image Yo is generated by regular error diffusion with no hidden visual patterns. In other words, at each pixel location ( i , j ) , a value fo(i, j ) related to the current multi-tone pixel value x ( i , j ) is compared with a threshold T (T=128). And yo (i, j ) will be 0 if f o (i, j ) < T and 255 if fo (i, j ) 2 T . The error eo (i, j ) is fed forward or difhsed to the future pixels by a causal kernel. Note that eo (i, j ) is not the difference of x ( i , j ) and y o ( i , j ) but the difference of fo (i, j ) and yo (i, j ) . Suppose the causal kernel is the Jarvis kernel in Fig. 1. The fo (i, j ) is the sum of the current pixel value x ( i , j ) and the feed-forward error u0 (i, j ) as follows. (1) The second image Y, is generated by applymg Stochastic Error Diffusion (SED) to X with respect to Yo to hide H. In SED, the hidden binary image H is used to turn on or off the stochastic properties on a pixel-by-pixel basis. Let H , be the collection of the locations of all the black pixels in H. Similarly, let H, be the collection of all the white pixel locations in H. For ( i , j ) ~ Hw , the pixel y, ( i , j ) in Y, is forced to be identical to the colocated pixel yo (i, j ) in Yo . In other words, yI ( i , j ) =yo( i , j ) for (i, j ) ~ H, . For H, , error diffusion is applied with some special boundary condtions using the same error diffusion kernel as in Yo such that the texture and the look-and-feel of the regions in Y, are very similar to, if not the same as, the corresponding regions in Yo . The purpose of the special boundary conditions is to create a dlfkrence in the “phase” of error diffusion texture in Y, relative to that in Yo such that the collocated pixels in the Yo and Y, can be considered as statistically independent. Firstly, morphological dilation with some structuring element S is applied to H B to give C = H B @ S . If S is a ( 2 L + l ) x ( 2 L + l ) square matrix with current pixel being in the center, C is basically H , expanded outward both horizontally and vertically by L pixel. An example is shown in Fig. 2 in which H B is a single connected region. Define region D = C n H B C = C n Hw , which is the dark region outside H B in Fig. 1. In SED, the boundary condition is that the error e, ( i , j ) is assumed to be zero outside C, i.e. e, ( i , j )=O for ( i , j ) p C . For ( i , j ) ~ D , Eqns. 1 and 2 are applied to compute ul (i, j ) and fi (i, j ) using the neighboring el . Eqns. 3 and 4 are not applied. Instead of Eqn. 3, we set y , (i, j ) = y o (i, j ) because D c H , . Instead of Eqn."
"G. Rohde, S. Pajevic, C. Pierpaoli",45a2e62d9bc763a060da05626bb45f5fd3c7a932,Multi-channel registration of diffusion tensor images using directional information,IEEE International Symposium on Biomedical Imaging,2004,27,"The problem of registering diffusion tensor (DT) images is considered. We describe a novel intensity based registration method capable of performing affine and nonlinear registration of multi-channel images such as DT images. We use this method to register 3 dimensional DT images of the human brain based on several channel configurations derived from the DT model. Specifically, we compare the use of channel configurations that include rotationally invariant scalar quantities derived from the DT model against channel configurations that include directional information, such as the elements of the diffusion tensor. Experiments performed with real and simulated data show that the use of the directional information present in the diffusion tensor elements can, in some instances, significantly improve the accuracy of the registration results when compared to methods that use rotationally invariant scalar information."
"Hui Zhang, Paul Yushkevich, J. Gee",8dfea52df9af2fdfa4343fac5baa7bbc03f3a2ea,Towards diffusion profile image registration,IEEE International Symposium on Biomedical Imaging,2004,7,"This paper presents a novel method for diffusion MRI registration that treats the diffusion profile as an arbitrary positive-valued function of spatial direction and treats Cartesian diffusion tensors as a special case. A metric based on elementary notions of signal analysis is presented and in the case of diffusion tensors, a closed form expression of the metric is derived in terms of tensor components. The registration method applies piece-wise local affine registration in a multi-resolution framework. Affine registration is defined in terms of an objective function that allows derivatives to be computed analytically. Experimental results demonstrate the robustness of the method for non-linear registration."
J. Bisquert,013a384b03eba650c09bb9fb66771d183cc95dd0,Fractional diffusion in the multiple-trapping regime and revision of the equivalence with the continuous-time random walk.,Physical Review Letters,2003,91,"We investigate the macroscopic diffusion of carriers in the multiple-trapping (MT) regime, in relation with electron transport in nanoscaled heterogeneous systems, and we describe the differences, as well as the similarities, between MT and the continuous-time random walk (CTRW). Diffusion of free carriers in MT can be expressed as a generalized continuity equation based on fractional time derivatives, while the CTRW model for diffusive transport generalizes the constitutive equation for the carrier flux."
"Scott N. Hwang, C. Chin, F. Wehrli, D. Hackney",6aaefaa73b18b8e1d9b544a72eee5875ab37aee2,An image‐based finite difference model for simulating restricted diffusion,Magnetic Resonance in Medicine,2003,85,"Water diffusion in tissues is generally restricted and often anisotropic. Neural tissue is of particular interest, since it is well known that injury alters diffusion in a characteristic manner. Both Monte Carlo simulations and approximate analytical models have previously been reported in attempts to predict water diffusion behavior in the central nervous system. These methods have relied on axonal models, which assume simple geometries (e.g., ellipsoids, cylinders, and square prisms) and ignore the thickness of the myelin sheath. The current work describes a method for generating models using synthetic images. The computations are based on a 3D finite difference (FD) approximation of the diffusion equation. The method was validated with known analytic solutions for diffusion in a cylindrical pore and in a hexagonal array of cylinders. Therefore, it is envisioned that, by exploiting histologic images of neuronal tissues as input model, current method allows investigating the water diffusion behavior inside biological tissues and potentially assessing the status of neural injury and regeneration. Magn Reson Med 50:373–382, 2003. © 2003 Wiley‐Liss, Inc."
"H. Scharr, Michael J. Black, H. Haussecker",2549833a4324bde21add895f9d9ebbcc76f8e160,Image statistics and anisotropic diffusion,Proceedings Ninth IEEE International Conference on Computer Vision,2003,73,"Many sensing techniques and image processing applications are characterized by noisy, or corrupted, image data. Anisotropic diffusion is a popular, and theoretically well understood, technique for denoising such images. Diffusion approaches however require the selection of an ""edge stopping"" function, the definition of which is typically ad hoc. We exploit and extend recent work on the statistics of natural images to define principled edge stopping functions for different types of imagery. We consider a variety of anisotropic diffusion schemes and note that they compute spatial derivatives at fixed scales from which we estimate the appropriate algorithm-specific image statistics. Going beyond traditional work on image statistics, we also model the statistics of the eigenvalues of the local structure tensor. Novel edge-stopping functions are derived from these image statistics giving a principled way of formulating anisotropic diffusion problems in which all edge-stopping parameters are learned from training data."
"M. Fu, O. Au",b88812bc1b1bb6c45fd18078baaccf61a98af96f,Steganography in halftone images: conjugate error diffusion,Signal Processing,2003,46,
"S. Pei, Jing-Ming Guo",b5ce57d7febcda1622bd7c35ebbafdc0748f699e,Data hiding in halftone images with noise-balanced error diffusion,IEEE Signal Processing Letters,2003,34,"In this letter, we propose a low-complexity algorithm for embedding watermarks into two or more error-diffused images. The first one is only a regular error-diffused image, and the others are achieved by applying the proposed noise-balanced error diffusion technique (NBEDF) to the original gray-level image. The visual decoding pattern can be perceived when these two or more similar error-diffused images are overlaid each other. Furthermore, with the proposed modified version of NBEDF, the two halftone images can be made from two totally different gray-tone images and still provide a clear and sharp visual decoding pattern."
"K. Curran, D. Alexander",c9ebee81853dc9b085b9f822821accf373ad180e,Diffusion Tensor Orientation Matching for Image Registration,SPIE Medical Imaging,2003,7,"We present a new method to perform registration of DT-MRI (Diffusion Tensor Magnetic Resonance Imaging) data. The goal of image registration is to determine the spatial alignment between multiple images of the same or different subjects, acquired intra or inter-modality. Registration of DT-MRI is more complex than for scalar data because it contains additional directional information. The exploitation of DT-MR data for registration should improve the accuracy of image matching for scalar data because the information in DT-MRI is complementary to that contained in standard MR images and thus provides additional cues for matching, which can be used both to test registration quality and improve it. Moreover, developing techniques for spatial normalisation of DT-MR images allows for cross-population studies to be performed using the whole tensor. The novelty of the proposed approach is that it uses the tensor orientation to calculate the registration transformation. We have quantitatively shown that this new algorithm reconstructs some synthetic transformations more closely than current techniques. However, further analysis of our results is necessary to quantify the advantage of our methods more clearly."
"Guy Gilboa, N. Sochen, Y. Zeevi",694a56489a44920151a70b48087d00b49a055260,Forward-and-backward diffusion processes for adaptive image enhancement and denoising,IEEE Transactions on Image Processing,2002,385,"Signal and image enhancement is considered in the context of a new type of diffusion process that simultaneously enhances, sharpens, and denoises images. The nonlinear diffusion coefficient is locally adjusted according to image features such as edges, textures, and moments. As such, it can switch the diffusion process from a forward to a backward (inverse) mode according to a given set of criteria. This results in a forward-and-backward (FAB) adaptive diffusion process that enhances features while locally denoising smoother segments of the signal or image. The proposed method, using the FAB process, is applied in a super-resolution scheme. The FAB method is further generalized for color processing via the Beltrami flow, by adaptively modifying the structure tensor that controls the nonlinear diffusion process. The proposed structure tensor is neither positive definite nor negative, and switches between these states according to image features. This results in a forward-and-backward diffusion flow where different regions of the image are either forward or backward diffused according to the local geometry within a neighborhood."
"J. Weickert, T. Brox",d2c1fac53480ddcda2eac78818fa4f5976ee8076,Diffusion and regularization of vector- and matrix-valued images,,2002,182,
"C. Chin, F. Wehrli, Scott N. Hwang, Masaya Takahashi, D. Hackney",ef05bb2473ad1d91d7abeff72192ca98df9a53b6,Biexponential diffusion attenuation in the rat spinal cord: Computer simulations based on anatomic images of axonal architecture,Magnetic Resonance in Medicine,2002,102,"Water diffusion in neurological tissues is known to possess multicomponent diffusion behavior. The fractions of fast and slow apparent diffusion components have often been attributed to the volume fractions of extracellular space (ECS) and intracellular space (ICS) although diffusion fractions are at variance with the tissue compartment volume ratios. In this article this puzzle was examined with a finite difference diffusion simulation model on the basis of optical images from sectioned rat spinal cord. Here the results show that assignment of fractions obtained from biexponential fits of fast and slow diffusion attenuation to ECS and ICS volume ratios is not correct. Rather, the observed multicomponent diffusion behavior is caused by motional restriction and limited intercompartmental water exchange in that at long diffusion times diffusion attenuation is shown to become monoexponential. Although the measured apparent diffusion fractions also depend on T2 relaxation time of water protons in the various compartments, the sensitivity to T2 is small and thus T2 differences are unlikely to explain the mismatch between apparent diffusion fractions and cellular volume fractions. Magn Reson Med 47:455–460, 2002. © 2002 Wiley‐Liss, Inc."
"K. Curran, D. Alexander",7b2d9fc561f659ad84fd2e6057249f3657f3f576,Orientation matching for registration of diffusion tensor images,,2002,7,
"D. Alexander, C. Pierpaoli, P. Basser, J. Gee",a88c3829ecd4040dd89bc685ac7e594920c8c1e5,Spatial transformations of diffusion tensor magnetic resonance images,IEEE Transactions on Medical Imaging,2001,644,"The authors address the problem of applying spatial transformations (or ""image warps"") to diffusion tensor magnetic resonance images. The orientational information that these images contain must be handled appropriately when they are transformed spatially during image registration. The authors present solutions for global transformations of three-dimensional images up to 12-parameter affine complexity and indicate how their methods can be extended for higher order transformations. Several approaches are presented and tested using synthetic data. One method, the preservation of principal direction algorithm, which takes into account shearing, stretching and rigid rotation, is shown to be the most effective. Additional registration experiments are performed on human brain data obtained from a single subject, whose head was imaged in three different orientations within the scanner. All of the authors' methods improve the consistency between registered and target images over naive warping algorithms."
"Bei Tang, G. Sapiro, V. Caselles",836973ca8c06e9cab22d3ab77c95ef77fea758cd,Color image enhancement via chromaticity diffusion,IEEE Transactions on Image Processing,2001,224,"A novel approach for color image denoising is proposed in this paper. The algorithm is based on separating the color data into chromaticity and brightness, and then processing each one of these components with partial differential equations or diffusion flows. In the proposed algorithm, each color pixel is considered as an n-dimensional vector. The vectors' direction, a unit vector, gives the chromaticity, while the magnitude represents the pixel brightness. The chromaticity is processed with a system of coupled diffusion equations adapted from the theory of harmonic maps in liquid crystals. This theory deals with the regularization of vectorial data, while satisfying the intrinsic unit norm constraint of directional data such as chromaticity. Both isotropic and anisotropic diffusion flows are presented for this n-dimensional chromaticity diffusion flow. The brightness is processed by a scalar median filter or any of the popular and well established anisotropic diffusion flows for scalar image enhancement. We present the underlying theory, a number of examples, and briefly compare with the current literature."
"C. Filippi, A. Uluğ, E. Ryan, S. Ferrando, W. V. van Gorp",0e4b81c19c814e7e32d55bf126cd89600d18e0aa,Diffusion tensor imaging of patients with HIV and normal-appearing white matter on MR images of the brain.,AJNR. American journal of neuroradiology,2001,191,"BACKGROUND AND PURPOSE
HIV enters the CNS early in the course of infection and produces neuropsychiatric impairment throughout the course of illness, which preferentially affects the subcortical white matter. The development of a neuroimaging marker of HIV may allow for the earliest detection of cognitive impairment. The purpose of this study was to determine whether MR diffusion tensor imaging can detect white matter abnormalities in patients who have tested positive for HIV.


METHODS
Ten patients with HIV (eight men and two women; mean age, 42 years) underwent MR imaging of the brain with MR diffusion tensor imaging, which included routine fluid-attenuated inversion recovery and fast spin-echo T2-weighted imaging. Diffusion constants and anisotropy indices were calculated from diffusion tensor maps. Peripheral viral load, Centers for Disease Control staging, and cluster of differentiation 4 levels were determined.


RESULTS
All patients had normal results of MR imaging of the brain, except for mild atrophy. Four of 10 patients had undetectable viral loads. These patients were receiving highly active antiretroviral therapy. The diffusion constant and anisotropy were normal. Four of 10 patients had viral loads between 10,000 and 200,000. Diffusion anisotropy in the splenium and genu was significantly decreased (P < .02). The diffusion constant of the subcortical white matter was elevated in the frontal and parietooccipital lobes (11%). Two of 10 patients had viral loads >400,000. Anisotropy of the splenium was half normal (P < .0004) and of the genu was decreased 25% (P < .002). The average diffusion constant was diffusely elevated in the subcortical white matter.


CONCLUSION
Calculating the diffusion constant and anisotropy in the subcortical white matter and corpus callosum in patients with HIV detected abnormalities despite normal-appearing white matter on MR images and nonfocal neurologic examinations. Patients with the highest diffusion constant elevations and largest anisotropy decreases had the most advanced HIV disease. Patients with the lowest viral load levels, who had normal anisotropy and diffusion constants, were receiving highly active antiretroviral therapy."
"M. Bergui, J. Zhong, G. Bradac, S. Sales",c336a5cc4542e175d9b2ddc86543dbe7498fccb5,Diffusion-weighted images of intracranial cyst-like lesions,Neuroradiology,2001,87,
"C. Hoopes, R. Walterbos, G. Bothun",b37ffa045fc02e305e7760661ac930fe7e63b142,Far-Ultraviolet and Hα Imaging of Nearby Spiral Galaxies: The OB Stellar Population in the Diffuse Ionized Gas,,2001,74,"We have compared Hα and far-ultraviolet (FUV) images of 10 nearby spirals, with the goal of understanding the contribution of field OB stars to the ionization of the diffuse ionized gas (DIG) in spiral galaxies. The FUV images were obtained by the Ultraviolet Imaging Telescope (UIT), and the Hα images were obtained using various ground-based telescopes. In all of the galaxies, the FHα/FUIT flux ratio is lower in the DIG than in the H II regions. This is likely an indication that the mean spectral type for OB stars in the field is later than that in H II regions. Comparison of the NLyc/LUIT ratio with models of evolving stellar populations shows that the stellar population in the DIG is consistent with either an older single-burst population or a steady state model with constant star formation and an initial mass function (IMF) slope steeper than α = 2.35. The steady state model is probably a more realistic representation of the stellar population outside of H II regions. The steep IMF slope simulates the steep present-day mass function slope expected for field OB stars and does not necessarily indicate that the IMF slope is actually steeper than α = 2.35. We compared the FHα/FUIT ratio in the DIG of these galaxies with that in M33, in which the field OB stellar population has previously been investigated using Hubble Space Telescope images. If the mean spectral types of stars in H II regions and in the DIG are the same as in M33 and the difference in extinction between DIG and H II regions is constant among galaxies, then the analysis suggests that field stars are important sources of ionization in most galaxies and may be the dominant source in some galaxies. The FHα/FUIT ratio is correlated with Hα surface brightness in both DIG and H II regions, although there is a large scatter in faint H II regions, which may be due to undersampling the IMF in regions with a low total mass of stars formed. The FHα/FUIT ratio is often highest in the centers of galaxies and in the spiral arms, which is also where the DIG is brightest. This can be explained if the extinction is greater in these regions or if the fraction of DIG ionized by leakage is lower in the interarm regions."
"M. Fu, O. Au",53b4cce921b50dfff5d9144fceb538a96f4cc3a0,Data hiding in halftone images by stochastic error diffusion,"2001 IEEE International Conference on Acoustics, Speech, and Signal Processing. Proceedings (Cat. No.01CH37221)",2001,58,"We propose a novel method called DHSED (data hiding stochastic error diffusion) to hide binary visual patterns in two error diffused halftone images. While one halftone image is only a regular error diffused image, stochastic error diffusion is applied to the other image to generate special stochastic characteristics with respect to the first image such that the visual pattern would appear when the two halftone images are overlaid Simulation results show that the two halftone images have good visual quality, and the hidden pattern appears with ""normal"" and ""lower-than-normal"" intensity when the two halftone images are overlaid."
"Guy Gilboa, Y. Zeevi, N. Sochen",d30513bf92d8095b2a7e54dd81e2e52747c736f3,Complex Diffusion Processes for Image Filtering,Scale-Space,2001,55,
J. Weickert,a328d4ce201d1830e5f452d630a6822f8ebe310a,Applications of nonlinear diffusion in image processing and computer vision,,2000,174,"Nonlinear diffusion processes can be found in many recent methods for image processing and computer vision. In this article, four applications are surveyed: nonlinear diffusion filtering, variational image regularization, optic flow estimation, and geodesic active contours. For each of these techniques we explain the main ideas, discuss theoretical properties and present an appropriate numerical scheme. The numerical schemes are based on additive operator splittings (AOS). In contrast to traditional multiplicative splittings such as ADI, LOD or D'yakonov splittings, all axes are treated in the same manner, and additional possibilities for efficient realizations on parallel and distributed architectures appear. Geodesic active contours lead to equations that resemble mean curvature motion. For this application, a novel AOS scheme is presented that uses harmonie averaging and does not require reinitializations of the distance function in each iteration step."
"D. Alexander, J. Gee",79266896c361f9d8032b8e613a7d409522bca2d6,Elastic Matching of Diffusion Tensor Images,Computer Vision and Image Understanding,2000,97,"In this paper, we discuss matching of magnetic resonance, diffusion tensor (DT) images of the human brain. Issues concerned with matching and transforming these complex images are discussed. In particular, we outline a method for preserving the intrinsic orientation of the data during nonrigid warps of the image and a number of similarity measures are proposed, based on the DT itself, on the DT deviatoric, and on indices derived from the DT. Each measure is used to drive an elastic matching algorithm applied to the task of registration of 3D images of the human brain. The performance of the various similarity measures is compared empirically by the use of several quality of match measures computed over a pair of matched images. Results indicate that the best matches are obtained from a Euclidean difference measure using the full DT."
"Jesse S. Jin, Yung Wang, J. Hiller",17e1e9764bfc0051d0c98113c34fe07df3ad3bac,An adaptive nonlinear diffusion algorithm for filtering medical images,IEEE Transactions on Information Technology in Biomedicine,2000,75,"The nonlinear anisotropic diffusive process has shown the good property of eliminating noise while preserving the accuracy of edges and has been widely used in image processing. However, filtering depends on the threshold of the diffusion process, i.e., the cut-off contrast of edges. The threshold varies from image to image and even from region to region within an image. The problem compounds with intensity distortion and contrast variation. We have developed an adaptive diffusion scheme by applying the central limit theorem to selecting the threshold. Gaussian distribution and Rayleigh distribution are used to estimate the distributions of visual objects in images. Regression under such distributions separates the distribution of the major object from other visual objects in a single-peak histogram. The separation helps to automatically determine the threshold. A fast algorithm is derived for the regression process. The method has been successfully used in filtering various medical images."
"M. Bastin, P. Armitage",e19af30f4648c4ddd881c4b3ce1908fcb8522b51,On the use of water phantom images to calibrate and correct eddy current induced artefacts in MR diffusion tensor imaging.,Magnetic Resonance Imaging,2000,55,
J. Weickert,1c71164b88a016516d99be72ebf49056daea842a,Coherence-enhancing diffusion of colour images,Image and Vision Computing,1999,319,
"C. Westin, S. Maier, B. Khidhir, P. Everett, F. Jolesz, R. Kikinis",7e4329c3f2db29fa8c0646dc246207a24c703abf,Image Processing for Diffusion Tensor Magnetic Resonance Imaging,International Conference on Medical Image Computing and Computer-Assisted Intervention,1999,193,
M. Horsfield,ce20059dd20e2d322a5973ebc241646875825fb5,Mapping eddy current induced fields for the correction of diffusion-weighted echo planar images.,Magnetic Resonance Imaging,1999,117,
"D. Alexander, J. Gee, R. Bajcsy",f48d987b35fc9b4b47469c26255627d375580c42,Similarity Measures for Matching Diffusion Tensor Images,British Machine Vision Conference,1999,74,"In this paper, we discuss matching of diffusion tensor (DT) MRIs of the human brain. Issues concerned with matching and transforming these complex images are discussed. A number of similarity measures are proposed, based on indices derived from the DT, the DT itself and the DT deviatoric. Each measure is used to drive an elastic matching algorithm applied to the task of registration of 3D images of the human brain. The performance of the various similarity measures is compared empirically by use of several quality of match measures computed over a pair of matched images. Results indicate that the best matches are obtained from a Euclidean difference measure using the full DT."
"D. Alexander, J. Gee, R. Bajcsy",82601c6610e958fd6f84b064f568b9c55f15f8d5,Strategies for Data Reorientation during Non-rigid Warps of Diffusion Tensor Images,International Conference on Medical Image Computing and Computer-Assisted Intervention,1999,27,
"P. Basser, C. Pierpaoli",319f5782c96a537c60c0d3f8009c469886d14745,A simplified method to measure the diffusion tensor from seven MR images,Magnetic Resonance in Medicine,1998,610,"Analytical expressions of the diffusion tensor of water, D, and of scalar invariants derived from it, are given in terms of the intensities of seven diffusion‐weighted images (DWIs). These formulas simplify the post‐processing steps required in diffusion tensor imaging, including estimating D in each voxel (from the set of b‐matrices and their corresponding DWIs), and then computing its eigenvalues, eigenvectors, and scalar invariants. In a study conducted using artifact‐free DWIs with high diffusion weighting (bmax ˜ 900 s/mm2), maps of Trace(D) and the Relative and Lattice Anisotropy indices calculated analytically and by multivariate linear regression showed excellent agreement in brain parenchyma of a healthy living cat. However, the quality of the analytically computed maps degraded markedly as diffusion weighting was reduced. Although diffusion tensor MRI with seven DWIs may be useful for clinical applications where rapid scanning and data processing are required, it does not provide estimates of the uncertainty of the measured imaging parameters, rendering it susceptible to noise and systematic artifacts. Therefore, care should be taken when using this technique in radiological applications."
"A. Alexander, J. Tsuruda, D. Parker",4579e01971c8c0739b362060b3f497a0f62d21ce,Elimination of eddy current artifacts in diffusion‐weighted echo‐planar images: The use of bipolar gradients,Magnetic Resonance in Medicine,1997,184,"Small gradient fields resulting from incompletely canceled eddy currents can cause geometric distortion in echo‐planar images. Although this distortion is negligible in most echo‐planar applications, the large gradient pulses used in diffusion‐weighted echo‐planar imaging can result in significant image distortion. In this report, it is shown that this distortion can be significantly reduced by the application of bipolar gradient waveforms. Both bipolar diffusion‐sensitizing gradients and an inverted gradient preparatory pulse were examined for minimizing the eddy currents responsible for these distortions."
P. Basser,d87f99cc10c479a1d30a5caab83669a10063709b,New Histological and Physiological Stains Derived from Diffusion‐Tensor MR Images,Annals of the New York Academy of Sciences,1997,156,"The measurement of the self-diffusivity of water (and other solvents) using the phenomenon of nuclear magnetic resonance was first reported more than four decades ago. Methodological improvements in these diffusion measurements2 and the subsequent development of magnetic resonance imaging,' together created the possibility to measure diffusion properties of water in tissues on a voxel by voxel basis. Diffusion imaging (DI), which was first realized in 1985,4-6 consists of measuring an apparent diffusion constant (ADC)7 in each voxel. Both its theoretical underpinnings and its applications are well-known and are described in a number of excellent books and review"
"K. Krissian, G. Malandain, N. Ayache",de0b16aad486e24a8920da34d6aa45e6a7f34754,Directional Anisotropic Diffusion Applied to Segmentation of Vessels in 3D Images,Scale-Space,1997,94,
"J. Monreal, L. Álvarez",33ffc427b621f78dc827d344b65e33c1fc7c77cb,Image Quantization Using Reaction-Diffusion Equations,SIAM Journal on Applied Mathematics,1997,43,"In this paper we present an image quantization model based on a reaction-diffusion partial differential equation. The quantized image is given by the asymptotic state of this equation. Existence and uniqueness of the solution are proved in the framework of viscosity solutions. We introduce an $L^\infty$ stable algorithm in order to compute numerically the solution of the equation, and some experimental results are shown. A new energy functional based on the classical Lloyd method is used to compute the quantizer codewords."
"Michael J. Black, G. Sapiro, D. Marimont, D. Heeger",859a37314939863060bac417f5775e8c9b5a2ab9,Robust anisotropic diffusion and sharpening of scalar and vector images,Proceedings of International Conference on Image Processing,1997,15,"Relations between anisotropic diffusion and robust statistics are described. We show that anisotropic diffusion can be seen as a robust estimation procedure that estimates a piecewise smooth image from a noisy input image. The ""edge-stopping"" function in the anisotropic diffusion equation is closely related to the error norm and influence function in the robust estimation framework. This connection leads to a new ""edge-stopping"" function based on Tukey's biweight robust estimator, that preserves sharper boundaries than previous formulations and improves the automatic stopping of the diffusion. The robust statistical interpretation also provides a means for detecting the boundaries (edges) between the piecewise smooth regions in the image. We extend the framework to vector-valued images and show applications to robust image sharpening."
"Yu-Li You, Wenyuan Xu, A. Tannenbaum, M. Kaveh",4d2f0f119a6ecf15669636c8d261dbd9e0207447,Behavioral analysis of anisotropic diffusion in image processing,IEEE Transactions on Image Processing,1996,569,"In this paper, we analyze the behavior of the anisotropic diffusion model of Perona and Malik (1990). The main idea is to express the anisotropic diffusion equation as coming from a certain optimization problem, so its behavior can be analyzed based on the shape of the corresponding energy surface. We show that anisotropic diffusion is the steepest descent method for solving an energy minimization problem. It is demonstrated that an anisotropic diffusion is well posed when there exists a unique global minimum for the energy functional and that the ill posedness of a certain anisotropic diffusion is caused by the fact that its energy functional has an infinite number of global minima that are dense in the image space. We give a sufficient condition for an anisotropic diffusion to be well posed and a sufficient and necessary condition for it to be ill posed due to the dense global minima. The mechanism of smoothing and edge enhancement of anisotropic diffusion is illustrated through a particular orthogonal decomposition of the diffusion operator into two parts: one that diffuses tangentially to the edges and therefore acts as an anisotropic smoothing operator, and the other that flows normally to the edges and thus acts as an enhancement operator."
"G. Sapiro, D. Ringach",674285f115841d8a237a68e55b4e651cc558bf9d,Anisotropic diffusion of multivalued images with applications to color filtering,IEEE Transactions on Image Processing,1996,482,"A general framework for anisotropic diffusion of multivalued images is presented. We propose an evolution equation where, at each point in time, the directions and magnitudes of the maximal and minimal rate of change in the vector-image are first evaluated. These are given by eigenvectors and eigenvalues of the first fundamental form in the given image metric. Then, the image diffuses via a system of coupled differential equations in the direction of minimal change. The diffusion ""strength"" is controlled by a function that measures the degree of dissimilarity between the eigenvalues. We apply the proposed framework to the filtering of color images represented in CIE-L*a*b* space."
"J. Haselgrove, J. R. Moore",e4a39c4e72c19a5653ff494b8f257babf7c04ac6,Correction for distortion of echo‐planar images used to calculate the apparent diffusion coefficient,Magnetic Resonance in Medicine,1996,340,"An algorithm for correcting the distortions that occur in diffusion‐weighted echo‐planar images due to the strong diffusion‐sensitizing gradients is presented. The dominant distortions may be considered to be only changes of scale coupled with a shear and linear translation in the phase‐encoding direction. It is then possible to correct for them by using an algorithm in which each line of the image in the phase‐encoding direction is considered in turn, with only one parameter (the scale) to be found by searching."
"W. Cai, B. Das, F. Liu, M. Zevallos, M. Lax, R. Alfano",d100617210884ee884ec4be9596274686d66189b,Time-resolved optical diffusion tomographic image reconstruction in highly scattering turbid media.,Proceedings of the National Academy of Sciences of the United States of America,1996,45,"The image of an object hidden in highly scattering media was reconstructed using a fast, noise-resistant algorithm newly applied to diffusion tomography. A pulsed light source producing scattered and transmitted light is examined at multiple times. Multiple source detector pairs around the medium are used to obtain data in many different directions. An inverse scattering algorithm with nonuniform regularization achieves rapid inversion convergence."
P. Basser,c212a92e133ccb61ac50b779c9b0bc330dd6e3cf,Inferring microstructural features and the physiological state of tissues from diffusion‐weighted images,NMR in Biomedicine,1995,1520,"We review several methods that have been developed to infer microstructural and physiological information about isotropic and anisotropic tissues from diffusion weighted images (DWIs). These include Diffusion Imaging (DI), Diffusion Tensor Imaging (DTI), isotropically weighted imaging, and q‐space imaging. Just as DI provides useful information about molecular displacements in one dimension with which to characterize diffusion in isotropic tissues, DTI provides information about molecular displacements in three dimensions needed to characterize diffusion is anisotropic tissues. DTI also furnishes scalar parameters that behave like quantitative histological or physiological‘stains’ for different features of diffusion. These include Trace(D), which is related to the mean diffusivity, and a family of parameters derived from the diffusion tensor, D, which characterize different features of anisotropic diffusion. Simple thought experiments and geometrical constructs, such as the diffusion ellipsoid, can be used to understand water diffusion in isotropic and anisotropic media, and the NMR experiments used to characterize it."
"J. Kacur, K. Mikula",7703f8565e7fe9b981f4273a21fe327ceecff55c,Solution of nonlinear diffusion appearing in image smoothing and edge detection,,1995,122,
"A. Uluğ, P. Barker, P. Zijl",12c334bf69111249e7d46b9636481c77ff1dd44a,Correction of motional artifacts in diffusion‐weighted images using a reference phase map,Magnetic Resonance in Medicine,1995,29,"A method of correcting motional artifacts in diffusion‐weighted images is described. Motion causes changes in the phase of the k‐space NMR signal and thereby introduces positional shifts (or ghosts) in the spatial domain. By correcting the phase of the NMR signal before Fourier transformation, the image sharpness is greatly enhanced. The new method measures the phases of the NMR signal once and stores this phase information in a phase map. Subsequent images with motional artifacts are corrected during postprocessing using this reference phase map."
B. H. Romeny,e62ffb7a63e063aedf046f8cf05b8aa47ddb930a,Geometry-Driven Diffusion in Computer Vision,Computational Imaging and Vision,1994,802,
"L. Álvarez, L. Mazorra",27df57bbd656d4ee9f87e5a2ed4e951e64dae539,Signal and image restoration using shock filters and anisotropic diffusion,,1994,402,The authors define a new class of filters for noise elimination and edge enhancement by using shock filters and anisotropic diffusion. Some nonlinear partial differential equations used as models f...
J. Weickert,60b1f3d452696feafd0fe54621ff015e688adcd2,Theoretical Foundations of Anisotropic Diffusion in Image Processing,Theoretical Foundations of Computer Vision,1994,337,
"R. Ordidge, J. Helpern, Z. X. Qing, R. Knight, V. Nagesh",407efd96dd33d506518a4ed2c780f98a002487ac,Correction of motional artifacts in diffusion-weighted MR images using navigator echoes.,Magnetic Resonance Imaging,1994,336,
"M. Proesmans, E. Pauwels, L. Gool",c3af625b8d68beb56099b7159d7608b5d054ed94,Coupled Geometry-Driven Diffusion Equations for Low-Level Vision,Geometry-Driven Diffusion in Computer Vision,1994,72,
"J. Weickert, J. Fröhlich",e7fc7cc7afa27c06dd09679396d3285e35bc6edb,Image Processing Using a Wavelet Algorithm for Nonlinear Diffusion,,1994,34,"The edge enhancement property of a nonlinear diffusion equation with a suitable expression for the diffusivity is an important feature for image processing. We present an algorithm to solve this equation in a wavelet basis and discuss its one dimensional version in some detail. Sample calculations demonstrate principle effects and treat in particular the case of highly noise perturbed signals. The results are discussed with respect to performance, efficiency, choice of parameters and are illustrated by a large number of figures. Finally, a comparison with a Fourier method and a finite volume method is performed."
"G. Cottet, L. Germain",f0b610c578dc1c659c3d5b4f3be3c617dd514b1e,Image processing through reaction combined with nonlinear diffusion,,1993,166,We propose a method based on nonlinear diffusion and reaction for edge detection and contrast enhancement in image processing. We prove that the mathematical model is well posed and show numerically that the processed image can be observed on the asymptotic state of its solution. We illustrate the methods on test images and show on medical images how it can help to draw contours and detect one-dimensional coherent signals.
G. Cottet,74d6227e3bbe4915cd9c2b96ee44088773b35c8f,Diffusion approximation on neural networks and applications for image processing,,1992,11,
"D. Bihan, É. Breton",f591644d344ea53000c42f08eb2318345f725a9e,Imagerie de diffusion in-vivo par résonance magnétique nucléaire,,1985,355,
